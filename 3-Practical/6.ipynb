{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1ofncK2cYhs"
      },
      "source": [
        "Disclaimer: Nothing herein is financial advice, and NOT a recommendation to trade real money. Many platforms exist for simulated trading (paper trading) which can be used for building and developing the methods discussed. Please use common sense and always first consult a professional before trading or investing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIG9ebIEgGfx"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/3-Practical/FinRL_PaperTrading_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3mbRu3s1YlD"
      },
      "source": [
        "# Part 1: Install FinRL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0gkmsPgbvNf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43bd2a77-31ba-4fc0-8a3d-936c6e7451ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wrds\n",
            "  Downloading wrds-3.1.6-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from wrds) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from wrds) (1.5.3)\n",
            "Collecting psycopg2-binary (from wrds)\n",
            "  Downloading psycopg2_binary-2.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from wrds) (1.10.1)\n",
            "Collecting sqlalchemy<2 (from wrds)\n",
            "  Downloading SQLAlchemy-1.4.48-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2->wrds) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->wrds) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\n",
            "Installing collected packages: sqlalchemy, psycopg2-binary, wrds\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.10\n",
            "    Uninstalling SQLAlchemy-2.0.10:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.10\n",
            "Successfully installed psycopg2-binary-2.9.6 sqlalchemy-1.4.48 wrds-3.1.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting swig\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "⏬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:10\n",
            "🔁 Restarting kernel...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../libgl1-mesa-glx_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Selecting previously unselected package swig4.0.\n",
            "Preparing to unpack .../swig4.0_4.0.1-5build1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.1-5build1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.1-5build1_all.deb ...\n",
            "Unpacking swig (4.0.1-5build1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Setting up swig4.0 (4.0.1-5build1) ...\n",
            "Setting up swig (4.0.1-5build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-r682ssc4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-r682ssc4\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 7414adb012b554f7c684d4615830dc5c31a094d1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-nosvlkig/elegantrl_9dee8c757fa9480999fb2da03e0e5fdf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-nosvlkig/elegantrl_9dee8c757fa9480999fb2da03e0e5fdf\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 0c019eec035391dbe7aca1464ed6a0067e5a130f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jqdatasdk<2,>=1\n",
            "  Downloading jqdatasdk-1.8.11-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrds<4,>=3\n",
            "  Using cached wrds-3.1.6-py3-none-any.whl (12 kB)\n",
            "Collecting yfinance<0.3,>=0.2\n",
            "  Downloading yfinance-0.2.18-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn<2,>=1\n",
            "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alpaca-trade-api<4,>=3\n",
            "  Downloading alpaca_trade_api-3.0.0-py3-none-any.whl (33 kB)\n",
            "Collecting ccxt<4,>=3\n",
            "  Downloading ccxt-3.0.101-py2.py3-none-any.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stockstats<0.6,>=0.5\n",
            "  Downloading stockstats-0.5.2-py2.py3-none-any.whl (20 kB)\n",
            "Collecting pyfolio<0.10,>=0.9\n",
            "  Downloading pyfolio-0.9.2.tar.gz (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ray[default,tune]<3,>=2\n",
            "  Downloading ray-2.4.0-cp310-cp310-manylinux2014_x86_64.whl (58.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyportfolioopt<2,>=1\n",
            "  Downloading pyportfolioopt-1.5.5-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting exchange-calendars<5,>=4\n",
            "  Downloading exchange_calendars-4.2.7-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.1/190.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stable-baselines3[extra]>=2.0.0a5\n",
            "  Downloading stable_baselines3-2.0.0a5-py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.5/177.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.15)\n",
            "Collecting numpy>=1.11.1\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>2 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.28.2)\n",
            "Collecting websockets<11,>=9.0\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msgpack==1.0.3\n",
            "  Downloading msgpack-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.7/323.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecation==2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting websocket-client<2,>=0.56.0\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp==3.8.1\n",
            "  Downloading aiohttp-3.8.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=0.18.1\n",
            "  Downloading pandas-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting charset-normalizer<3.0,>=2.0\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiodns>=1.1.1\n",
            "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (65.6.3)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (40.0.1)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (2022.12.7)\n",
            "Collecting pyluach\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting python-dateutil\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toolz in /usr/local/lib/python3.10/site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.12.0)\n",
            "Collecting pytz\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting korean-lunar-calendar\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Collecting thriftpy2>=0.3.9\n",
            "  Downloading thriftpy2-0.4.16.tar.gz (643 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m643.4/643.4 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymysql>=0.7.6\n",
            "  Downloading PyMySQL-1.0.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting SQLAlchemy>=1.2.8\n",
            "  Downloading SQLAlchemy-2.0.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython>=3.2.3\n",
            "  Downloading ipython-8.13.2-py3-none-any.whl (797 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.7/797.7 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib>=1.4.0\n",
            "  Downloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=0.14.0\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seaborn>=0.7.1\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting empyrical>=0.5.0\n",
            "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cvxpy<2.0.0,>=1.1.19\n",
            "  Downloading cvxpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click>=7.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
            "Collecting protobuf!=3.19.5,>=3.15.3\n",
            "  Downloading protobuf-4.23.0-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio<=1.51.3,>=1.42.0\n",
            "  Downloading grpcio-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting virtualenv<20.21.1,>=20.0.24\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prometheus-client>=0.7.1\n",
            "  Downloading prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.5/122.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorful\n",
            "  Downloading colorful-0.5.5-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open\n",
            "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic\n",
            "  Downloading pydantic-1.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencensus\n",
            "  Downloading opencensus-0.11.2-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpustat>=1.0.0\n",
            "  Downloading gpustat-1.1.tar.gz (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tabulate\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.1.1\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting gymnasium==0.28.1\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Collecting torch>=1.11\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.65.0)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autorom[accept-rom-license]~=0.6.0\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard>=2.9.1\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.1/282.1 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich\n",
            "  Downloading rich-13.3.5-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.7/238.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shimmy[atari]~=0.2.1\n",
            "  Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
            "Collecting typing-extensions>=4.3.0\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting farama-notifications>=0.0.1\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting jax-jumpy>=1.0.0\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Collecting psycopg2-binary\n",
            "  Using cached psycopg2_binary-2.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Collecting SQLAlchemy>=1.2.8\n",
            "  Using cached SQLAlchemy-1.4.48-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "Collecting frozendict>=2.3.4\n",
            "  Downloading frozendict-2.3.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lxml>=4.9.1\n",
            "  Downloading lxml-4.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html5lib>=1.1\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multitasking>=0.0.7\n",
            "  Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
            "Collecting beautifulsoup4>=4.11.1\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs>=1.4.4\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting gym\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycares>=4.0.0\n",
            "  Downloading pycares-4.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/site-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (1.15.1)\n",
            "Collecting osqp>=0.4.1\n",
            "  Downloading osqp-0.6.2.post9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.6/298.6 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scs>=1.1.6\n",
            "  Downloading scs-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ecos>=2\n",
            "  Downloading ecos-2.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas-datareader>=0.2\n",
            "  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-ml-py>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.525.112-py3-none-any.whl (35 kB)\n",
            "Collecting blessed>=1.17.1\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webencodings\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting stack-data\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30\n",
            "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments>=2.4.0\n",
            "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitlets>=5\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzdata>=2022.1\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.4)\n",
            "Collecting ale-py~=0.8.1\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting greenlet!=0.4.17\n",
            "  Downloading greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.7/613.7 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=0.4\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.18.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.40.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting protobuf!=3.19.5,>=3.15.3\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ply<4.0,>=3.4\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy\n",
            "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lit\n",
            "  Downloading lit-16.0.3.tar.gz (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmake\n",
            "  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting platformdirs<4,>=2.4\n",
            "  Downloading platformdirs-3.5.1-py3-none-any.whl (15 kB)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gym-notices>=0.0.4\n",
            "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Collecting box2d-py==2.3.5\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting swig==4.*\n",
            "  Using cached swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-core<3.0.0,>=1.0.0\n",
            "  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencensus-context>=0.1.3\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting markdown-it-py<3.0.0,>=2.2.0\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting wcwidth>=0.1.4\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (2.21)\n",
            "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting qdldl\n",
            "  Downloading qdldl-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting executing>=1.2.0\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1<0.6.0,>=0.4.6\n",
            "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: finrl, pyfolio, elegantrl, empyrical, gpustat, thriftpy2, gym, box2d-py, AutoROM.accept-rom-license, lit\n",
            "  Building wheel for finrl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.6-py3-none-any.whl size=4668689 sha256=19875b136db5d16516baeabaf5a22a482e7388fc2349a77c00071d07f6c2f321\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a6xv2otu/wheels/72/3b/1a/0fc805a8cc65ecd5bfe4f74a3c586b6075678b8ba53fd8f749\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2-py3-none-any.whl size=88663 sha256=e3addbe273f1817a28f6431e7743957f5b230c94fc3633dff224d19cf263011e\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/38/bc/e53700cfd8b0ad6b539d2fbaaf060ed8a299e7622a5b86ef42\n",
            "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elegantrl: filename=elegantrl-0.3.6-py3-none-any.whl size=197329 sha256=5cf27e1df9fa267857b809f7efc249b28dc287e7a9981233c4786034090487d5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a6xv2otu/wheels/c0/51/a5/b05f165548221bc570f7223babd33e2992fa873cdcebe2d229\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39762 sha256=a9ed574c2458bdfd075c5e68d7097ca721c24c6bb7605b168f729d8200fcbd19\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/2e/f2/d6d2d9a1eb8fbbd9949bb5d4c00f753e3b74e5bd7ed10b1d36\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1-py3-none-any.whl size=26280 sha256=fddbd380f45c0bd3eb5bc466939cecc26e9f6ce349bb9de309f611d6cb0ffcf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/d0/2c/1e02440645c2318ba03aea99993a44a9108dc8f74de0bd370b\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.4.16-cp310-cp310-linux_x86_64.whl size=522560 sha256=cc1ecc2a9c8848630b71065b54e859cc9184a673a6fd00179fa6db78119df9f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/f5/1d/fe404692e1c8aaea45220c322d1d0f32c9fd40eb0e2bdd571e\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827634 sha256=4ae0d6492ab3ea91ca97096f427aa1a39a5e29b4041c14476471df2f50c2760c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=494635 sha256=a977dd982335a37cda53846d8fa32b0ef5481fa3fdfc874b06277cd8dfaac708\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=93fc581a9fe8c1397cd8e18cd0d1a4a6c67fb5ed5bf518da69c5fc93f25db657\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.3-py3-none-any.whl size=88173 sha256=14a4f6a62c706186efb3c49eec60b61312bd887093e03a883579b0f4eed3d9f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/81/1c/a49ba782377339294cc45c9899927b61a92e58d6ad3ac942f7\n",
            "Successfully built finrl pyfolio elegantrl empyrical gpustat thriftpy2 gym box2d-py AutoROM.accept-rom-license lit\n",
            "Installing collected packages: webencodings, wcwidth, swig, pytz, py-spy, pure-eval, ptyprocess, ply, pickleshare, opencensus-context, nvidia-ml-py, multitasking, msgpack, mpmath, lit, korean-lunar-calendar, gym-notices, farama-notifications, executing, distlib, colorful, cmake, box2d-py, backcall, appdirs, websockets, websocket-client, tzdata, typing-extensions, traitlets, threadpoolctl, tensorboard-data-server, tabulate, sympy, soupsieve, smart-open, six, PyYAML, pyrsistent, pyparsing, pymysql, pyluach, pygments, pygame, pyasn1, psycopg2-binary, psutil, protobuf, prompt-toolkit, prometheus-client, platformdirs, pillow, pexpect, parso, packaging, oauthlib, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, multidict, mdurl, MarkupSafe, markdown, lxml, kiwisolver, joblib, importlib-resources, grpcio, greenlet, frozenlist, frozendict, fonttools, filelock, decorator, cycler, cloudpickle, click, charset-normalizer, cachetools, attrs, async-timeout, absl-py, yarl, werkzeug, virtualenv, thriftpy2, tensorboardX, SQLAlchemy, scipy, rsa, python-dateutil, pydantic, pycares, pyasn1-modules, opencv-python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, matplotlib-inline, markdown-it-py, jsonschema, jinja2, jedi, jax-jumpy, html5lib, gym, googleapis-common-protos, deprecation, contourpy, blessed, beautifulsoup4, asttokens, ale-py, aiosignal, stack-data, scs, scikit-learn, rich, requests-oauthlib, ray, qdldl, pandas, matplotlib, gymnasium, gpustat, google-auth, ecos, AutoROM.accept-rom-license, autorom, aiohttp, aiodns, yfinance, wrds, stockstats, shimmy, seaborn, pandas-datareader, osqp, jqdatasdk, ipython, google-auth-oauthlib, google-api-core, exchange-calendars, ccxt, alpaca-trade-api, aiohttp-cors, tensorboard, opencensus, empyrical, cvxpy, pyportfolioopt, pyfolio, triton, torch, stable-baselines3, elegantrl, finrl\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.1.0\n",
            "    Uninstalling charset-normalizer-3.1.0:\n",
            "      Successfully uninstalled charset-normalizer-3.1.0\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 MarkupSafe-2.1.2 PyYAML-6.0 SQLAlchemy-1.4.48 absl-py-1.4.0 aiodns-3.0.0 aiohttp-3.8.1 aiohttp-cors-0.7.0 aiosignal-1.3.1 ale-py-0.8.1 alpaca-trade-api-3.0.0 appdirs-1.4.4 asttokens-2.2.1 async-timeout-4.0.2 attrs-23.1.0 autorom-0.6.1 backcall-0.2.0 beautifulsoup4-4.12.2 blessed-1.20.0 box2d-py-2.3.5 cachetools-5.3.0 ccxt-3.0.101 charset-normalizer-2.1.1 click-8.1.3 cloudpickle-2.2.1 cmake-3.26.3 colorful-0.5.5 contourpy-1.0.7 cvxpy-1.3.1 cycler-0.11.0 decorator-5.1.1 deprecation-2.1.0 distlib-0.3.6 ecos-2.0.12 elegantrl-0.3.6 empyrical-0.5.5 exchange-calendars-4.2.7 executing-1.2.0 farama-notifications-0.0.4 filelock-3.12.0 finrl-0.3.6 fonttools-4.39.4 frozendict-2.3.8 frozenlist-1.3.3 google-api-core-2.11.0 google-auth-2.18.0 google-auth-oauthlib-1.0.0 googleapis-common-protos-1.59.0 gpustat-1.1 greenlet-2.0.2 grpcio-1.51.3 gym-0.26.2 gym-notices-0.0.8 gymnasium-0.28.1 html5lib-1.1 importlib-resources-5.12.0 ipython-8.13.2 jax-jumpy-1.0.0 jedi-0.18.2 jinja2-3.1.2 joblib-1.2.0 jqdatasdk-1.8.11 jsonschema-4.17.3 kiwisolver-1.4.4 korean-lunar-calendar-0.3.1 lit-16.0.3 lxml-4.9.2 markdown-3.4.3 markdown-it-py-2.2.0 matplotlib-3.7.1 matplotlib-inline-0.1.6 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.0.3 multidict-6.0.4 multitasking-0.0.11 networkx-3.1 numpy-1.24.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-ml-py-11.525.112 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 oauthlib-3.2.2 opencensus-0.11.2 opencensus-context-0.1.3 opencv-python-4.7.0.72 osqp-0.6.2.post9 packaging-23.1 pandas-2.0.1 pandas-datareader-0.10.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.5.0 platformdirs-3.5.1 ply-3.11 prometheus-client-0.16.0 prompt-toolkit-3.0.38 protobuf-3.20.3 psutil-5.9.5 psycopg2-binary-2.9.6 ptyprocess-0.7.0 pure-eval-0.2.2 py-spy-0.3.14 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pydantic-1.10.7 pyfolio-0.9.2 pygame-2.1.0 pygments-2.15.1 pyluach-2.2.0 pymysql-1.0.3 pyparsing-3.0.9 pyportfolioopt-1.5.5 pyrsistent-0.19.3 python-dateutil-2.8.2 pytz-2023.3 qdldl-0.1.7 ray-2.4.0 requests-oauthlib-1.3.1 rich-13.3.5 rsa-4.9 scikit-learn-1.2.2 scipy-1.10.1 scs-3.2.3 seaborn-0.12.2 shimmy-0.2.1 six-1.16.0 smart-open-6.3.0 soupsieve-2.4.1 stable-baselines3-2.0.0a5 stack-data-0.6.2 stockstats-0.5.2 swig-4.1.1 sympy-1.12 tabulate-0.9.0 tensorboard-2.13.0 tensorboard-data-server-0.7.0 tensorboardX-2.6 threadpoolctl-3.1.0 thriftpy2-0.4.16 torch-2.0.1 traitlets-5.9.0 triton-2.0.0 typing-extensions-4.5.0 tzdata-2023.3 virtualenv-20.21.0 wcwidth-0.2.6 webencodings-0.5.1 websocket-client-1.5.1 websockets-10.4 werkzeug-2.3.4 wrds-3.1.6 yarl-1.9.2 yfinance-0.2.18\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "google",
                  "kiwisolver",
                  "matplotlib",
                  "matplotlib_inline",
                  "mpl_toolkits",
                  "pexpect",
                  "pickleshare",
                  "prompt_toolkit",
                  "psutil",
                  "six",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting exchange_calendars==3.6.3\n",
            "  Downloading exchange_calendars-3.6.3.tar.gz (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from exchange_calendars==3.6.3) (1.24.3)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/site-packages (from exchange_calendars==3.6.3) (2.0.1)\n",
            "Requirement already satisfied: pyluach in /usr/local/lib/python3.10/site-packages (from exchange_calendars==3.6.3) (2.2.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/site-packages (from exchange_calendars==3.6.3) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/site-packages (from exchange_calendars==3.6.3) (2023.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/site-packages (from exchange_calendars==3.6.3) (0.12.0)\n",
            "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.10/site-packages (from exchange_calendars==3.6.3) (0.3.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.1->exchange_calendars==3.6.3) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil->exchange_calendars==3.6.3) (1.16.0)\n",
            "Building wheels for collected packages: exchange_calendars\n",
            "  Building wheel for exchange_calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for exchange_calendars: filename=exchange_calendars-3.6.3-py3-none-any.whl size=182619 sha256=f79526fc23bb8c03a958b1f8aa226e4057b75eabc32dcae3922ea0d267c9328d\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/ca/8f/1e1c90cc79fb3ca9b5413ff58e3fccf3baf2182c994c6dfd37\n",
            "Successfully built exchange_calendars\n",
            "Installing collected packages: exchange_calendars\n",
            "  Attempting uninstall: exchange_calendars\n",
            "    Found existing installation: exchange-calendars 4.2.7\n",
            "    Uninstalling exchange-calendars-4.2.7:\n",
            "      Successfully uninstalled exchange-calendars-4.2.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "finrl 0.3.6 requires exchange-calendars<5,>=4, but you have exchange-calendars 3.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed exchange_calendars-3.6.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install exchange_calendars==3.6.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFiXTmk-gGfy",
        "outputId": "cea7b614-941b-491e-dfd1-9c4b14edd690"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas==1.5.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFb1Br22kHOn",
        "outputId": "76b18293-d355-4322-bedb-244de34c5fdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas==1.5.3\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas==1.5.3) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/site-packages (from pandas==1.5.3) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/site-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.1\n",
            "    Uninstalling pandas-2.0.1:\n",
            "      Successfully uninstalled pandas-2.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "finrl 0.3.6 requires exchange-calendars<5,>=4, but you have exchange-calendars 3.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.5.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--6Kx8I21erH"
      },
      "source": [
        "## Import related modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H7I7zsyYfoLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a88583a3-fa2b-4d7e-c82c-92b4cf3946d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.config import INDICATORS\n",
        "from finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\n",
        "from finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "from finrl import config\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "import datetime\n",
        "from pandas.tseries.offsets import BDay  # BDay is business day, not birthday.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf5aVHAU-xF6"
      },
      "source": [
        "## Import Dow Jones 30 Symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jx25TA_X87F-"
      },
      "outputs": [],
      "source": [
        "ticker_list = DOW_30_TICKER\n",
        "action_dim = len(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rwy7V72-8YY"
      },
      "source": [
        "## Get the API Keys Ready"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"PKO361BYCXVIYHB1FCNX\"\n",
        "API_SECRET = \"HCyg7FQNA3nlXRSNp2emmbqVR0GYw2iDWIO97h4w\"\n",
        "API_BASE_URL = 'https://paper-api.alpaca.markets'\n",
        "data_url = 'wss://data.alpaca.markets'\n",
        "env = StockTradingEnv"
      ],
      "metadata": {
        "id": "GcPfnYWF2Com"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ],
      "metadata": {
        "id": "ZXBl89W524yL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from finrl.meta.data_processor import DataProcessor\n",
        "def get_data(start_date, end_date, if_vix = True):\n",
        "      DP = DataProcessor(data_source = 'alpaca',\n",
        "                    API_KEY = API_KEY, \n",
        "                    API_SECRET = API_SECRET, \n",
        "                    API_BASE_URL = API_BASE_URL\n",
        "                    )\n",
        "      print('Downloading ticker data')\n",
        "      df = DP.download_data(start_date = start_date, \n",
        "                            end_date = end_date,\n",
        "                            ticker_list = ticker_list, \n",
        "                            time_interval= '1Min')\n",
        "      data = DP.clean_data(df)\n",
        "      data = DP.add_technical_indicator(data, INDICATORS)\n",
        "      data = DP.add_vix(data)\n",
        "      data = data.fillna(0)\n",
        "      return DP.df_to_array(data, if_vix)\n"
      ],
      "metadata": {
        "id": "PFl9eq8R2JlM"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "today = datetime.datetime.today()\n",
        "\n",
        "TEST_END_DATE = (today - BDay(1)).to_pydatetime().date()\n",
        "TEST_START_DATE = (TEST_END_DATE - BDay(1)).to_pydatetime().date()\n",
        "TRAIN_END_DATE = (TEST_START_DATE - BDay(1)).to_pydatetime().date()\n",
        "TRAIN_START_DATE = (TRAIN_END_DATE - BDay(5)).to_pydatetime().date()\n",
        "TRAINFULL_START_DATE = TRAIN_START_DATE\n",
        "TRAINFULL_END_DATE = TEST_END_DATE\n",
        "\n",
        "TRAIN_START_DATE = str(TRAIN_START_DATE)\n",
        "TRAIN_END_DATE = str(TRAIN_END_DATE)\n",
        "TEST_START_DATE = str(TEST_START_DATE)\n",
        "TEST_END_DATE = str(TEST_END_DATE)\n",
        "TRAINFULL_START_DATE = str(TRAINFULL_START_DATE)\n",
        "TRAINFULL_END_DATE = str(TRAINFULL_END_DATE)\n",
        "\n",
        "print(\"TRAIN_START_DATE : \", TRAIN_START_DATE)\n",
        "print(\"TRAIN_END_DATE.  : \", TRAIN_END_DATE)\n",
        "print(\"TEST_START_DATE  : \", TEST_START_DATE)\n",
        "print(\"TEST_END_DATE    : \", TEST_END_DATE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xll1tDi_-6Dl",
        "outputId": "21aaf489-4b6e-4d85-c099-db6b9c270c67"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN_START_DATE :  2023-05-02\n",
            "TRAIN_END_DATE.  :  2023-05-09\n",
            "TEST_START_DATE  :  2023-05-10\n",
            "TEST_END_DATE    :  2023-05-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from numpy import random as rd\n",
        "\n",
        "\n",
        "class StockTradingEnv(gym.Env):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        initial_account=50000,\n",
        "        gamma=0.99,\n",
        "        turbulence_thresh=99,\n",
        "        min_stock_rate=0.1,\n",
        "        max_stock=30,\n",
        "        initial_capital=50000,\n",
        "        buy_cost_pct=1e-3,\n",
        "        sell_cost_pct=1e-3,\n",
        "        reward_scaling=2**-11,\n",
        "        initial_stocks=None,\n",
        "    ):\n",
        "        price_ary = config[\"price_array\"]\n",
        "        tech_ary = config[\"tech_array\"]\n",
        "        turbulence_ary = config[\"turbulence_array\"]\n",
        "        if_train = config[\"if_train\"]\n",
        "        \n",
        "        self.price_ary = price_ary.astype(np.float32)\n",
        "        self.tech_ary = tech_ary.astype(np.float32)\n",
        "        self.turbulence_ary = turbulence_ary\n",
        "\n",
        "        self.tech_ary = self.tech_ary * 2**-7\n",
        "        self.turbulence_bool = (turbulence_ary > turbulence_thresh).astype(np.float32)\n",
        "        self.turbulence_ary = (self.sigmoid_sign(turbulence_ary, turbulence_thresh) * 2**-5).astype(np.float32)\n",
        "\n",
        "        stock_dim = self.price_ary.shape[1]\n",
        "        self.gamma = gamma\n",
        "        self.max_stock = max_stock\n",
        "        self.min_stock_rate = min_stock_rate\n",
        "        self.buy_cost_pct = buy_cost_pct\n",
        "        self.sell_cost_pct = sell_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.initial_capital = initial_capital\n",
        "        self.initial_stocks = (\n",
        "            np.zeros(stock_dim, dtype=np.float32)\n",
        "            if initial_stocks is None\n",
        "            else initial_stocks\n",
        "        )\n",
        "\n",
        "        # reset()\n",
        "        self.day = None\n",
        "        self.amount = None\n",
        "        self.stocks = None\n",
        "        self.total_asset = None\n",
        "        self.gamma_reward = None\n",
        "        self.initial_total_asset = None\n",
        "\n",
        "        # environment information\n",
        "        self.env_name = \"StockEnv\"\n",
        "        # self.state_dim = 1 + 2 + 2 * stock_dim + self.tech_ary.shape[1]\n",
        "        # # amount + (turbulence, turbulence_bool) + (price, stock) * stock_dim + tech_dim\n",
        "        self.state_dim = 1 + 2 + 3 * stock_dim + self.tech_ary.shape[1]\n",
        "        # amount + (turbulence, turbulence_bool) + (price, stock) * stock_dim + tech_dim\n",
        "        self.stocks_cd = None\n",
        "        self.action_dim = stock_dim\n",
        "        self.max_step = self.price_ary.shape[0] - 1\n",
        "        self.if_train = if_train\n",
        "        self.if_discrete = False\n",
        "        self.target_return = 10.0\n",
        "        self.episode_return = 0.0\n",
        "\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=-3000, high=3000, shape=(self.state_dim,), dtype=np.float32\n",
        "        )\n",
        "        self.action_space = gym.spaces.Box(\n",
        "            low=-1, high=1, shape=(self.action_dim,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def reset(self):\n",
        "        self.day = 0\n",
        "        price = self.price_ary[self.day]\n",
        "\n",
        "        if self.if_train:\n",
        "            self.stocks = (\n",
        "                self.initial_stocks + rd.randint(0, 64, size=self.initial_stocks.shape)\n",
        "            ).astype(np.float32)\n",
        "            self.stocks_cool_down = np.zeros_like(self.stocks)\n",
        "            self.amount = (\n",
        "                self.initial_capital * rd.uniform(0.95, 1.05)\n",
        "                - (self.stocks * price).sum()\n",
        "            )\n",
        "        else:\n",
        "            self.stocks = self.initial_stocks.astype(np.float32)\n",
        "            self.stocks_cool_down = np.zeros_like(self.stocks)\n",
        "            self.amount = self.initial_capital\n",
        "\n",
        "        self.total_asset = self.amount + (self.stocks * price).sum()\n",
        "        self.initial_total_asset = self.total_asset\n",
        "        self.gamma_reward = 0.0\n",
        "        return self.get_state(price), {}  # state\n",
        "\n",
        "    def step(self, actions):\n",
        "        actions = (actions * self.max_stock).astype(int)\n",
        "\n",
        "        self.day += 1\n",
        "        price = self.price_ary[self.day]\n",
        "        self.stocks_cool_down += 1\n",
        "\n",
        "        if self.turbulence_bool[self.day] == 0:\n",
        "            min_action = int(self.max_stock * self.min_stock_rate)  # stock_cd\n",
        "            for index in np.where(actions < -min_action)[0]:  # sell_index:\n",
        "                if price[index] > 0:  # Sell only if current asset is > 0\n",
        "                    sell_num_shares = min(self.stocks[index], -actions[index])\n",
        "                    self.stocks[index] -= sell_num_shares\n",
        "                    self.amount += (\n",
        "                        price[index] * sell_num_shares * (1 - self.sell_cost_pct)\n",
        "                    )\n",
        "                    self.stocks_cool_down[index] = 0\n",
        "            for index in np.where(actions > min_action)[0]:  # buy_index:\n",
        "                if (\n",
        "                    price[index] > 0\n",
        "                ):  # Buy only if the price is > 0 (no missing data in this particular date)\n",
        "                    buy_num_shares = min(self.amount // price[index], actions[index])\n",
        "                    self.stocks[index] += buy_num_shares\n",
        "                    self.amount -= (\n",
        "                        price[index] * buy_num_shares * (1 + self.buy_cost_pct)\n",
        "                    )\n",
        "                    self.stocks_cool_down[index] = 0\n",
        "\n",
        "        else:  # sell all when turbulence\n",
        "            self.amount += (self.stocks * price).sum() * (1 - self.sell_cost_pct)\n",
        "            self.stocks[:] = 0\n",
        "            self.stocks_cool_down[:] = 0\n",
        "\n",
        "        state = self.get_state(price)\n",
        "        total_asset = self.amount + (self.stocks * price).sum()\n",
        "        reward = (total_asset - self.total_asset) * self.reward_scaling\n",
        "        self.total_asset = total_asset\n",
        "\n",
        "        self.gamma_reward = self.gamma_reward * self.gamma + reward\n",
        "        done = self.day == self.max_step\n",
        "        if done:\n",
        "            reward = self.gamma_reward\n",
        "            self.episode_return = total_asset / self.initial_total_asset\n",
        "\n",
        "        return state, reward, done, False, dict()\n",
        "\n",
        "    def get_state(self, price):\n",
        "        amount = np.array(self.amount * (2**-12), dtype=np.float32)\n",
        "        scale = np.array(2**-6, dtype=np.float32)\n",
        "        return np.hstack(\n",
        "            (\n",
        "                amount,\n",
        "                self.turbulence_ary[self.day],\n",
        "                self.turbulence_bool[self.day],\n",
        "                price * scale,\n",
        "                self.stocks * scale,\n",
        "                self.stocks_cool_down,\n",
        "                self.tech_ary[self.day],\n",
        "            )\n",
        "        )  # state.astype(np.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid_sign(ary, thresh):\n",
        "        def sigmoid(x):\n",
        "            return 1 / (1 + np.exp(-x * np.e)) - 0.5\n",
        "\n",
        "        return sigmoid(ary / thresh) * thresh"
      ],
      "metadata": {
        "id": "-5o3UE-i_X9Z"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZMkcyjZ-25l"
      },
      "source": [
        "## Calculate the DRL state dimension manually for paper trading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "GLfkTsXK-e90"
      },
      "outputs": [],
      "source": [
        "# amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\n",
        "state_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW0UDAXI1nEa"
      },
      "source": [
        "# Creating Environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A9hq9_BO1Fc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_list = DOW_30_TICKER\n",
        "action_dim = len(DOW_30_TICKER)\n",
        "# amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\n",
        "state_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\n",
        "if_vix = True\n",
        "\n",
        "# Train Data\n",
        "train_price_array, train_tech_array, train_turbulence_array = get_data(TRAIN_START_DATE, TRAIN_END_DATE, if_vix = True)\n",
        "\n",
        "# Test Data\n",
        "test_price_array, test_tech_array, test_turbulence_array = get_data(TEST_START_DATE, TEST_END_DATE, if_vix = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg3dVtHT6hR9",
        "outputId": "146592bf-36b4-4eec-ae89-3bbc5cfd4cc3"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpaca successfully connected\n",
            "Downloading ticker data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/finrl/meta/data_processors/processor_alpaca.py:52: FutureWarning: Timedelta.delta is deprecated and will be removed in a future version.\n",
            "  if pd.Timedelta(time_interval).delta < day_delta:\n",
            "/usr/local/lib/python3.10/site-packages/finrl/meta/data_processors/processor_alpaca.py:52: FutureWarning: Timedelta.delta is deprecated and will be removed in a future version.\n",
            "  if pd.Timedelta(time_interval).delta < day_delta:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpaca successfully connected\n",
            "Downloading ticker data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/finrl/meta/data_processors/processor_alpaca.py:52: FutureWarning: Timedelta.delta is deprecated and will be removed in a future version.\n",
            "  if pd.Timedelta(time_interval).delta < day_delta:\n",
            "/usr/local/lib/python3.10/site-packages/finrl/meta/data_processors/processor_alpaca.py:52: FutureWarning: Timedelta.delta is deprecated and will be removed in a future version.\n",
            "  if pd.Timedelta(time_interval).delta < day_delta:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in range(len(train_turbulence_array)):\n",
        "  count +=1\n",
        "  if count ==390:\n",
        "    count = 0\n",
        "    #train_turbulence_array[i] = 100\n",
        "\n",
        "count =0\n",
        "for i in range(len(test_turbulence_array)):\n",
        "  count +=1\n",
        "  if count ==390:\n",
        "    count = 0  \n",
        "    #test_turbulence_array[i] = 100\n",
        "\n",
        "train_env_config = {\n",
        "    \"price_array\": train_price_array,\n",
        "    \"tech_array\": train_tech_array,\n",
        "    \"turbulence_array\": train_turbulence_array,\n",
        "    \"if_train\": True,\n",
        "}\n",
        "env = StockTradingEnv\n",
        "env_train = StockTradingEnv(config=train_env_config) \n",
        "\n",
        "\n",
        "test_env_config = {\n",
        "        \"price_array\": test_price_array,\n",
        "        \"tech_array\": test_tech_array,\n",
        "        \"turbulence_array\": test_turbulence_array,\n",
        "        \"if_train\": False,\n",
        "    }\n",
        "env_test = StockTradingEnv(config=test_env_config)"
      ],
      "metadata": {
        "id": "yzuAiIs1TF8Y"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_turbulence_array[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SOyh0weTQsH",
        "outputId": "1a20f515-b8af-47de-dbf1-c6baa4293106"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.525"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_ddpg = agent.get_model(\"ddpg\")\n",
        "trained_ddpg = agent.train_model(model=model_ddpg, tb_log_name=\"ddpg\", total_timesteps=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lE3jIiF8TBi",
        "outputId": "91559039-e2d9-43e4-f63d-0d41ff2a5e28"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "environment = env_test\n",
        "state = environment.reset()[0]\n",
        "env_train.max_step\n",
        "episode_returns = []  # the cumulative_return / initial_account\n",
        "episode_total_assets = [environment.initial_total_asset]\n",
        "done = False\n",
        "count = 0\n",
        "while not done:\n",
        "  action = trained_ddpg.predict(state,  deterministic=True)[0]\n",
        "  state, reward, done, _,_= environment.step(action)\n",
        "  total_asset = (\n",
        "                    environment.amount\n",
        "                    + (\n",
        "                        environment.price_ary[environment.day] * environment.stocks\n",
        "                    ).sum()\n",
        "                )\n",
        "  episode_total_assets.append(total_asset)\n",
        "  episode_return = total_asset / environment.initial_total_asset\n",
        "  episode_returns.append(episode_return)\n",
        "  count +=1\n",
        "  if done:\n",
        "      break\n",
        "\n",
        "print(\"end_asset \", round(episode_total_assets[-1]))      \n",
        "print(\"episode_return\", episode_return)\n",
        "print(\"Test Finished!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxvG0yeMPTp1",
        "outputId": "77af934c-1178-4d06-87c5-f405fd465f83"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end_asset  996227\n",
            "episode_return 0.9962271483790472\n",
            "Test Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## install required packages\n",
        "\n",
        "# if True:\n",
        "#     # installing packages\n",
        "#     !pip install swig\n",
        "#     !pip install wrds\n",
        "#     !pip install pyportfolioopt\n",
        "#     !pip install trading_calendars\n",
        "#     !pip install alpaca_trade_api\n",
        "#     !pip install ccxt\n",
        "#     !pip install jqdatasdk\n",
        "\n",
        "#     !pip install lz4\n",
        "#     !pip install tensorboardX\n",
        "#     !pip install gputil\n",
        "#     !pip install pyfolio-reloaded  #original pyfolio no longer maintained\n",
        "#     !pip install optuna\n",
        "#     !pip install plotly\n",
        "#     !pip install ipywidgets\n",
        "#     !pip install -U kaleido"
      ],
      "metadata": {
        "id": "O1Kn_NksSVe0"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna"
      ],
      "metadata": {
        "id": "FFTDCeh6YvS6"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Variables\n",
        "## Fixed\n",
        "tpm_hist = {}  # record tp metric values for trials\n",
        "tp_metric = 'avgwl'  # specified trade_param_metric: ratio avg value win/loss\n",
        "## Settable by User\n",
        "n_trials = 100  # number of HP optimization runs\n",
        "total_timesteps = 2000 # per HP optimization run\n",
        "## Logging callback params\n",
        "lc_threshold=3e-5\n",
        "lc_patience=15\n",
        "lc_trial_number=10"
      ],
      "metadata": {
        "id": "ofgkCsECZGLM"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_ddpg_params_all(trial:optuna.Trial,\n",
        "                           # fixed values from previous study\n",
        "                           learning_rate=0.0103,\n",
        "                           batch_size=128,\n",
        "                           buffer_size=int(1e6)):\n",
        "\n",
        "    buffer_size = trial.suggest_int(\"buffer_size\", int(1e4), int(1e6))\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1)\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 32, 1024)\n",
        "    gamma = trial.suggest_float(\"gamma\", 0.1, 2)\n",
        "    \n",
        "    # Polyak coeff\n",
        "    tau = trial.suggest_float(\"tau\", 1e-5, 1)\n",
        "    \n",
        "    train_freq = trial.suggest_int(\"train_freq\", 64, 2048)\n",
        "    gradient_steps = trial.suggest_int(\"gradient_steps\", 64, 2048)\n",
        "    \n",
        "    #noise_type = trial.suggest_categorical(\"noise_type\", [\"ornstein-uhlenbeck\", \"normal\", None])\n",
        "    #noise_std = trial.suggest_categorical(\"noise_std\", [.0,.1,.2,.3, .4, .5, .6,.8] )\n",
        "\n",
        "    # NOTE: Add \"verybig\" to net_arch when tuning HER (see TD3)\n",
        "    net_arch = trial.suggest_categorical(\"net_arch\", [\"verysmall\",\"small\",\"medium\", \"big\", \"verybig\",\n",
        "                                                      \"same_verysmall\",\"same_small\",\"same_medium\", \"same_big\", \"same_verybig\"])\n",
        "    # activation_fn = trial.suggest_categorical('activation_fn', [nn.Tanh, nn.ReLU, nn.ELU, nn.LeakyReLU])\n",
        "\n",
        "    net_arch = {\n",
        "        \"verysmall\": [64, 32],\n",
        "        \"small\": [128, 64],\n",
        "        \"medium\": [256, 512],\n",
        "        \"big\": [512, 1024],\n",
        "        \"verybig\": [2028, 1024],\n",
        "        \"same_verysmall\": [64, 64],\n",
        "        \"same_small\": [128, 128],\n",
        "        \"same_medium\": [256, 256],\n",
        "        \"same_big\": [512, 512],\n",
        "        \"same_verybig\": [1024, 1024],\n",
        "    }[net_arch]\n",
        "  \n",
        "    hyperparams = {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"buffer_size\": buffer_size,\n",
        "        \"gamma\": gamma,\n",
        "        \"gradient_steps\": gradient_steps,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"tau\": tau,\n",
        "        \"train_freq\": train_freq,\n",
        "        #\"noise_std\": noise_std,\n",
        "        #\"noise_type\": noise_type,\n",
        "        \n",
        "        \"policy_kwargs\": dict(net_arch=net_arch)\n",
        "    }\n",
        "    return hyperparams"
      ],
      "metadata": {
        "id": "hNauvUvc9wvS"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoggingCallback:\n",
        "    def __init__(self,threshold,trial_number,patience):\n",
        "      '''\n",
        "      threshold:int tolerance for increase in objective\n",
        "      trial_number: int Prune after minimum number of trials\n",
        "      patience: int patience for the threshold\n",
        "      '''\n",
        "      self.threshold = threshold\n",
        "      self.trial_number  = trial_number\n",
        "      self.patience = patience\n",
        "      print(f'Callback threshold {self.threshold}, \\\n",
        "            trial_number {self.trial_number}, \\\n",
        "            patience {self.patience}')\n",
        "      self.cb_list = [] #Trials list for which threshold is reached\n",
        "    def __call__(self,study:optuna.study, frozen_trial:optuna.Trial):\n",
        "      #Setting the best value in the current trial\n",
        "      study.set_user_attr(\"previous_best_value\", study.best_value)\n",
        "      \n",
        "      #Checking if the minimum number of trials have pass\n",
        "      if frozen_trial.number >self.trial_number:\n",
        "          previous_best_value = study.user_attrs.get(\"previous_best_value\",None)\n",
        "          #Checking if the previous and current objective values have the same sign\n",
        "          if previous_best_value * study.best_value >=0:\n",
        "              #Checking for the threshold condition\n",
        "              if abs(previous_best_value-study.best_value) < self.threshold: \n",
        "                  self.cb_list.append(frozen_trial.number)\n",
        "                  #If threshold is achieved for the patience amount of time\n",
        "                  if len(self.cb_list)>self.patience:\n",
        "                      print('The study stops now...')\n",
        "                      print('With number',frozen_trial.number ,'and value ',frozen_trial.value)\n",
        "                      print('The previous and current best values are {} and {} respectively'\n",
        "                              .format(previous_best_value, study.best_value))\n",
        "                      study.stop()"
      ],
      "metadata": {
        "id": "9TqnqNHzSsl-"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y0XhST3KZ5f5"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = DRLAgent(env = env_train)"
      ],
      "metadata": {
        "id": "sV22R24zZpNI"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import sys \n",
        "\n",
        "os.makedirs(\"models\",exist_ok=True)\n",
        "\n",
        "def objective(trial:optuna.Trial):\n",
        "  #Trial will suggest a set of hyperparamters from the specified range\n",
        "\n",
        "  # Optional to optimize larger set of parameters\n",
        "  # hyperparameters = sample_ddpg_params_all(trial)\n",
        "  \n",
        "  # Optimize buffer size, batch size, learning rate\n",
        "  hyperparameters = sample_ddpg_params_all(trial)\n",
        "  \n",
        "  print(f'Hyperparameters from objective: {hyperparameters.keys()}')\n",
        "  policy_kwargs = None  # default\n",
        "  if 'policy_kwargs' in hyperparameters.keys():\n",
        "    policy_kwargs = hyperparameters['policy_kwargs']\n",
        "    del hyperparameters['policy_kwargs']\n",
        "    print(f'Policy keyword arguments {policy_kwargs}')\n",
        "  \n",
        "  model_ddpg = agent.get_model(\"ddpg\",\n",
        "                               policy_kwargs = policy_kwargs,\n",
        "                               model_kwargs = hyperparameters )\n",
        "  \n",
        "  #You can increase it for better comparison\n",
        "  trained_ddpg = agent.train_model(model=model_ddpg,\n",
        "                                   tb_log_name=\"ddpg\",\n",
        "                                   total_timesteps=total_timesteps)\n",
        "  trained_ddpg.save('models/ddpg_{}.pth'.format(trial.number))\n",
        "  clear_output(wait=True)\n",
        "  \n",
        "  #For the given hyperparamters, determine the account value in the trading period\n",
        "  environment = env_test\n",
        "  state = environment.reset()[0]\n",
        "  env_train.max_step\n",
        "  episode_returns = []  # the cumulative_return / initial_account\n",
        "  episode_total_assets = [environment.initial_total_asset]\n",
        "  done = False\n",
        "  count = 0\n",
        "  while not done:\n",
        "    action = trained_ddpg.predict(state,  deterministic=True)[0]\n",
        "    state, reward, done, _,_= environment.step(action)\n",
        "    total_asset = (environment.amount + (environment.price_ary[environment.day] * environment.stocks).sum())\n",
        "    episode_total_assets.append(total_asset)\n",
        "    episode_return = total_asset / environment.initial_total_asset\n",
        "    episode_returns.append(episode_return)\n",
        "    count +=1\n",
        "    if done:\n",
        "        break\n",
        "  return episode_return\n",
        "\n",
        "#Create a study object and specify the direction as 'maximize'\n",
        "#As you want to maximize sharpe\n",
        "#Pruner stops not promising iterations\n",
        "#Use a pruner, else you will get error related to divergence of model\n",
        "#You can also use Multivariate samplere\n",
        "#sampler = optuna.samplers.TPESampler(multivarite=True,seed=42)\n",
        "sampler = optuna.samplers.TPESampler()\n",
        "\n",
        "study = optuna.create_study(study_name=\"ddpg_study\",direction='maximize',\n",
        "                            sampler = sampler, pruner=optuna.pruners.HyperbandPruner())\n",
        "\n",
        "logging_callback = LoggingCallback(threshold=lc_threshold,\n",
        "                                   patience=lc_patience,\n",
        "                                   trial_number=lc_trial_number)\n",
        "#You can increase the n_trials for a better search space scanning\n",
        "study.optimize(objective, n_trials=n_trials,catch=(ValueError,),callbacks=[logging_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "KbdmF-RtY2me",
        "outputId": "88da58f8-cbf4-4ba6-996f-4e46842ce636"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-12 21:17:05,668]\u001b[0m A new study created in memory with name: ddpg_study\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Callback threshold 3e-05,             trial_number 10,             patience 15\n",
            "Hyperparameters from objective: dict_keys(['batch_size', 'buffer_size', 'gamma', 'gradient_steps', 'learning_rate', 'tau', 'train_freq', 'policy_kwargs'])\n",
            "Policy keyword arguments {'net_arch': [512, 512]}\n",
            "{'batch_size': 164, 'buffer_size': 619570, 'gamma': 0.266418419784302, 'gradient_steps': 847, 'learning_rate': 0.07509894666748007, 'tau': 0.20401634706527402, 'train_freq': 140}\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m[W 2023-05-12 21:17:52,484]\u001b[0m Trial 0 failed with parameters: {'buffer_size': 619570, 'learning_rate': 0.07509894666748007, 'batch_size': 164, 'gamma': 0.266418419784302, 'tau': 0.20401634706527402, 'train_freq': 140, 'gradient_steps': 847, 'net_arch': 'same_big'} because of the following error: KeyboardInterrupt().\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-223-cd6f01d505e0>\", line 27, in objective\n",
            "    trained_ddpg = agent.train_model(model=model_ddpg,\n",
            "  File \"/usr/local/lib/python3.10/site-packages/finrl/agents/stablebaselines3/models.py\", line 103, in train_model\n",
            "    model = model.learn(\n",
            "  File \"/usr/local/lib/python3.10/site-packages/stable_baselines3/ddpg/ddpg.py\", line 123, in learn\n",
            "    return super().learn(\n",
            "  File \"/usr/local/lib/python3.10/site-packages/stable_baselines3/td3/td3.py\", line 222, in learn\n",
            "    return super().learn(\n",
            "  File \"/usr/local/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py\", line 331, in learn\n",
            "    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)\n",
            "  File \"/usr/local/lib/python3.10/site-packages/stable_baselines3/td3/td3.py\", line 194, in train\n",
            "    actor_loss = -self.critic.q1_forward(replay_data.observations, self.actor(replay_data.observations)).mean()\n",
            "  File \"/usr/local/lib/python3.10/site-packages/stable_baselines3/common/policies.py\", line 947, in q1_forward\n",
            "    return self.q_networks[0](th.cat([features, actions], dim=1))\n",
            "KeyboardInterrupt\n",
            "\u001b[33m[W 2023-05-12 21:17:52,486]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-223-cd6f01d505e0>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m                                    trial_number=lc_trial_number)\n\u001b[1;32m     67\u001b[0m \u001b[0;31m#You can increase the n_trials for a better search space scanning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogging_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-223-cd6f01d505e0>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m#You can increase it for better comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   trained_ddpg = agent.train_model(model=model_ddpg,\n\u001b[0m\u001b[1;32m     28\u001b[0m                                    \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ddpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                    total_timesteps=total_timesteps)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         model = model.learn(\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/ddpg/ddpg.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     ) -> SelfDDPG:\n\u001b[0;32m--> 123\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/td3/td3.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     ) -> SelfTD3:\n\u001b[0;32m--> 222\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/td3/td3.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_updates\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_delay\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;31m# Compute actor loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq1_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m                 \u001b[0mactor_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mq1_forward\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_networks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utils"
      ],
      "metadata": {
        "id": "MLPLRpNKyx6J",
        "outputId": "6d022ef3-0c87-49cd-dbe8-f28ee502baeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "environment.amount"
      ],
      "metadata": {
        "id": "PwKVE2mxvjzY",
        "outputId": "728dbfdb-e930-41e3-f1a8-6f72910d4f53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.068179407005672"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(study, \"final_ddpg_study__.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnUldVPcKDIH",
        "outputId": "245fc0a6-5437-4ca9-a319-2df73d95d1d0"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['final_ddpg_study__.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the best hyperparamters\n",
        "print('Hyperparameters after tuning',study.best_params)\n",
        "print('Hyperparameters before tuning',config.DDPG_PARAMS)"
      ],
      "metadata": {
        "id": "gOQhAnevmsnN",
        "outputId": "5afcd713-c962-4cfc-db35-973d2261d00c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters after tuning {'buffer_size': 404206, 'learning_rate': 0.017906980149605733, 'batch_size': 1021, 'gamma': 1.9889644863918345, 'tau': 0.0065353029388855455, 'train_freq': 1340, 'gradient_steps': 1396, 'net_arch': 'same_big'}\n",
            "Hyperparameters before tuning {'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_trial"
      ],
      "metadata": {
        "id": "GPQwnIuymtBN",
        "outputId": "c3a0eb8d-b7d9-42e5-86d5-8c30e60e4b37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenTrial(number=10, state=TrialState.COMPLETE, values=[0.996522505679407], datetime_start=datetime.datetime(2023, 5, 12, 20, 37, 32, 963740), datetime_complete=datetime.datetime(2023, 5, 12, 20, 37, 56, 781820), params={'buffer_size': 404206, 'learning_rate': 0.017906980149605733, 'batch_size': 1021, 'gamma': 1.9889644863918345, 'tau': 0.0065353029388855455, 'train_freq': 1340, 'gradient_steps': 1396, 'net_arch': 'same_big'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'buffer_size': IntDistribution(high=1000000, log=False, low=10000, step=1), 'learning_rate': FloatDistribution(high=1.0, log=False, low=1e-05, step=None), 'batch_size': IntDistribution(high=1024, log=False, low=32, step=1), 'gamma': FloatDistribution(high=2.0, log=False, low=0.1, step=None), 'tau': FloatDistribution(high=1.0, log=False, low=1e-05, step=None), 'train_freq': IntDistribution(high=2048, log=False, low=64, step=1), 'gradient_steps': IntDistribution(high=2048, log=False, low=64, step=1), 'net_arch': CategoricalDistribution(choices=('verysmall', 'small', 'medium', 'big', 'verybig', 'same_verysmall', 'same_small', 'same_medium', 'same_big', 'same_verybig'))}, trial_id=10, value=None)"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DDPG\n",
        "tuned_model_ddpg = DDPG.load('models/ddpg_{}.pth'.format(study.best_trial.number),env=env_train)"
      ],
      "metadata": {
        "id": "HTHHxLZCmtal",
        "outputId": "978995d5-2d93-4e6c-cd85-32f3f567a02c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "environment = env_test\n",
        "state = environment.reset()[0]\n",
        "env_train.max_step\n",
        "episode_returns = []  # the cumulative_return / initial_account\n",
        "episode_total_assets = [environment.initial_total_asset]\n",
        "done = False\n",
        "count = 0\n",
        "while not done:\n",
        "  action = tuned_model_ddpg.predict(state,  deterministic=True)[0]\n",
        "  print(environment.amount)\n",
        "  state, reward, done, _,_= environment.step(action)\n",
        "  total_asset = (\n",
        "                    environment.amount\n",
        "                    + (\n",
        "                        environment.price_ary[environment.day] * environment.stocks\n",
        "                    ).sum()\n",
        "                )\n",
        "  #print(total_asset)\n",
        "  episode_total_assets.append(total_asset)\n",
        "  episode_return = total_asset / environment.initial_total_asset\n",
        "  episode_returns.append(episode_return)\n",
        "  count +=1\n",
        "  if done:\n",
        "      break\n",
        "episode_return"
      ],
      "metadata": {
        "id": "-BOkcIzfmtzj",
        "outputId": "dbd48d53-d0dd-432b-93c0-88254d4b0967",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000000.0\n",
            "734602.9579565047\n",
            "469277.24800758355\n",
            "203896.30137386307\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n",
            "14.068179407005672\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.996522505679407"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "environment.stocks"
      ],
      "metadata": {
        "id": "zJ8K6-dDmuPS",
        "outputId": "eaeddc40-847e-46e9-8f5f-0cad56b484cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([400., 400.,   0., 400.,   0.,   0., 400., 400.,   0.,   0., 400.,\n",
              "         0., 400., 400.,   0.,   0., 400.,   0.,   0.,   0.,   0., 400.,\n",
              "         0., 389., 300.,   0., 300.,   0., 303., 300.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lArLOFcJ7VMO"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1F84mebj4gu"
      },
      "outputs": [],
      "source": [
        "ERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n",
        "        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,\n",
        "        \"eval_times\":1} \n",
        "env = StockTradingEnv\n",
        "#if you want to use larger datasets (change to longer period), and it raises error, \n",
        "#please try to increase \"target_step\". It should be larger than the episode steps. "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gFErowhTxaqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BxcNI2fdNjip",
        "outputId": "1c54ec9a-a79d-430e-be2c-2614cd391603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpaca successfully connected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/finrl/meta/data_processors/processor_alpaca.py:52: FutureWarning: Timedelta.delta is deprecated and will be removed in a future version.\n",
            "  if pd.Timedelta(time_interval).delta < day_delta:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price of the first row for ticker  AAPL  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  AMGN  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  AXP  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  BA  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  CAT  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  CRM  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  CSCO  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  CVX  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  DIS  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  DOW  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  GS  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  HD  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  HON  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  IBM  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  INTC  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  JNJ  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  JPM  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  KO  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  MCD  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  MMM  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  MRK  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  MSFT  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  NKE  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  PG  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  TRV  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  UNH  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  V  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  VZ  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  WBA  is NaN.  It will filled with the first valid price.\n",
            "The price of the first row for ticker  WMT  is NaN.  It will filled with the first valid price.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/finrl/meta/data_processors/processor_alpaca.py:52: FutureWarning: Timedelta.delta is deprecated and will be removed in a future version.\n",
            "  if pd.Timedelta(time_interval).delta < day_delta:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price of the first row for ticker  VIXY  is NaN.  It will filled with the first valid price.\n",
            "Stock Dimension: 30, State Space: 301\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9d55bb4339a9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(start_date = '2022-08-25', \n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2022-08-31'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mticker_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mticker_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mdata_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'alpaca'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mtime_interval\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'1Min'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-fa1c2e0752de>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(start_date, end_date, ticker_list, data_source, time_interval, technical_indicator_list, drl_lib, env, model_name, if_vix, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m#Instantiate the training gym compatible environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0me_train_gym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStockTradingEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0menv_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0menv_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me_train_gym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sb_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDRLAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/finrl/meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, stock_dim, hmax, initial_amount, num_stock_shares, buy_cost_pct, sell_cost_pct, reward_scaling, state_space, action_space, tech_indicator_list, turbulence_threshold, risk_indicator_col, make_plots, print_verbosity, day, initial, previous_state, model_name, mode, iteration)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# initalize state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initiate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# initialize reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/site-packages/finrl/meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36m_initiate_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 state = (\n\u001b[1;32m    403\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_amount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                     \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m                     \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_stock_shares\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                     + sum(\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'values'"
          ]
        }
      ],
      "source": [
        "train(start_date = '2022-08-25', \n",
        "      end_date = '2022-08-31',\n",
        "      ticker_list = ticker_list, \n",
        "      data_source = 'alpaca',\n",
        "      time_interval= '1Min', \n",
        "      technical_indicator_list= INDICATORS,\n",
        "      drl_lib='elegantrl', \n",
        "      env=env,\n",
        "      model_name='ppo',\n",
        "      if_vix=True, \n",
        "      API_KEY = API_KEY, \n",
        "      API_SECRET = API_SECRET, \n",
        "      API_BASE_URL = API_BASE_URL,\n",
        "      erl_params=ERL_PARAMS,\n",
        "      cwd='./papertrading_erl', #current_working_dir\n",
        "      break_step=1e5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g37WugV_1pAS"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxYoWCDa02TW"
      },
      "outputs": [],
      "source": [
        "account_value_erl=test(start_date = '2022-09-01', \n",
        "                      end_date = '2022-09-02',\n",
        "                      ticker_list = ticker_list, \n",
        "                      data_source = 'alpaca',\n",
        "                      time_interval= '1Min', \n",
        "                      technical_indicator_list= INDICATORS,\n",
        "                      drl_lib='elegantrl', \n",
        "                      env=env, \n",
        "                      model_name='ppo',\n",
        "                      if_vix=True, \n",
        "                      API_KEY = API_KEY, \n",
        "                      API_SECRET = API_SECRET, \n",
        "                      API_BASE_URL = API_BASE_URL,\n",
        "                      cwd='./papertrading_erl',\n",
        "                      net_dimension = ERL_PARAMS['net_dimension'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iY_E8SiEwZhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8aNQ58X7avM"
      },
      "source": [
        "## Use full data to train "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CQ9_Yv41r88"
      },
      "source": [
        "After tuning well, retrain on the training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUSgbwt_10V3"
      },
      "outputs": [],
      "source": [
        "train(start_date = '2022-08-25', \n",
        "      end_date = '2022-09-02',\n",
        "      ticker_list = ticker_list, \n",
        "      data_source = 'alpaca',\n",
        "      time_interval= '1Min', \n",
        "      technical_indicator_list= INDICATORS,\n",
        "      drl_lib='elegantrl', \n",
        "      env=env, \n",
        "      model_name='ppo',\n",
        "      if_vix=True, \n",
        "      API_KEY = API_KEY, \n",
        "      API_SECRET = API_SECRET, \n",
        "      API_BASE_URL = API_BASE_URL,\n",
        "      erl_params=ERL_PARAMS,\n",
        "      cwd='./papertrading_erl_retrain',\n",
        "      break_step=2e5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIQN6Ggt7gXY"
      },
      "source": [
        "# Part 3: Deploy the agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFoxkigg1zXa"
      },
      "source": [
        "## Setup Alpaca Paper trading environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpkoZpYzfneS"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import threading\n",
        "from finrl.meta.data_processors.processor_alpaca import AlpacaProcessor\n",
        "import alpaca_trade_api as tradeapi\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import gym\n",
        "\n",
        "class AlpacaPaperTrading():\n",
        "\n",
        "    def __init__(self,ticker_list, time_interval, drl_lib, agent, cwd, net_dim, \n",
        "                 state_dim, action_dim, API_KEY, API_SECRET, \n",
        "                 API_BASE_URL, tech_indicator_list, turbulence_thresh=30, \n",
        "                 max_stock=1e2, latency = None):\n",
        "        #load agent\n",
        "        self.drl_lib = drl_lib\n",
        "        if agent =='ppo':\n",
        "            if drl_lib == 'elegantrl':              \n",
        "                agent_class = AgentPPO\n",
        "                agent = agent_class(net_dim, state_dim, action_dim)\n",
        "                actor = agent.act\n",
        "                # load agent\n",
        "                try:  \n",
        "                    cwd = cwd + '/actor.pth'\n",
        "                    print(f\"| load actor from: {cwd}\")\n",
        "                    actor.load_state_dict(torch.load(cwd, map_location=lambda storage, loc: storage))\n",
        "                    self.act = actor\n",
        "                    self.device = agent.device\n",
        "                except BaseException:\n",
        "                    raise ValueError(\"Fail to load agent!\")\n",
        "                        \n",
        "            elif drl_lib == 'rllib':\n",
        "                from ray.rllib.agents import ppo\n",
        "                from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
        "                \n",
        "                config = ppo.DEFAULT_CONFIG.copy()\n",
        "                config['env'] = StockEnvEmpty\n",
        "                config[\"log_level\"] = \"WARN\"\n",
        "                config['env_config'] = {'state_dim':state_dim,\n",
        "                            'action_dim':action_dim,}\n",
        "                trainer = PPOTrainer(env=StockEnvEmpty, config=config)\n",
        "                trainer.restore(cwd)\n",
        "                try:\n",
        "                    trainer.restore(cwd)\n",
        "                    self.agent = trainer\n",
        "                    print(\"Restoring from checkpoint path\", cwd)\n",
        "                except:\n",
        "                    raise ValueError('Fail to load agent!')\n",
        "                    \n",
        "            elif drl_lib == 'stable_baselines3':\n",
        "                from stable_baselines3 import PPO\n",
        "                \n",
        "                try:\n",
        "                    #load agent\n",
        "                    self.model = PPO.load(cwd)\n",
        "                    print(\"Successfully load model\", cwd)\n",
        "                except:\n",
        "                    raise ValueError('Fail to load agent!')\n",
        "                    \n",
        "            else:\n",
        "                raise ValueError('The DRL library input is NOT supported yet. Please check your input.')\n",
        "               \n",
        "        else:\n",
        "            raise ValueError('Agent input is NOT supported yet.')\n",
        "            \n",
        "            \n",
        "            \n",
        "        #connect to Alpaca trading API\n",
        "        try:\n",
        "            self.alpaca = tradeapi.REST(API_KEY,API_SECRET,API_BASE_URL, 'v2')\n",
        "        except:\n",
        "            raise ValueError('Fail to connect Alpaca. Please check account info and internet connection.')\n",
        "        \n",
        "        #read trading time interval\n",
        "        if time_interval == '1s':\n",
        "            self.time_interval = 1\n",
        "        elif time_interval == '5s':\n",
        "            self.time_interval = 5\n",
        "        elif time_interval == '1Min':\n",
        "            self.time_interval = 60\n",
        "        elif time_interval == '5Min':\n",
        "            self.time_interval = 60 * 5\n",
        "        elif time_interval == '15Min':\n",
        "            self.time_interval = 60 * 15\n",
        "        else:\n",
        "            raise ValueError('Time interval input is NOT supported yet.')\n",
        "        \n",
        "        #read trading settings\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "        self.turbulence_thresh = turbulence_thresh\n",
        "        self.max_stock = max_stock \n",
        "        \n",
        "        #initialize account\n",
        "        self.stocks = np.asarray([0] * len(ticker_list)) #stocks holding\n",
        "        self.stocks_cd = np.zeros_like(self.stocks) \n",
        "        self.cash = None #cash record \n",
        "        self.stocks_df = pd.DataFrame(self.stocks, columns=['stocks'], index = ticker_list)\n",
        "        self.asset_list = []\n",
        "        self.price = np.asarray([0] * len(ticker_list))\n",
        "        self.stockUniverse = ticker_list\n",
        "        self.turbulence_bool = 0\n",
        "        self.equities = []\n",
        "        \n",
        "    def test_latency(self, test_times = 10): \n",
        "        total_time = 0\n",
        "        for i in range(0, test_times):\n",
        "            time0 = time.time()\n",
        "            self.get_state()\n",
        "            time1 = time.time()\n",
        "            temp_time = time1 - time0\n",
        "            total_time += temp_time\n",
        "        latency = total_time/test_times\n",
        "        print('latency for data processing: ', latency)\n",
        "        return latency\n",
        "        \n",
        "    def run(self):\n",
        "        orders = self.alpaca.list_orders(status=\"open\")\n",
        "        for order in orders:\n",
        "          self.alpaca.cancel_order(order.id)\n",
        "    \n",
        "        # Wait for market to open.\n",
        "        print(\"Waiting for market to open...\")\n",
        "        tAMO = threading.Thread(target=self.awaitMarketOpen)\n",
        "        tAMO.start()\n",
        "        tAMO.join()\n",
        "        print(\"Market opened.\")\n",
        "        while True:\n",
        "\n",
        "          # Figure out when the market will close so we can prepare to sell beforehand.\n",
        "          clock = self.alpaca.get_clock()\n",
        "          closingTime = clock.next_close.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "          currTime = clock.timestamp.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "          self.timeToClose = closingTime - currTime\n",
        "    \n",
        "          if(self.timeToClose < (60)):\n",
        "            # Close all positions when 1 minutes til market close.\n",
        "            print(\"Market closing soon. Stop trading.\")\n",
        "            break\n",
        "            \n",
        "            '''# Close all positions when 1 minutes til market close.\n",
        "            print(\"Market closing soon.  Closing positions.\")\n",
        "    \n",
        "            positions = self.alpaca.list_positions()\n",
        "            for position in positions:\n",
        "              if(position.side == 'long'):\n",
        "                orderSide = 'sell'\n",
        "              else:\n",
        "                orderSide = 'buy'\n",
        "              qty = abs(int(float(position.qty)))\n",
        "              respSO = []\n",
        "              tSubmitOrder = threading.Thread(target=self.submitOrder(qty, position.symbol, orderSide, respSO))\n",
        "              tSubmitOrder.start()\n",
        "              tSubmitOrder.join()\n",
        "    \n",
        "            # Run script again after market close for next trading day.\n",
        "            print(\"Sleeping until market close (15 minutes).\")\n",
        "            time.sleep(60 * 15)'''\n",
        "            \n",
        "          else:\n",
        "            trade = threading.Thread(target=self.trade)\n",
        "            trade.start()\n",
        "            trade.join()\n",
        "            last_equity = float(self.alpaca.get_account().last_equity)\n",
        "            cur_time = time.time()\n",
        "            self.equities.append([cur_time,last_equity])\n",
        "            time.sleep(self.time_interval)\n",
        "            \n",
        "    def awaitMarketOpen(self):\n",
        "        isOpen = self.alpaca.get_clock().is_open\n",
        "        while(not isOpen):\n",
        "          clock = self.alpaca.get_clock()\n",
        "          openingTime = clock.next_open.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "          currTime = clock.timestamp.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "          timeToOpen = int((openingTime - currTime) / 60)\n",
        "          print(str(timeToOpen) + \" minutes til market open.\")\n",
        "          time.sleep(60)\n",
        "          isOpen = self.alpaca.get_clock().is_open\n",
        "    \n",
        "    def trade(self):\n",
        "        state = self.get_state()\n",
        "        \n",
        "        if self.drl_lib == 'elegantrl':\n",
        "            with torch.no_grad():\n",
        "                s_tensor = torch.as_tensor((state,), device=self.device)\n",
        "                a_tensor = self.act(s_tensor)  \n",
        "                action = a_tensor.detach().cpu().numpy()[0]  \n",
        "            action = (action * self.max_stock).astype(int)\n",
        "            \n",
        "        elif self.drl_lib == 'rllib':\n",
        "            action = self.agent.compute_single_action(state)\n",
        "        \n",
        "        elif self.drl_lib == 'stable_baselines3':\n",
        "            action = self.model.predict(state)[0]\n",
        "            \n",
        "        else:\n",
        "            raise ValueError('The DRL library input is NOT supported yet. Please check your input.')\n",
        "        \n",
        "        self.stocks_cd += 1\n",
        "        if self.turbulence_bool == 0:\n",
        "            min_action = 10  # stock_cd\n",
        "            for index in np.where(action < -min_action)[0]:  # sell_index:\n",
        "                sell_num_shares = min(self.stocks[index], -action[index])\n",
        "                qty =  abs(int(sell_num_shares))\n",
        "                respSO = []\n",
        "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, self.stockUniverse[index], 'sell', respSO))\n",
        "                tSubmitOrder.start()\n",
        "                tSubmitOrder.join()\n",
        "                self.cash = float(self.alpaca.get_account().cash)\n",
        "                self.stocks_cd[index] = 0\n",
        "\n",
        "            for index in np.where(action > min_action)[0]:  # buy_index:\n",
        "                if self.cash < 0:\n",
        "                    tmp_cash = 0\n",
        "                else:\n",
        "                    tmp_cash = self.cash\n",
        "                buy_num_shares = min(tmp_cash // self.price[index], abs(int(action[index])))\n",
        "                if (buy_num_shares != buy_num_shares): # if buy_num_change = nan\n",
        "                    qty = 0 # set to 0 quantity\n",
        "                else:\n",
        "                    qty = abs(int(buy_num_shares))\n",
        "                qty = abs(int(buy_num_shares))\n",
        "                respSO = []\n",
        "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, self.stockUniverse[index], 'buy', respSO))\n",
        "                tSubmitOrder.start()\n",
        "                tSubmitOrder.join()\n",
        "                self.cash = float(self.alpaca.get_account().cash)\n",
        "                self.stocks_cd[index] = 0\n",
        "                \n",
        "        else:  # sell all when turbulence\n",
        "            positions = self.alpaca.list_positions()\n",
        "            for position in positions:\n",
        "                if(position.side == 'long'):\n",
        "                    orderSide = 'sell'\n",
        "                else:\n",
        "                    orderSide = 'buy'\n",
        "                qty = abs(int(float(position.qty)))\n",
        "                respSO = []\n",
        "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, position.symbol, orderSide, respSO))\n",
        "                tSubmitOrder.start()\n",
        "                tSubmitOrder.join()\n",
        "            \n",
        "            self.stocks_cd[:] = 0\n",
        "            \n",
        "    \n",
        "    def get_state(self):\n",
        "        alpaca = AlpacaProcessor(api=self.alpaca)\n",
        "        price, tech, turbulence = alpaca.fetch_latest_data(ticker_list = self.stockUniverse, time_interval='1Min',\n",
        "                                                     tech_indicator_list=self.tech_indicator_list)\n",
        "        turbulence_bool = 1 if turbulence >= self.turbulence_thresh else 0\n",
        "        \n",
        "        turbulence = (self.sigmoid_sign(turbulence, self.turbulence_thresh) * 2 ** -5).astype(np.float32)\n",
        "        \n",
        "        tech = tech * 2 ** -7\n",
        "        positions = self.alpaca.list_positions()\n",
        "        stocks = [0] * len(self.stockUniverse)\n",
        "        for position in positions:\n",
        "            ind = self.stockUniverse.index(position.symbol)\n",
        "            stocks[ind] = ( abs(int(float(position.qty))))\n",
        "        \n",
        "        stocks = np.asarray(stocks, dtype = float)\n",
        "        cash = float(self.alpaca.get_account().cash)\n",
        "        self.cash = cash\n",
        "        self.stocks = stocks\n",
        "        self.turbulence_bool = turbulence_bool \n",
        "        self.price = price\n",
        "        \n",
        "        \n",
        "        \n",
        "        amount = np.array(self.cash * (2 ** -12), dtype=np.float32)\n",
        "        scale = np.array(2 ** -6, dtype=np.float32)\n",
        "        state = np.hstack((amount,\n",
        "                    turbulence,\n",
        "                    self.turbulence_bool,\n",
        "                    price * scale,\n",
        "                    self.stocks * scale,\n",
        "                    self.stocks_cd,\n",
        "                    tech,\n",
        "                    )).astype(np.float32)\n",
        "        state[np.isnan(state)] = 0.0\n",
        "        state[np.isinf(state)] = 0.0\n",
        "        print(len(self.stockUniverse))\n",
        "        return state\n",
        "        \n",
        "    def submitOrder(self, qty, stock, side, resp):\n",
        "        if(qty > 0):\n",
        "          try:\n",
        "            self.alpaca.submit_order(stock, qty, side, \"market\", \"day\")\n",
        "            print(\"Market order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | completed.\")\n",
        "            resp.append(True)\n",
        "          except:\n",
        "            print(\"Order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | did not go through.\")\n",
        "            resp.append(False)\n",
        "        else:\n",
        "          print(\"Quantity is 0, order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | not completed.\")\n",
        "          resp.append(True)\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid_sign(ary, thresh):\n",
        "        def sigmoid(x):\n",
        "            return 1 / (1 + np.exp(-x * np.e)) - 0.5\n",
        "\n",
        "        return sigmoid(ary / thresh) * thresh\n",
        "    \n",
        "class StockEnvEmpty(gym.Env):\n",
        "    #Empty Env used for loading rllib agent\n",
        "    def __init__(self,config):\n",
        "      state_dim = config['state_dim']\n",
        "      action_dim = config['action_dim']\n",
        "      self.env_num = 1\n",
        "      self.max_step = 10000\n",
        "      self.env_name = 'StockEnvEmpty'\n",
        "      self.state_dim = state_dim  \n",
        "      self.action_dim = action_dim\n",
        "      self.if_discrete = False  \n",
        "      self.target_return = 9999\n",
        "      self.observation_space = gym.spaces.Box(low=-3000, high=3000, shape=(state_dim,), dtype=np.float32)\n",
        "      self.action_space = gym.spaces.Box(low=-1, high=1, shape=(action_dim,), dtype=np.float32)\n",
        "        \n",
        "    def reset(self):\n",
        "        return \n",
        "\n",
        "    def step(self, actions):\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os4C4-4H7ns7"
      },
      "source": [
        "## Run Paper trading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nw0i-0UN3-7"
      },
      "outputs": [],
      "source": [
        "print(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsSBK9ION1t6"
      },
      "outputs": [],
      "source": [
        "state_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYtSv6P1N247"
      },
      "outputs": [],
      "source": [
        "action_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl9nulnAJtiI"
      },
      "outputs": [],
      "source": [
        "paper_trading_erl = AlpacaPaperTrading(ticker_list = DOW_30_TICKER, \n",
        "                                       time_interval = '1Min', \n",
        "                                       drl_lib = 'elegantrl', \n",
        "                                       agent = 'ppo', \n",
        "                                       cwd = './papertrading_erl_retrain', \n",
        "                                       net_dim = ERL_PARAMS['net_dimension'], \n",
        "                                       state_dim = state_dim, \n",
        "                                       action_dim= action_dim, \n",
        "                                       API_KEY = API_KEY, \n",
        "                                       API_SECRET = API_SECRET, \n",
        "                                       API_BASE_URL = API_BASE_URL, \n",
        "                                       tech_indicator_list = INDICATORS, \n",
        "                                       turbulence_thresh=30, \n",
        "                                       max_stock=1e2)\n",
        "paper_trading_erl.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srzBZfYEUI1O"
      },
      "source": [
        "# Part 4: Check Portfolio Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chovN1UhTAht"
      },
      "outputs": [],
      "source": [
        "import alpaca_trade_api as tradeapi\n",
        "import exchange_calendars as tc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytz\n",
        "import yfinance as yf\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.dates as mdates\n",
        "from datetime import datetime as dt\n",
        "from finrl.plot import backtest_stats\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaofxMNCfAR1"
      },
      "outputs": [],
      "source": [
        "def get_trading_days(start, end):\n",
        "    nyse = tc.get_calendar('NYSE')\n",
        "    df = nyse.sessions_in_range(pd.Timestamp(start,tz=pytz.UTC),\n",
        "                                pd.Timestamp(end,tz=pytz.UTC))\n",
        "    trading_days = []\n",
        "    for day in df:\n",
        "        trading_days.append(str(day)[:10])\n",
        "\n",
        "    return trading_days\n",
        "\n",
        "def alpaca_history(key, secret, url, start, end):\n",
        "    api = tradeapi.REST(key, secret, url, 'v2')\n",
        "    trading_days = get_trading_days(start, end)\n",
        "    df = pd.DataFrame()\n",
        "    for day in trading_days:\n",
        "        df = df.append(api.get_portfolio_history(date_start = day,timeframe='5Min').df.iloc[:78])\n",
        "    equities = df.equity.values\n",
        "    cumu_returns = equities/equities[0]\n",
        "    cumu_returns = cumu_returns[~np.isnan(cumu_returns)]\n",
        "    \n",
        "    return df, cumu_returns\n",
        "\n",
        "def DIA_history(start):\n",
        "    data_df = yf.download(['^DJI'],start=start, interval=\"5m\")\n",
        "    data_df = data_df.iloc[:]\n",
        "    baseline_returns = data_df['Adj Close'].values/data_df['Adj Close'].values[0]\n",
        "    return data_df, baseline_returns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CHiZRVpURpx"
      },
      "source": [
        "## Get cumulative return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hmmo-iG1s_rd"
      },
      "outputs": [],
      "source": [
        "API_KEY = \"\"\n",
        "API_SECRET = \"\"\n",
        "API_BASE_URL = 'https://paper-api.alpaca.markets'\n",
        "data_url = 'wss://data.alpaca.markets'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_YT7v-LSdfV"
      },
      "outputs": [],
      "source": [
        "df_erl, cumu_erl = alpaca_history(key=API_KEY, \n",
        "                                  secret=API_SECRET, \n",
        "                                  url=API_BASE_URL, \n",
        "                                  start='2022-09-01', #must be within 1 month\n",
        "                                  end='2022-09-12') #change the date if error occurs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMcQjwHOS6Zb"
      },
      "outputs": [],
      "source": [
        "df_djia, cumu_djia = DIA_history(start='2022-09-01')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJXPwmx9Ts5o"
      },
      "outputs": [],
      "source": [
        "df_erl.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1Iaw90FTNfU"
      },
      "outputs": [],
      "source": [
        "returns_erl = cumu_erl -1 \n",
        "returns_dia = cumu_djia - 1\n",
        "returns_dia = returns_dia[:returns_erl.shape[0]]\n",
        "print('len of erl return: ', returns_erl.shape[0])\n",
        "print('len of dia return: ', returns_dia.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IawaMsDwZni"
      },
      "outputs": [],
      "source": [
        "returns_erl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z0LEm7KUZ5W"
      },
      "source": [
        "## plot and save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Foqk1wIQTQJ3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(dpi=1000)\n",
        "plt.grid()\n",
        "plt.grid(which='minor', axis='y')\n",
        "plt.title('Stock Trading (Paper trading)', fontsize=20)\n",
        "plt.plot(returns_erl, label = 'ElegantRL Agent', color = 'red')\n",
        "#plt.plot(returns_sb3, label = 'Stable-Baselines3 Agent', color = 'blue' )\n",
        "#plt.plot(returns_rllib, label = 'RLlib Agent', color = 'green')\n",
        "plt.plot(returns_dia, label = 'DJIA', color = 'grey')\n",
        "plt.ylabel('Return', fontsize=16)\n",
        "plt.xlabel('Year 2021', fontsize=16)\n",
        "plt.xticks(size = 14)\n",
        "plt.yticks(size = 14)\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(78))\n",
        "ax.xaxis.set_minor_locator(ticker.MultipleLocator(6))\n",
        "ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\n",
        "ax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\n",
        "ax.xaxis.set_major_formatter(ticker.FixedFormatter(['','10-19','','10-20',\n",
        "                                                    '','10-21','','10-22']))\n",
        "plt.legend(fontsize=10.5)\n",
        "plt.savefig('papertrading_stock.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TxWDkdzkuEEI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0EVJIQUR6_fu",
        "9tzAw9k26nAC",
        "zjLda8No6pvI",
        "pf5aVHAU-xF6",
        "rZMkcyjZ-25l",
        "3rwy7V72-8YY",
        "J25MuZLiGqCP",
        "eW0UDAXI1nEa",
        "UFoxkigg1zXa"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "005d14239094016f48a03a57365c4ccb734e3f38c20ed0ca595d84f773bc39cd"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}