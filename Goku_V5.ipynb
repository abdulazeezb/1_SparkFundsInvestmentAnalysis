{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulazeezb/1_SparkFundsInvestmentAnalysis/blob/master/Goku_V5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking GPU Version"
      ],
      "metadata": {
        "id": "NAjscLW7Sk9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "t8nxH9ZvSaY6",
        "outputId": "639a9340-4954-481e-8733-fba793f02e51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 27 19:48:32 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "KEPzY7qCS2Lc",
        "outputId": "312fc4cb-9d91-419e-b130-9354bee0dd78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Part 1: Getting Started - Install Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23TOba33L4qf",
        "outputId": "0a861c19-0c68-4838-e71c-105d30d6d4f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wrds\n",
            "  Downloading wrds-3.1.6-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from wrds) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from wrds) (1.10.1)\n",
            "Collecting sqlalchemy<2\n",
            "  Downloading SQLAlchemy-1.4.47-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from wrds) (1.5.3)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2->wrds) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->wrds) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\n",
            "Installing collected packages: sqlalchemy, psycopg2-binary, wrds\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.10\n",
            "    Uninstalling SQLAlchemy-2.0.10:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.10\n",
            "Successfully installed psycopg2-binary-2.9.6 sqlalchemy-1.4.47 wrds-3.1.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting swig\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "竢ｬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "沒ｦ Installing...\n",
            "沒 Adjusting configuration...\n",
            "洸ｹ Patching environment...\n",
            "竢ｲ Done in 0:00:11\n",
            "沐 Restarting kernel...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "(Reading database ... 122519 files and directories currently installed.)\n",
            "Preparing to unpack .../libgl1-mesa-glx_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Selecting previously unselected package swig4.0.\n",
            "Preparing to unpack .../swig4.0_4.0.1-5build1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.1-5build1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.1-5build1_all.deb ...\n",
            "Unpacking swig (4.0.1-5build1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Setting up swig4.0 (4.0.1-5build1) ...\n",
            "Setting up swig (4.0.1-5build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ],
      "source": [
        "## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ],
      "metadata": {
        "id": "haJsmd15TCdH",
        "outputId": "71ce3935-e3f2-4821-d467-130ae54351ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-q7awp_i1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-q7awp_i1\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 8a75a4bbb28f86f88ee2d4bd9a8c19cce444badb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-ucfb07xn/elegantrl_777a9161401c4d70b3b2a2b1e27a8670\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-ucfb07xn/elegantrl_777a9161401c4d70b3b2a2b1e27a8670\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit b974a806e6235f59055c954418e54640fa549331\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-ucfb07xn/pyfolio_d3af745a51db4bb59ebc602a0650d30d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/quantopian/pyfolio.git /tmp/pip-install-ucfb07xn/pyfolio_d3af745a51db4bb59ebc602a0650d30d\n",
            "  Resolved https://github.com/quantopian/pyfolio.git to commit 4b901f6d73aa02ceb6d04b7d83502e5c6f2e81aa\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gym>=0.17\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stable-baselines3<2.0.0,>=1.6.2\n",
            "  Downloading stable_baselines3-1.8.0-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrds>=3.1.6\n",
            "  Using cached wrds-3.1.6-py3-none-any.whl (12 kB)\n",
            "Collecting importlib-metadata==4.13.0\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stockstats>=0.4.0\n",
            "  Downloading stockstats-0.5.2-py2.py3-none-any.whl (20 kB)\n",
            "Collecting ray[default,tune]>=2.0.0\n",
            "  Downloading ray-2.4.0-cp39-cp39-manylinux2014_x86_64.whl (58.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=1.1.5\n",
            "  Downloading pandas-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lz4\n",
            "  Downloading lz4-4.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=0.21.0\n",
            "  Downloading scikit_learn-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.17.3\n",
            "  Downloading numpy-1.24.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jqdatasdk\n",
            "  Downloading jqdatasdk-1.8.11-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m158.2/158.2 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting exchange_calendars==3.6.3\n",
            "  Downloading exchange_calendars-3.6.3.tar.gz (152 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.2.18-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ccxt>=1.66.32\n",
            "  Downloading ccxt-3.0.80-py2.py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alpaca_trade_api>=2.1.0\n",
            "  Downloading alpaca_trade_api-3.0.0-py3-none-any.whl (33 kB)\n",
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyluach\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting python-dateutil\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toolz in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.12.0)\n",
            "Collecting korean_lunar_calendar\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting aiohttp==3.8.1\n",
            "  Downloading aiohttp-3.8.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11,>=9.0\n",
            "  Downloading websockets-10.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecation==2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting websocket-client<2,>=0.56.0\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>2 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.28.2)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.26.15)\n",
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m661.8/661.8 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msgpack==1.0.3\n",
            "  Downloading msgpack-1.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.1.1)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs>=17.3.0\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (65.6.3)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (2022.12.7)\n",
            "Collecting aiodns>=1.1.1\n",
            "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (39.0.2)\n",
            "Collecting gym-notices>=0.0.4\n",
            "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Collecting cloudpickle>=1.2.0\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Collecting tzdata>=2022.1\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click>=7.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf!=3.19.5,>=3.15.3\n",
            "  Downloading protobuf-4.22.3-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting virtualenv<20.21.1,>=20.0.24\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
            "Collecting grpcio<=1.51.3,>=1.32.0\n",
            "  Downloading grpcio-1.51.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tabulate\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-1.10.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencensus\n",
            "  Downloading opencensus-0.11.2-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpustat>=1.0.0\n",
            "  Downloading gpustat-1.1.tar.gz (97 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting prometheus-client>=0.7.1\n",
            "  Downloading prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m122.5/122.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open\n",
            "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorful\n",
            "  Downloading colorful-0.5.5-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.1.1\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.3.2\n",
            "  Downloading scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting torch>=1.11\n",
            "  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gym>=0.17\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf!=3.19.5,>=3.15.3\n",
            "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy<2\n",
            "  Downloading SQLAlchemy-1.4.47-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting thriftpy2>=0.3.9\n",
            "  Downloading thriftpy2-0.4.16.tar.gz (643 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m643.4/643.4 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymysql>=0.7.6\n",
            "  Downloading PyMySQL-1.0.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting importlib-resources>=3.2.0\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m299.7/299.7 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython>=3.2.3\n",
            "  Downloading ipython-8.12.0-py3-none-any.whl (796 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m796.4/796.4 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seaborn>=0.7.1\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting empyrical>=0.5.0\n",
            "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting html5lib>=1.1\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozendict>=2.3.4\n",
            "  Downloading frozendict-2.3.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m114.3/114.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beautifulsoup4>=4.11.1\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs>=1.4.4\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting multitasking>=0.0.7\n",
            "  Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
            "Collecting lxml>=4.9.1\n",
            "  Downloading lxml-4.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycares>=4.0.0\n",
            "  Downloading pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/site-packages (from cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (1.15.1)\n",
            "Collecting pandas-datareader>=0.2\n",
            "  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil>=5.6.0\n",
            "  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m282.1/282.1 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blessed>=1.17.1\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-ml-py>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.525.112-py3-none-any.whl (35 kB)\n",
            "Collecting webencodings\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting stack-data\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30\n",
            "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting typing-extensions\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting traitlets>=5\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pygments>=2.4.0\n",
            "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api>=2.1.0->finrl==0.3.5) (3.4)\n",
            "Collecting greenlet!=0.4.17\n",
            "  Downloading greenlet-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (610 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m610.9/610.9 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ply<4.0,>=3.4\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy\n",
            "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (0.38.4)\n",
            "Collecting cmake\n",
            "  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lit\n",
            "  Downloading lit-16.0.2.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting platformdirs<4,>=2.4\n",
            "  Downloading platformdirs-3.5.0-py3-none-any.whl (15 kB)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gym[box2d]\n",
            "  Downloading gym-0.26.1.tar.gz (719 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m719.9/719.9 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.26.0.tar.gz (710 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m710.3/710.3 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.25.2.tar.gz (734 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m734.5/734.5 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.25.1.tar.gz (732 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m732.2/732.2 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.25.0.tar.gz (720 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.24.1.tar.gz (696 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m696.4/696.4 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.24.0.tar.gz (694 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m694.4/694.4 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.22.0.tar.gz (631 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting box2d-py==2.3.5\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyglet>=1.4.0\n",
            "  Downloading pyglet-2.0.5-py3-none-any.whl (831 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m831.3/831.3 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-core<3.0.0,>=1.0.0\n",
            "  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencensus-context>=0.1.3\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting wcwidth>=0.1.4\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (2.21)\n",
            "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<3.0dev,>=2.14.1\n",
            "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting executing>=1.2.0\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6\n",
            "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: finrl, exchange_calendars, gym, elegantrl, gputil, pyfolio, empyrical, gpustat, thriftpy2, box2d-py, lit\n",
            "  Building wheel for finrl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.5-py3-none-any.whl size=4668722 sha256=b5d9990feddfce4dac1109677bd1616fcf78abb54bcf1b30c280638a7696b8d0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1sktyqjp/wheels/ec/6a/08/c43694890a7c5a62c23af4b2a497bce5ee7edef607852cf53f\n",
            "  Building wheel for exchange_calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for exchange_calendars: filename=exchange_calendars-3.6.3-py3-none-any.whl size=182636 sha256=8eb0edb33e032bf90729df3eaff20a9fdd025ab3a58ba6bc769e59c46ab4a833\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/02/f9/6c6eeb48a242879e357caf2813953fa8b6e26bd0110bd94226\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616823 sha256=a95b8731b34f25ea92adb6a0cb8c2a31904f72ea05510fdc5fd5b144708a7e1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/50/6c/0a82c1358b4da2dbd9c1bb17e0f89467db32812ab236dbf6d5\n",
            "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elegantrl: filename=elegantrl-0.3.6-py3-none-any.whl size=195067 sha256=92c0c84785c0aa39a87d7280136dc48e11e2c257bab0595c0f287ecf37854067\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1sktyqjp/wheels/a3/c3/be/03eb1f20c8650f23ab13b823d93a297a917899f5d08b04b7b9\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7409 sha256=a0b427c42cafcc7d1b075f77583b06b344143e05369102289f8f6ff7f24a67e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/b5/24/fbb56595c286984f7315ee31821d6121e1b9828436021a88b3\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75773 sha256=7b05ac9ad25b5b5c746ededee1efcaeb23546f3f105fb95f5a310a0ae6a94290\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1sktyqjp/wheels/da/0d/dd/aef7001cc1238aff04ec9eabfc002341f00c50deead3083855\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39776 sha256=26f5d191fad3d1233c8432263ada7be2deefa39b67249cac0c349f9d05c3b055\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/23/d1/a4ef8ff88dc9af7b0eeb1b6fd0d90c6057eaad5a2df25f4e3f\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1-py3-none-any.whl size=26298 sha256=b5a5b0534fa4ec6fc428e2d31c28d556a2f1a2b771a00bedd09e264c506d9def\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/f0/b3/8566d6821307110981a5db015cbf8fd88697446f81e5f40a27\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.4.16-cp39-cp39-linux_x86_64.whl size=529342 sha256=fa096b829b982d1482361f22282ddd019ce62a5f1ddffedb0803aeade23c48a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/a4/d5/907737b4c175aec82087b815fa93a8afea5c6c5a3e7bb748b9\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp39-cp39-linux_x86_64.whl size=494643 sha256=37cbbb99f5118cef198bcda87ac63ecd0b614ddaaccb4b75c71c78f97a2e02be\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/c2/c1/076651c394f05fe60990cd85616c2d95bc1619aa113f559d7d\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.2-py3-none-any.whl size=88190 sha256=c941d07f8487b9d49f624b3bac7326fd1b40836b36a4c3801250b12955d3c931\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/a0/7c/a850abc2cfad92656c1bc61795c340ce1f741c1686ad9f0908\n",
            "Successfully built finrl exchange_calendars gym elegantrl gputil pyfolio empyrical gpustat thriftpy2 box2d-py lit\n",
            "Installing collected packages: webencodings, wcwidth, pytz, pyglet, py-spy, pure-eval, ptyprocess, ply, pickleshare, opencensus-context, nvidia-ml-py, multitasking, msgpack, mpmath, lit, korean_lunar_calendar, gputil, executing, distlib, colorful, cmake, box2d-py, backcall, appdirs, zipp, websockets, websocket-client, tzdata, typing-extensions, traitlets, threadpoolctl, tabulate, sympy, soupsieve, smart-open, six, PyYAML, pyrsistent, pyparsing, pymysql, pyluach, pygments, pyasn1, psycopg2-binary, psutil, protobuf, prompt-toolkit, prometheus-client, platformdirs, pillow, pexpect, parso, packaging, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, multidict, MarkupSafe, lz4, lxml, kiwisolver, joblib, grpcio, greenlet, frozenlist, frozendict, fonttools, filelock, decorator, cycler, cloudpickle, click, cachetools, attrs, async-timeout, yarl, virtualenv, thriftpy2, tensorboardX, sqlalchemy, scipy, rsa, python-dateutil, pydantic, pycares, pyasn1-modules, nvidia-cusolver-cu11, nvidia-cudnn-cu11, matplotlib-inline, jsonschema, jinja2, jedi, importlib-resources, importlib-metadata, html5lib, gym, googleapis-common-protos, deprecation, contourpy, blessed, beautifulsoup4, asttokens, aiosignal, stack-data, scikit-learn, ray, pandas, matplotlib, gpustat, google-auth, aiohttp, aiodns, yfinance, wrds, stockstats, seaborn, pandas-datareader, jqdatasdk, ipython, google-api-core, exchange_calendars, ccxt, alpaca_trade_api, aiohttp-cors, opencensus, empyrical, pyfolio, triton, torch, stable-baselines3, elegantrl, finrl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Check if the additional packages needed are present, if not install them"
      ],
      "metadata": {
        "id": "DMaIlOcVTJfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install trading_calendars\n",
        "# !pip install alpaca_trade_api\n",
        "# !pip install ccxt\n",
        "# !pip install jqdatasdk\n",
        "# !pip install wrds\n",
        "\n",
        "# !pip install lz4\n",
        "# !pip install ray[tune]\n",
        "# !pip install tensorboardX\n",
        "# !pip install gputil\n",
        "\n",
        "#%%capture\n",
        "if True:\n",
        "    # installing packages\n",
        "    !pip install pyfolio-reloaded  #original pyfolio no longer maintained\n",
        "    !pip install optuna\n",
        "    !pip install -U \"ray[rllib]\"\n",
        "    !pip install plotly\n",
        "    !pip install ipywidgets\n",
        "    !pip install -U kaleido   # enables saving plots to file\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "UfmXkH1rTFM7",
        "outputId": "3a43049b-fb84-452f-f22c-8ccc925bc9a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyfolio-reloaded\n",
            "  Downloading pyfolio_reloaded-0.9.5-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.16.1 in /usr/local/lib/python3.9/site-packages (from pyfolio-reloaded) (1.2.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.9/site-packages (from pyfolio-reloaded) (8.12.0)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.9/site-packages (from pyfolio-reloaded) (2.0.1)\n",
            "Collecting empyrical-reloaded>=0.5.8\n",
            "  Downloading empyrical_reloaded-0.5.9-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.9/site-packages (from pyfolio-reloaded) (2023.3)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.9/site-packages (from pyfolio-reloaded) (0.12.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.9/site-packages (from pyfolio-reloaded) (1.10.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.9/site-packages (from pyfolio-reloaded) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.9/site-packages (from pyfolio-reloaded) (1.24.3)\n",
            "Requirement already satisfied: yfinance>=0.1.63 in /usr/local/lib/python3.9/site-packages (from empyrical-reloaded>=0.5.8->pyfolio-reloaded) (0.2.18)\n",
            "Requirement already satisfied: pandas-datareader>=0.4 in /usr/local/lib/python3.9/site-packages (from empyrical-reloaded>=0.5.8->pyfolio-reloaded) (0.10.0)\n",
            "Collecting bottleneck>=1.3.0\n",
            "  Downloading Bottleneck-1.3.7-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m353.1/353.1 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (5.9.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (0.18.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (4.8.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (0.1.6)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (2.15.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (0.7.5)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (4.5.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio-reloaded) (3.0.38)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (9.5.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded) (23.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/site-packages (from pandas>=0.18.1->pyfolio-reloaded) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.16.1->pyfolio-reloaded) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.16.1->pyfolio-reloaded) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=1.4.0->pyfolio-reloaded) (3.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio-reloaded) (0.8.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/site-packages (from pandas-datareader>=0.4->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (2.28.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/site-packages (from pandas-datareader>=0.4->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (4.9.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio-reloaded) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=3.2.3->pyfolio-reloaded) (0.2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->pyfolio-reloaded) (1.16.0)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.9/site-packages (from yfinance>=0.1.63->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (1.4.4)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.9/site-packages (from yfinance>=0.1.63->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (1.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.9/site-packages (from yfinance>=0.1.63->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (4.12.2)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.9/site-packages (from yfinance>=0.1.63->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (0.0.11)\n",
            "Requirement already satisfied: cryptography>=3.3.2 in /usr/local/lib/python3.9/site-packages (from yfinance>=0.1.63->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (39.0.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.9/site-packages (from yfinance>=0.1.63->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (2.3.7)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded) (2.2.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded) (0.2.2)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded) (1.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance>=0.1.63->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (2.4.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/site-packages (from cryptography>=3.3.2->yfinance>=0.1.63->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (1.15.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance>=0.1.63->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (0.5.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests>=2.19.0->pandas-datareader>=0.4->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests>=2.19.0->pandas-datareader>=0.4->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.19.0->pandas-datareader>=0.4->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests>=2.19.0->pandas-datareader>=0.4->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (2022.12.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance>=0.1.63->empyrical-reloaded>=0.5.8->pyfolio-reloaded) (2.21)\n",
            "Installing collected packages: bottleneck, empyrical-reloaded, pyfolio-reloaded\n",
            "Successfully installed bottleneck-1.3.7 empyrical-reloaded-0.5.9 pyfolio-reloaded-0.9.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/site-packages (from optuna) (6.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from optuna) (4.65.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/site-packages (from optuna) (1.4.47)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from optuna) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.4 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray[rllib] in /usr/local/lib/python3.9/site-packages (2.4.0)\n",
            "Requirement already satisfied: virtualenv<20.21.1,>=20.0.24 in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (20.21.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (6.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (3.12.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (8.1.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (23.1.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (1.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (1.0.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (4.17.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (1.3.1)\n",
            "Requirement already satisfied: grpcio<=1.51.3,>=1.32.0 in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (1.51.3)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (2.28.2)\n",
            "Collecting typer\n",
            "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (2.6)\n",
            "Collecting dm-tree\n",
            "  Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich\n",
            "  Downloading rich-13.3.5-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m238.7/238.7 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image\n",
            "  Downloading scikit_image-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium==0.26.3\n",
            "  Downloading Gymnasium-0.26.3-py3-none-any.whl (836 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m836.9/836.9 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (2.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (1.10.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (0.9.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.9/site-packages (from ray[rllib]) (4.3.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/site-packages (from gymnasium==0.26.3->ray[rllib]) (4.13.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/site-packages (from gymnasium==0.26.3->ray[rllib]) (2.2.1)\n",
            "Collecting gymnasium-notices>=0.0.1\n",
            "  Downloading gymnasium_notices-0.0.1-py3-none-any.whl (2.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from tensorboardX>=1.9->ray[rllib]) (23.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.9/site-packages (from virtualenv<20.21.1,>=20.0.24->ray[rllib]) (0.3.6)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/site-packages (from virtualenv<20.21.1,>=20.0.24->ray[rllib]) (3.5.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/site-packages (from jsonschema->ray[rllib]) (0.19.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from pandas->ray[rllib]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->ray[rllib]) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/site-packages (from pandas->ray[rllib]) (2023.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->ray[rllib]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests->ray[rllib]) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->ray[rllib]) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->ray[rllib]) (1.26.15)\n",
            "Collecting markdown-it-py<3.0.0,>=2.2.0\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from rich->ray[rllib]) (2.15.1)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
            "  Downloading PyWavelets-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tifffile>=2019.7.26\n",
            "  Downloading tifffile-2023.4.12-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m219.4/219.4 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.9/site-packages (from scikit-image->ray[rllib]) (3.1)\n",
            "Requirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.9/site-packages (from scikit-image->ray[rllib]) (9.5.0)\n",
            "Collecting imageio>=2.4.1\n",
            "  Downloading imageio-2.28.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lazy_loader>=0.1\n",
            "  Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium==0.26.3->ray[rllib]) (3.15.0)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->ray[rllib]) (1.16.0)\n",
            "Installing collected packages: gymnasium-notices, dm-tree, typer, tifffile, scipy, PyWavelets, mdurl, lazy_loader, imageio, scikit-image, markdown-it-py, gymnasium, rich\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "Successfully installed PyWavelets-1.4.1 dm-tree-0.1.8 gymnasium-0.26.3 gymnasium-notices-0.0.1 imageio-2.28.0 lazy_loader-0.2 markdown-it-py-2.2.0 mdurl-0.1.2 rich-13.3.5 scikit-image-0.20.0 scipy-1.9.1 tifffile-2023.4.12 typer-0.7.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting plotly\n",
            "  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tenacity>=6.2.0\n",
            "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from plotly) (23.1)\n",
            "Installing collected packages: tenacity, plotly\n",
            "Successfully installed plotly-5.14.1 tenacity-8.2.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.0.6-py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m299.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-widgets~=3.0.7\n",
            "  Downloading jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m198.2/198.2 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.9/site-packages (from ipywidgets) (8.12.0)\n",
            "Collecting ipykernel>=4.5.1\n",
            "  Downloading ipykernel-6.22.0-py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m150.0/150.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting widgetsnbextension~=4.0.7\n",
            "  Downloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.9/site-packages (from ipywidgets) (5.9.0)\n",
            "Collecting tornado>=6.1\n",
            "  Downloading tornado-6.3.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m426.8/426.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-client>=6.1.12\n",
            "  Downloading jupyter_client-8.2.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzmq>=20\n",
            "  Downloading pyzmq-25.0.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-core!=5.0.*,>=4.12\n",
            "  Downloading jupyter_core-5.3.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (23.1)\n",
            "Collecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting debugpy>=1.6.5\n",
            "  Downloading debugpy-1.6.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
            "Collecting comm>=0.1.1\n",
            "  Downloading comm-0.1.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.5.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.13.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.5.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (3.15.0)\n",
            "Installing collected packages: widgetsnbextension, tornado, pyzmq, nest-asyncio, jupyterlab-widgets, jupyter-core, debugpy, comm, jupyter-client, ipykernel, ipywidgets\n",
            "Successfully installed comm-0.1.3 debugpy-1.6.7 ipykernel-6.22.0 ipywidgets-8.0.6 jupyter-client-8.2.0 jupyter-core-5.3.0 jupyterlab-widgets-3.0.7 nest-asyncio-1.5.6 pyzmq-25.0.2 tornado-6.3.1 widgetsnbextension-4.0.7\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas==1.5.3\n",
        "!pip install gymnasium"
      ],
      "metadata": {
        "id": "9Zkmtvr-TFn_",
        "outputId": "432ff578-a0a2-4fda-a514-8ae351e33991",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.9/site-packages (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/site-packages (from pandas==1.5.3) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas==1.5.3) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/site-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.9/site-packages (0.26.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/site-packages (from gymnasium) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/site-packages (from gymnasium) (1.24.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/site-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: gymnasium-notices>=0.0.1 in /usr/local/lib/python3.9/site-packages (from gymnasium) (0.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.15.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Import packages"
      ],
      "metadata": {
        "id": "BbOMJnGdTRYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "import optuna\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "%matplotlib inline\n",
        "from finrl import config\n",
        "from finrl import config_tickers\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv as StockTradingEnv_numpy\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from finrl.agents.rllib.models import DRLAgent as DRLAgent_rllib\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "import joblib\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "import ray\n",
        "from pprint import pprint\n",
        "import kaleido\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(f'Torch device: {device}')"
      ],
      "metadata": {
        "id": "tG5qIkVHTNv8",
        "outputId": "17276148-a455-406a-d3d7-0462f1bff80a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/site-packages/pyfolio/pos.py:25: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DB11ygQLVLUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fMaPm8MsUo0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ],
      "metadata": {
        "id": "FAZpwTH3VVi-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collecting data and preprocessing"
      ],
      "metadata": {
        "id": "cqJ8ngFWVcNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Custom ticker list dataframe download\n",
        "#TODO save df to avoid download\n",
        "path_pf = '/content/ticker_data.csv'\n",
        "if Path(path_pf).is_file():\n",
        "  print('Reading ticker data')\n",
        "  df = pd.read_csv(path_pf)\n",
        "  \n",
        "else:\n",
        "  print('Downloading ticker data')\n",
        "  ticker_list = config_tickers.DOW_30_TICKER\n",
        "  df = YahooDownloader(start_date = '2009-01-01',\n",
        "                     end_date = '2021-10-01',\n",
        "                     ticker_list = ticker_list).fetch_data()\n",
        "  df.to_csv('ticker_data.csv')"
      ],
      "metadata": {
        "id": "7BJNlsAuVZ-o",
        "outputId": "9253f678-00d3-4448-efb8-c69ec733bf4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ticker data\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (93701, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_processed_full(processed):\n",
        "  list_ticker = processed[\"tic\"].unique().tolist()\n",
        "  list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
        "  combination = list(itertools.product(list_date,list_ticker))\n",
        "\n",
        "  processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
        "  processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
        "  processed_full = processed_full.sort_values(['date','tic'])\n",
        "\n",
        "  processed_full = processed_full.fillna(0)\n",
        "  processed_full.sort_values(['date','tic'],ignore_index=True).head(5)\n",
        "\n",
        "  processed_full.to_csv('processed_full.csv')\n",
        "  return processed_full"
      ],
      "metadata": {
        "id": "RD6wwtGSVZVU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#You can add technical indicators and turbulence factor to dataframe\n",
        "#Just set the use_technical_indicator=True, use_vix=True and use_turbulence=True\n",
        "def create_techind():\n",
        "  fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    tech_indicator_list = config.INDICATORS,\n",
        "                    use_vix=True,\n",
        "                    use_turbulence=True,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "  processed = fe.preprocess_data(df)\n",
        "  return processed"
      ],
      "metadata": {
        "id": "UNqEALmbVoJo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load price and technical indicator data from file if available\n",
        "path_pf = '/content/processed_full.csv'\n",
        "if Path(path_pf).is_file():\n",
        "  print('Reading processed_full data')\n",
        "  processed_full = pd.read_csv(path_pf)\n",
        "\n",
        "else:\n",
        "  print('Creating processed_full file')\n",
        "  processed=create_techind()\n",
        "  processed_full=create_processed_full(processed)"
      ],
      "metadata": {
        "id": "Qr1Qd-lMVpzg",
        "outputId": "d7bd1a9c-30ee-42df-f0a6-a46b35beeaeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating processed_full file\n",
            "Successfully added technical indicators\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (3208, 8)\n",
            "Successfully added vix\n",
            "Successfully added turbulence index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_col = \"date\"\n",
        "tic_col = \"tic\"\n",
        "\n",
        "init_train_trade_data = processed_full.sort_values([date_col, tic_col])\n",
        "\n",
        "init_train_trade_data = processed_full.fillna(0)\n",
        "\n",
        "init_train_data = data_split(\n",
        "    init_train_trade_data, '2020-01-01', '2020-07-01')\n",
        "init_trade_data = data_split(\n",
        "    init_train_trade_data, '2021-05-01','2021-10-01')\n",
        "\n",
        "print(f'Number of training samples: {len(init_train_data)}')\n",
        "print(f'Number of testing samples: {len(init_train_trade_data)}')"
      ],
      "metadata": {
        "id": "KFs4AjWIVr2s",
        "outputId": "480b7be2-1dee-4b36-ab08-f1cd26f7e762",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 3625\n",
            "Number of testing samples: 93032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Environment"
      ],
      "metadata": {
        "id": "L3VlkfBMW8e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import gym\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym import spaces\n",
        "from gym.utils import seeding\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# from stable_baselines3.common.logger import Logger, KVWriter, CSVOutputFormat\n",
        "\n",
        "\n",
        "class GokuEnv(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "\n",
        "    metadata = {\"render.modes\": [\"human\"]}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        stock_dim: int,\n",
        "        hmax: int,\n",
        "        initial_amount: int,\n",
        "        num_stock_shares: list[int],\n",
        "        buy_cost_pct: list[float],\n",
        "        sell_cost_pct: list[float],\n",
        "        reward_scaling: float,\n",
        "        state_space: int,\n",
        "        action_space: int,\n",
        "        tech_indicator_list: list[str],\n",
        "        turbulence_threshold=None,\n",
        "        risk_indicator_col=\"turbulence\",\n",
        "        make_plots: bool = False,\n",
        "        print_verbosity=10,\n",
        "        day=0,\n",
        "        initial=True,\n",
        "        previous_state=[],\n",
        "        model_name=\"\",\n",
        "        mode=\"\",\n",
        "        iteration=\"\",\n",
        "    ):\n",
        "        self.day = day\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.num_stock_shares = num_stock_shares\n",
        "        self.initial_amount = initial_amount  # get the initial cash\n",
        "        self.buy_cost_pct = buy_cost_pct\n",
        "        self.sell_cost_pct = sell_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.action_space,))\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(self.state_space,)\n",
        "        )\n",
        "        self.data = self.df.loc[self.day, :]\n",
        "        self.terminal = False\n",
        "        self.make_plots = make_plots\n",
        "        self.print_verbosity = print_verbosity\n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        self.risk_indicator_col = risk_indicator_col\n",
        "        self.initial = initial\n",
        "        self.previous_state = previous_state\n",
        "        self.model_name = model_name\n",
        "        self.mode = mode\n",
        "        self.iteration = iteration\n",
        "        # initalize state\n",
        "        self.state = self._initiate_state()\n",
        "\n",
        "        # initialize reward\n",
        "        self.reward = 0\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.episode = 0\n",
        "        # memorize all the total balance change\n",
        "        self.asset_memory = [\n",
        "            self.initial_amount\n",
        "            + np.sum(\n",
        "                np.array(self.num_stock_shares)\n",
        "                * np.array(self.state[1 : 1 + self.stock_dim])\n",
        "            )\n",
        "        ]  # the initial total asset is calculated by cash + sum (num_share_stock_i * price_stock_i)\n",
        "        self.rewards_memory = []\n",
        "        self.actions_memory = []\n",
        "        self.state_memory = (\n",
        "            []\n",
        "        )  # we need sometimes to preserve the state in the middle of trading process\n",
        "        self.date_memory = [self._get_date()]\n",
        "        #         self.logger = Logger('results',[CSVOutputFormat])\n",
        "        # self.reset()\n",
        "        self._seed()\n",
        "        self.total_price = np.array([0] * 29)\n",
        "        self.avg_price = np.array([0] * 29)\n",
        "        self.total_stockss = np.array([0] * 29)\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        def _do_sell_normal():\n",
        "            if (\n",
        "                self.state[index + 2 * self.stock_dim + 1] != True\n",
        "            ):  # check if the stock is able to sell, for simlicity we just add it in techical index\n",
        "                # if self.state[index + 1] > 0: # if we use price<0 to denote a stock is unable to trade in that day, the total asset calculation may be wrong for the price is unreasonable\n",
        "                # Sell only if the price is > 0 (no missing data in this particular date)\n",
        "                # perform sell action based on the sign of the action\n",
        "                if self.state[index + self.stock_dim + 1] > 0:\n",
        "                    # Sell only if current asset is > 0\n",
        "                    sell_num_shares = min(\n",
        "                        abs(action), self.state[index + self.stock_dim + 1]\n",
        "                    )\n",
        "                    sell_amount = (\n",
        "                        self.state[index + 1]\n",
        "                        * sell_num_shares\n",
        "                        * (1 - self.sell_cost_pct[index])\n",
        "                    )\n",
        "                    # update balance\n",
        "                    self.state[0] += sell_amount\n",
        "\n",
        "                    self.state[index + self.stock_dim + 1] -= sell_num_shares\n",
        "                    self.cost += (\n",
        "                        self.state[index + 1]\n",
        "                        * sell_num_shares\n",
        "                        * self.sell_cost_pct[index]\n",
        "                    )\n",
        "                    self.trades += 1\n",
        "                    if sell_num_shares >0:\n",
        "                      print(\"stocks Sold sell_num_shares\", sell_num_shares)\n",
        "                else:\n",
        "                    sell_num_shares = 0\n",
        "            else:\n",
        "                sell_num_shares = 0\n",
        "            return sell_num_shares\n",
        "\n",
        "        # perform sell action based on the sign of the action\n",
        "        if self.turbulence_threshold is not None:\n",
        "            if self.turbulence >= self.turbulence_threshold:\n",
        "                if self.state[index + 1] > 0:\n",
        "                    # Sell only if the price is > 0 (no missing data in this particular date)\n",
        "                    # if turbulence goes over threshold, just clear out all positions\n",
        "                    if self.state[index + self.stock_dim + 1] > 0:\n",
        "                        # Sell only if current asset is > 0\n",
        "                        sell_num_shares = self.state[index + self.stock_dim + 1]\n",
        "                        sell_amount = (\n",
        "                            self.state[index + 1]\n",
        "                            * sell_num_shares\n",
        "                            * (1 - self.sell_cost_pct[index])\n",
        "                        )\n",
        "                        # update balance\n",
        "                        self.state[0] += sell_amount\n",
        "                        self.state[index + self.stock_dim + 1] = 0\n",
        "                        self.cost += (\n",
        "                            self.state[index + 1]\n",
        "                            * sell_num_shares\n",
        "                            * self.sell_cost_pct[index]\n",
        "                        )\n",
        "                        self.trades += 1\n",
        "                    else:\n",
        "                        sell_num_shares = 0\n",
        "                else:\n",
        "                    sell_num_shares = 0\n",
        "            else:\n",
        "                sell_num_shares = _do_sell_normal()\n",
        "        else:\n",
        "            sell_num_shares = _do_sell_normal()\n",
        "        print(\"stocks Sold sell_num_shares\", sell_num_shares)\n",
        "        return sell_num_shares\n",
        "\n",
        "    def _buy_stock(self, index, action):\n",
        "        def _do_buy():\n",
        "            if (self.state[index + 2 * self.stock_dim + 1] != True):  # check if the stock is able to buy\n",
        "                # if self.state[index + 1] >0:\n",
        "                # Buy only if the price is > 0 (no missing data in this particular date)\n",
        "                available_amount = self.state[0] // (self.state[index + 1] * (1 + self.buy_cost_pct[index]))\n",
        "                # when buying stocks, we should consider the cost of trading when calculating available_amount, or we may be have cash<0\n",
        "                # print('available_amount:{}'.format(available_amount))\n",
        "                # update balance\n",
        "                buy_num_shares = min(available_amount, action)\n",
        "                buy_amount = (self.state[index + 1] * buy_num_shares * (1 + self.buy_cost_pct[index]))\n",
        "                self.state[0] -= buy_amount\n",
        "                self.state[index + self.stock_dim + 1] += buy_num_shares\n",
        "                self.cost += (self.state[index + 1] * buy_num_shares * self.buy_cost_pct[index])\n",
        "                self.trades += 1\n",
        "            else:\n",
        "                buy_num_shares = 0\n",
        "\n",
        "            return buy_num_shares\n",
        "\n",
        "        # perform buy action based on the sign of the action\n",
        "        if self.turbulence_threshold is None:\n",
        "            buy_num_shares = _do_buy()\n",
        "        else:\n",
        "            if self.turbulence < self.turbulence_threshold:\n",
        "                buy_num_shares = _do_buy()\n",
        "            else:\n",
        "                buy_num_shares = 0\n",
        "                pass\n",
        "\n",
        "        return buy_num_shares\n",
        "\n",
        "    def _make_plot(self):\n",
        "        plt.plot(self.asset_memory, \"r\")\n",
        "        plt.savefig(f\"results/account_value_trade_{self.episode}.png\")\n",
        "        plt.close()\n",
        "\n",
        "    def step(self, actions):\n",
        "        self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
        "        if self.terminal:\n",
        "            # print(f\"Episode: {self.episode}\")\n",
        "            if self.make_plots:\n",
        "                self._make_plot()\n",
        "            end_total_asset = self.state[0] + sum(np.array(self.state[1 : (self.stock_dim + 1)]) * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]))\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\n",
        "            tot_reward = (self.state[0] + \n",
        "                          sum(np.array(self.state[1 : (self.stock_dim + 1)]) \n",
        "                          * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])) \n",
        "                          - self.asset_memory[0])  # initial_amount is only cash part of our initial asset\n",
        "            df_total_value.columns = [\"account_value\"]\n",
        "            df_total_value[\"date\"] = self.date_memory\n",
        "            df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(1)\n",
        "            if df_total_value[\"daily_return\"].std() != 0:\n",
        "                sharpe = ((252**0.5) \n",
        "                * df_total_value[\"daily_return\"].mean() \n",
        "                / df_total_value[\"daily_return\"].std())\n",
        "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "            df_rewards.columns = [\"account_rewards\"]\n",
        "            df_rewards[\"date\"] = self.date_memory[:-1]\n",
        "            \n",
        "            if self.episode % self.print_verbosity == 0:\n",
        "                print(f\"day: {self.day}, episode: {self.episode}\")\n",
        "                print(f\"begin_total_asset: {self.asset_memory[0]:0.2f}\")\n",
        "                print(f\"end_total_asset: {end_total_asset:0.2f}\")\n",
        "                print(f\"total_reward: {tot_reward:0.2f}\")\n",
        "                print(f\"total_cost: {self.cost:0.2f}\")\n",
        "                print(f\"total_trades: {self.trades}\")\n",
        "                if df_total_value[\"daily_return\"].std() != 0:\n",
        "                    print(f\"Sharpe: {sharpe:0.3f}\")\n",
        "                print(\"=================================\")\n",
        "\n",
        "            if (self.model_name != \"\") and (self.mode != \"\"):\n",
        "                df_actions = self.save_action_memory()\n",
        "                df_actions.to_csv(\"results/actions_{}_{}_{}.csv\".format(self.mode, self.model_name, self.iteration))\n",
        "                df_total_value.to_csv(\"results/account_value_{}_{}_{}.csv\".format(self.mode, self.model_name, self.iteration),index=False,)\n",
        "                df_rewards.to_csv(\"results/account_rewards_{}_{}_{}.csv\".format(self.mode, self.model_name, self.iteration),index=False,)\n",
        "                plt.plot(self.asset_memory, \"r\")\n",
        "                plt.savefig(\"results/account_value_{}_{}_{}.png\".format(self.mode, self.model_name, self.iteration))\n",
        "                plt.close()\n",
        "            return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "        else:\n",
        "            actions = actions * self.hmax  # actions initially is scaled between 0 to 1\n",
        "            actions = actions.astype(int)  # convert into integer because we can't by fraction of shares\n",
        "\n",
        "\n",
        "            if self.turbulence_threshold is not None:\n",
        "                if self.turbulence >= self.turbulence_threshold:\n",
        "                    actions = np.array([-self.hmax] * self.stock_dim)\n",
        "\n",
        "            begin_total_asset = self.state[0] + sum(np.array(self.state[1 : (self.stock_dim + 1)])* np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]))\n",
        "            # print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
        "            #print(\"*\" * 20 )\n",
        "            #print(np.array(self.state[1 : (self.stock_dim + 1)]))\n",
        "            \n",
        "            #print(np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]))\n",
        "            #print(\"*\" * 20 )\n",
        "            \n",
        "            #print(\"AVG PRices\")  \n",
        "            #print(self.avg_price)\n",
        "            #print(np.where(np.array(self.state[1 : (self.stock_dim + 1)]) > (self.avg_price + self.avg_price*.15))) \n",
        "            #print(self.avg_price)\n",
        "            #print(self.total_stockss)\n",
        "            #print(\"*\"*20)\n",
        "\n",
        "            # if sum(self.total_stockss) !=0:\n",
        "            #   for i in np.where(np.array(self.state[1 : (self.stock_dim + 1)]) > (self.avg_price + self.avg_price*.15)):\n",
        "            #     for a in i:\n",
        "            #       actions[a] = actions[a]*-1\n",
        "\n",
        "            # for a in actions:\n",
        "            #   print(a)\n",
        "\n",
        "            argsort_actions = np.argsort(actions)\n",
        "            sell_index = argsort_actions[: np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = argsort_actions[::-1][: np.where(actions > 0)[0].shape[0]]\n",
        "\n",
        "            for index in sell_index:\n",
        "              actions[index] = self._sell_stock(index, actions[index]) * (-1)\n",
        "\n",
        "            for index in buy_index:\n",
        "                actions[index] = self._buy_stock(index, actions[index])\n",
        "\n",
        "\n",
        "            self.actions_memory.append(actions)\n",
        "\n",
        "            # state: s -> s+1\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day, :]\n",
        "            if self.turbulence_threshold is not None:\n",
        "                if len(self.df.tic.unique()) == 1:\n",
        "                    self.turbulence = self.data[self.risk_indicator_col]\n",
        "                elif len(self.df.tic.unique()) > 1:\n",
        "                    self.turbulence = self.data[self.risk_indicator_col].values[0]\n",
        "\n",
        "\n",
        "\n",
        "            self.total_stockss = actions + self.total_stockss\n",
        "            print(\"Total Stocks\")\n",
        "            self.total_price = np.array(self.state[1 : (self.stock_dim + 1)])* np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]) + self.total_price\n",
        "\n",
        "            \n",
        "            self.avg_price = np.divide(self.total_price,\n",
        "                      self.total_stockss, out=np.zeros_like(self.total_price),\n",
        "                      where=self.total_stockss!=0)\n",
        "          \n",
        "            print(self.total_stockss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            self.state = self._update_state()\n",
        "\n",
        "            end_total_asset = self.state[0] + sum(\n",
        "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
        "            )\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "            self.date_memory.append(self._get_date())\n",
        "            self.reward = end_total_asset - begin_total_asset\n",
        "            self.rewards_memory.append(self.reward)\n",
        "            self.reward = self.reward * self.reward_scaling\n",
        "            self.state_memory.append(\n",
        "                self.state\n",
        "            )  # add current state in state_recorder for each step\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        # initiate state\n",
        "        self.state = self._initiate_state()\n",
        "\n",
        "        if self.initial:\n",
        "            self.asset_memory = [\n",
        "                self.initial_amount\n",
        "                + np.sum(\n",
        "                    np.array(self.num_stock_shares)\n",
        "                    * np.array(self.state[1 : 1 + self.stock_dim])\n",
        "                )\n",
        "            ]\n",
        "        else:\n",
        "            previous_total_asset = self.previous_state[0] + sum(\n",
        "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
        "                * np.array(\n",
        "                    self.previous_state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]\n",
        "                )\n",
        "            )\n",
        "            self.asset_memory = [previous_total_asset]\n",
        "\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day, :]\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.terminal = False\n",
        "        # self.iteration=self.iteration\n",
        "        self.rewards_memory = []\n",
        "        self.actions_memory = []\n",
        "        self.date_memory = [self._get_date()]\n",
        "\n",
        "        self.episode += 1\n",
        "\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode=\"human\", close=False):\n",
        "        return self.state\n",
        "\n",
        "    def _initiate_state(self):\n",
        "        if self.initial:\n",
        "            # For Initial State\n",
        "            if len(self.df.tic.unique()) > 1:\n",
        "                # for multiple stock\n",
        "                state = (\n",
        "                    [self.initial_amount]\n",
        "                    + self.data.close.values.tolist()\n",
        "                    + self.num_stock_shares\n",
        "                    + sum(\n",
        "                        (\n",
        "                            self.data[tech].values.tolist()\n",
        "                            for tech in self.tech_indicator_list\n",
        "                        ),\n",
        "                        [],\n",
        "                    )\n",
        "                )  # append initial stocks_share to initial state, instead of all zero\n",
        "            else:\n",
        "                # for single stock\n",
        "                state = (\n",
        "                    [self.initial_amount]\n",
        "                    + [self.data.close]\n",
        "                    + [0] * self.stock_dim\n",
        "                    + sum(([self.data[tech]] for tech in self.tech_indicator_list), [])\n",
        "                )\n",
        "        else:\n",
        "            # Using Previous State\n",
        "            if len(self.df.tic.unique()) > 1:\n",
        "                # for multiple stock\n",
        "                state = (\n",
        "                    [self.previous_state[0]]\n",
        "                    + self.data.close.values.tolist()\n",
        "                    + self.previous_state[\n",
        "                        (self.stock_dim + 1) : (self.stock_dim * 2 + 1)\n",
        "                    ]\n",
        "                    + sum(\n",
        "                        (\n",
        "                            self.data[tech].values.tolist()\n",
        "                            for tech in self.tech_indicator_list\n",
        "                        ),\n",
        "                        [],\n",
        "                    )\n",
        "                )\n",
        "            else:\n",
        "                # for single stock\n",
        "                state = (\n",
        "                    [self.previous_state[0]]\n",
        "                    + [self.data.close]\n",
        "                    + self.previous_state[\n",
        "                        (self.stock_dim + 1) : (self.stock_dim * 2 + 1)\n",
        "                    ]\n",
        "                    + sum(([self.data[tech]] for tech in self.tech_indicator_list), [])\n",
        "                )\n",
        "        return state\n",
        "\n",
        "    def _update_state(self):\n",
        "        if len(self.df.tic.unique()) > 1:\n",
        "            # for multiple stock\n",
        "            state = (\n",
        "                [self.state[0]]\n",
        "                + self.data.close.values.tolist()\n",
        "                + list(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
        "                + sum((self.data[tech].values.tolist() for tech in self.tech_indicator_list),[],))\n",
        "\n",
        "        else:\n",
        "            # for single stock\n",
        "            state = ([self.state[0]] + [self.data.close] \n",
        "                     + list(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
        "                     + sum(([self.data[tech]] for tech in self.tech_indicator_list), []))\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_date(self):\n",
        "        if len(self.df.tic.unique()) > 1:\n",
        "            date = self.data.date.unique()[0]\n",
        "        else:\n",
        "            date = self.data.date\n",
        "        return date\n",
        "\n",
        "\n",
        "    def save_asset_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        asset_list = self.asset_memory\n",
        "        # print(len(date_list))\n",
        "        # print(len(asset_list))\n",
        "        df_account_value = pd.DataFrame({\"date\": date_list, \"account_value\": asset_list})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        if len(self.df.tic.unique()) > 1:\n",
        "            # date and close price length must match actions length\n",
        "            date_list = self.date_memory[:-1]\n",
        "            df_date = pd.DataFrame(date_list)\n",
        "            df_date.columns = [\"date\"]\n",
        "\n",
        "            action_list = self.actions_memory\n",
        "            df_actions = pd.DataFrame(action_list)\n",
        "            df_actions.columns = self.data.tic.values\n",
        "            df_actions.index = df_date.date\n",
        "            # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        else:\n",
        "            date_list = self.date_memory[:-1]\n",
        "            action_list = self.actions_memory\n",
        "            df_actions = pd.DataFrame({\"date\": date_list, \"actions\": action_list})\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs\n"
      ],
      "metadata": {
        "id": "4p02b2cx_dj5"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_dimension = len(init_train_data.tic.unique())\n",
        "state_space = 1 + 2 * stock_dimension + len(config.INDICATORS) * stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
        "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "num_stock_shares = [0] * stock_dimension"
      ],
      "metadata": {
        "id": "rg7DTZbVV10n",
        "outputId": "e4906857-bb93-400b-fd19-00ee2617e170",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 29, State Space: 291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the environment kwargs\n",
        "\n",
        "initial_amount = 1000000\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": initial_amount,\n",
        "    \"num_stock_shares\": num_stock_shares,\n",
        "    \"buy_cost_pct\": buy_cost_list,\n",
        "    \"sell_cost_pct\": sell_cost_list,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": config.INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "}"
      ],
      "metadata": {
        "id": "zODPmc5hV42J"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the training gym compatible environment\n",
        "e_train_gym = GokuEnv(df = init_train_data, **env_kwargs)\n",
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "agent = DRLAgent(env = env_train)"
      ],
      "metadata": {
        "id": "7n2QYGP5V58p"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the trading environment\n",
        "e_trade_gym = GokuEnv(df = init_trade_data, turbulence_threshold = None, **env_kwargs)"
      ],
      "metadata": {
        "id": "xoBM74XEX1oI"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trade performance code\n",
        "The following code calculates trade performance metrics, which are then used as an objective for optimizing hyperparameter values.\n",
        "\n",
        "There are several available metrics. In this tutorial, the default choice is the ratio of average value of winning to losing trades."
      ],
      "metadata": {
        "id": "Dq6zJ14ZYsTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Main method\n",
        "# Calculates Trade Performance for Objective\n",
        "# Called from objective method\n",
        "# Returns selected trade perf metric(s)\n",
        "# Requires actions and associated prices\n",
        "\n",
        "def calc_trade_perf_metric(df_actions, \n",
        "                           df_prices_trade,\n",
        "                           tp_metric,\n",
        "                           dbg=False):\n",
        "  \n",
        "    df_actions_p, df_prices_p, tics = prep_data(df_actions.copy(),\n",
        "                                                df_prices_trade.copy())\n",
        "    # actions predicted by trained model on trade data\n",
        "    df_actions_p.to_csv('df_actions.csv') \n",
        "\n",
        "    \n",
        "    # Confirms that actions, prices and tics are consistent\n",
        "    df_actions_s, df_prices_s, tics_prtfl = \\\n",
        "        sync_tickers(df_actions_p.copy(),df_prices_p.copy(),tics)\n",
        "    \n",
        "    # copy to ensure that tics from portfolio remains unchanged\n",
        "    tics = tics_prtfl.copy()\n",
        "    \n",
        "    # Analysis is performed on each portfolio ticker\n",
        "    perf_data= collect_performance_data(df_actions_s, df_prices_s, tics)\n",
        "    # profit/loss for each ticker\n",
        "    pnl_all = calc_pnl_all(perf_data, tics)\n",
        "    # values for trade performance metrics\n",
        "    perf_results = calc_trade_perf(pnl_all)\n",
        "    df = pd.DataFrame.from_dict(perf_results, orient='index')\n",
        "    \n",
        "    # calculate and return trade metric value as objective\n",
        "    m = calc_trade_metric(df,tp_metric)\n",
        "    print(f'Ratio Avg Win/Avg Loss: {m}')\n",
        "    k = str(len(tpm_hist)+1)\n",
        "    # save metric value\n",
        "    tpm_hist[k] = m\n",
        "    return m\n",
        "\n",
        "\n",
        "# Supporting methods\n",
        "def calc_trade_metric(df,metric='avgwl'):\n",
        "    '''# trades', '# wins', '# losses', 'wins total value', 'wins avg value',\n",
        "       'losses total value', 'losses avg value'''\n",
        "    # For this tutorial, the only metric available is the ratio of \n",
        "    #  average values of winning to losing trades. Others are in development.\n",
        "    \n",
        "    # some test cases produce no losing trades.\n",
        "    # The code below assigns a value as a multiple of the highest value during\n",
        "    # previous hp optimization runs. If the first run experiences no losses,\n",
        "    # a fixed value is assigned for the ratio\n",
        "    tpm_mult = 1.0\n",
        "    avgwl_no_losses = 25\n",
        "    if metric == 'avgwl':\n",
        "        if sum(df['# losses']) == 0:\n",
        "          try:\n",
        "            return max(tpm_hist.values())*tpm_mult\n",
        "          except ValueError:\n",
        "            return avgwl_no_losses\n",
        "        avg_w = sum(df['wins total value'])/sum(df['# wins'])\n",
        "        avg_l = sum(df['losses total value'])/sum(df['# losses'])\n",
        "        m = abs(avg_w/avg_l)\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def prep_data(df_actions,\n",
        "              df_prices_trade):\n",
        "    \n",
        "    df=df_prices_trade[['date','close','tic']]\n",
        "    df['Date'] = pd.to_datetime(df['date'])\n",
        "    df = df.set_index('Date')\n",
        "    # set indices on both df to datetime\n",
        "    idx = pd.to_datetime(df_actions.index, infer_datetime_format=True)\n",
        "    df_actions.index=idx\n",
        "    tics = np.unique(df.tic)\n",
        "    n_tics = len(tics)\n",
        "    print(f'Number of tickers: {n_tics}')\n",
        "    print(f'Tickers: {tics}')\n",
        "    dategr = df.groupby('tic')\n",
        "    p_d={t:dategr.get_group(t).loc[:,'close'] for t in tics}\n",
        "    df_prices = pd.DataFrame.from_dict(p_d)\n",
        "    df_prices.index = df_prices.index.normalize()\n",
        "    return df_actions, df_prices, tics\n",
        "\n",
        "\n",
        "# prepares for integrating action and price files\n",
        "def link_prices_actions(df_a,\n",
        "                        df_p):\n",
        "    cols_a = [t + '_a' for t in df_a.columns]\n",
        "    df_a.columns = cols_a\n",
        "    cols_p = [t + '_p' for t in df_p.columns]\n",
        "    df_p.columns = cols_p\n",
        "    return df_a, df_p\n",
        "\n",
        "\n",
        "def sync_tickers(df_actions,df_tickers_p,tickers):\n",
        "    # Some DOW30 components may not be included in portfolio\n",
        "    # passed tickers includes all DOW30 components\n",
        "    # actions and ticker files may have different length indices\n",
        "    if len(df_actions) != len(df_tickers_p):\n",
        "      msng_dates = set(df_actions.index)^set(df_tickers_p.index)\n",
        "      try:\n",
        "        #assumption is prices has one additional timestamp (row)\n",
        "        df_tickers_p.drop(msng_dates,inplace=True)\n",
        "      except:\n",
        "        df_actions.drop(msng_dates,inplace=True)\n",
        "    df_actions, df_tickers_p = link_prices_actions(df_actions,df_tickers_p)\n",
        "    # identify any DOW components not in portfolio\n",
        "    t_not_in_a = [t for t in tickers if t + '_a' not in list(df_actions.columns)]\n",
        "  \n",
        "    # remove t_not_in_a from df_tickers_p\n",
        "    drop_cols = [t + '_p' for t in t_not_in_a]\n",
        "    df_tickers_p.drop(columns=drop_cols,inplace=True)\n",
        "    \n",
        "    # Tickers in portfolio\n",
        "    tickers_prtfl = [c.split('_')[0] for c in df_actions.columns]\n",
        "    return df_actions,df_tickers_p, tickers_prtfl\n",
        "\n",
        "def collect_performance_data(dfa,dfp,tics, dbg=False):\n",
        "    \n",
        "    perf_data = {}\n",
        "    # In current version, files columns include secondary identifier\n",
        "    for t in tics:\n",
        "        # actions: purchase/sale of DOW equities\n",
        "        acts = dfa['_'.join([t,'a'])].values\n",
        "        # ticker prices\n",
        "        prices = dfp['_'.join([t,'p'])].values\n",
        "        # market value of purchases/sales\n",
        "        tvals_init = np.multiply(acts,prices)\n",
        "        d={'actions':acts, 'prices':prices,'init_values':tvals_init}\n",
        "        perf_data[t]=d\n",
        "\n",
        "    return perf_data\n",
        "\n",
        "\n",
        "def calc_pnl_all(perf_dict, tics_all):\n",
        "    # calculate profit/loss for each ticker\n",
        "    print(f'Calculating profit/loss for each ticker')\n",
        "    pnl_all = {}\n",
        "    for tic in tics_all:\n",
        "        pnl_t = []\n",
        "        tic_data = perf_dict[tic]\n",
        "        init_values = tic_data['init_values']\n",
        "        acts = tic_data['actions']\n",
        "        prices = tic_data['prices']\n",
        "        cs = np.cumsum(acts)\n",
        "        args_s = [i + 1 for i in range(len(cs) - 1) if cs[i + 1] < cs[i]]\n",
        "        # tic actions with no sales\n",
        "        if not args_s:\n",
        "            pnl = complete_calc_buyonly(acts, prices, init_values)\n",
        "            pnl_all[tic] = pnl\n",
        "            continue\n",
        "        # copy acts: acts_rev will be revised based on closing/reducing init positions\n",
        "        pnl_all = execute_position_sales(tic,acts,prices,args_s,pnl_all)\n",
        "\n",
        "    return pnl_all\n",
        "\n",
        "\n",
        "def complete_calc_buyonly(actions, prices, init_values):\n",
        "    # calculate final pnl for each ticker assuming no sales\n",
        "    fnl_price = prices[-1]\n",
        "    final_values = np.multiply(fnl_price, actions)\n",
        "    pnl = np.subtract(final_values, init_values)\n",
        "    return pnl\n",
        "\n",
        "\n",
        "def execute_position_sales(tic,acts,prices,args_s,pnl_all):\n",
        "  # calculate final pnl for each ticker with sales\n",
        "    pnl_t = []\n",
        "    acts_rev = acts.copy()\n",
        "    # location of sales transactions\n",
        "    for s in args_s:  # s is scaler\n",
        "        # price_s = [prices[s]]\n",
        "        act_s = [acts_rev[s]]\n",
        "        args_b = [i for i in range(s) if acts_rev[i] > 0]\n",
        "        prcs_init_trades = prices[args_b]\n",
        "        acts_init_trades = acts_rev[args_b]\n",
        "  \n",
        "        # update actions for sales\n",
        "        # reduce/eliminate init values through trades\n",
        "        # always start with earliest purchase that has not been closed through sale\n",
        "        # selectors for purchase and sales trades\n",
        "        # find earliest remaining purchase\n",
        "        arg_sel = min(args_b)\n",
        "        # sel_s = len(acts_trades) - 1\n",
        "\n",
        "        # closing part/all of earliest init trade not yet closed\n",
        "        # sales actions are negative\n",
        "        # in this test case, abs_val of init and sales share counts are same\n",
        "        # zero-out sales actions\n",
        "        # market value of sale\n",
        "        # max number of shares to be closed: may be less than # originally purchased\n",
        "        acts_shares = min(abs(act_s.pop()), acts_rev[arg_sel])\n",
        "\n",
        "        # mv of shares when purchased\n",
        "        mv_p = abs(acts_shares * prices[arg_sel])\n",
        "        # mv of sold shares\n",
        "        mv_s = abs(acts_shares * prices[s])\n",
        "\n",
        "        # calc pnl\n",
        "        pnl = mv_s - mv_p\n",
        "        # reduce init share count\n",
        "        # close all/part of init purchase\n",
        "        acts_rev[arg_sel] -= acts_shares\n",
        "        acts_rev[s] += acts_shares\n",
        "        # calculate pnl for trade\n",
        "        # value of associated purchase\n",
        "        \n",
        "        # find earliest non-zero positive act in acts_revs\n",
        "        pnl_t.append(pnl)\n",
        "    \n",
        "    pnl_op = calc_pnl_for_open_positions(acts_rev, prices)\n",
        "    #pnl_op is list\n",
        "    # add pnl_op results (if any) to pnl_t (both lists)\n",
        "    pnl_t.extend(pnl_op)\n",
        "    #print(f'Total pnl for {tic}: {np.sum(pnl_t)}')\n",
        "    pnl_all[tic] = np.array(pnl_t)\n",
        "    return pnl_all\n",
        "\n",
        "\n",
        "def calc_pnl_for_open_positions(acts,prices):\n",
        "    # identify any positive share values after accounting for sales\n",
        "    pnl = []\n",
        "    fp = prices[-1] # last price\n",
        "    open_pos_arg = np.argwhere(acts>0)\n",
        "    if len(open_pos_arg)==0:return pnl # no open positions\n",
        "\n",
        "    mkt_vals_open = np.multiply(acts[open_pos_arg], prices[open_pos_arg])\n",
        "    # mkt val at end of testing period\n",
        "    # treat as trades for purposes of calculating pnl at end of testing period\n",
        "    mkt_vals_final = np.multiply(fp, acts[open_pos_arg])\n",
        "    pnl_a = np.subtract(mkt_vals_final, mkt_vals_open)\n",
        "    #convert to list\n",
        "    pnl = [i[0] for i in pnl_a.tolist()]\n",
        "    #print(f'Market value of open positions at end of testing {pnl}')\n",
        "    return pnl\n",
        "\n",
        "\n",
        "def calc_trade_perf(pnl_d):\n",
        "    # calculate trade performance metrics\n",
        "    perf_results = {}\n",
        "    for t,pnl in pnl_d.items():\n",
        "        wins = pnl[pnl>0]  # total val\n",
        "        losses = pnl[pnl<0]\n",
        "        n_wins = len(wins)\n",
        "        n_losses = len(losses)\n",
        "        n_trades = n_wins + n_losses\n",
        "        wins_val = np.sum(wins)\n",
        "        losses_val = np.sum(losses)\n",
        "        wins_avg = 0 if n_wins==0 else np.mean(wins)\n",
        "        #print(f'{t} n_wins: {n_wins} n_losses: {n_losses}')\n",
        "        losses_avg = 0 if n_losses==0 else np.mean(losses)\n",
        "        d = {'# trades':n_trades,'# wins':n_wins,'# losses':n_losses,\n",
        "             'wins total value':wins_val, 'wins avg value':wins_avg,\n",
        "             'losses total value':losses_val, 'losses avg value':losses_avg,}\n",
        "        perf_results[t] = d\n",
        "    return perf_results"
      ],
      "metadata": {
        "id": "QydaFexDX5BQ"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning hyperparameters using Optuna"
      ],
      "metadata": {
        "id": "c_AT1dsuZApj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_ddpg_params(trial:optuna.Trial):\n",
        "  # Size of the replay buffer\n",
        "  buffer_size = trial.suggest_categorical(\"buffer_size\", [int(1e4), int(1e5), int(1e6)])\n",
        "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256, 512])\n",
        "  \n",
        "  return {\"buffer_size\": buffer_size,\n",
        "          \"learning_rate\":learning_rate,\n",
        "          \"batch_size\":batch_size}"
      ],
      "metadata": {
        "id": "fKGkKHV7Y9AA"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Variables\n",
        "## Fixed\n",
        "tpm_hist = {}  # record tp metric values for trials\n",
        "tp_metric = 'avgwl'  # specified trade_param_metric: ratio avg value win/loss\n",
        "## Settable by User\n",
        "n_trials = 50  # number of HP optimization runs\n",
        "total_timesteps = 2000 # per HP optimization run\n",
        "## Logging callback params\n",
        "lc_threshold=1e-5\n",
        "lc_patience=15\n",
        "lc_trial_number=5"
      ],
      "metadata": {
        "id": "N6blMWpz-pR0"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTIONAL CODE FOR SAMPLING HYPERPARAMETERS\n",
        "\n",
        "Replace current call in function objective with\n",
        "\n",
        "hyperparameters = sample_ddpg_params_all(trial)"
      ],
      "metadata": {
        "id": "fHET-odKZShg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_ddpg_params_all(trial:optuna.Trial,\n",
        "                           # fixed values from previous study\n",
        "                           learning_rate=0.0103,\n",
        "                           batch_size=128,\n",
        "                           buffer_size=int(1e6)):\n",
        "\n",
        "    gamma = trial.suggest_categorical(\"gamma\", [0.94, 0.96, 0.98])\n",
        "    # Polyak coeff\n",
        "    tau = trial.suggest_categorical(\"tau\", [0.08, 0.1, 0.12])\n",
        "\n",
        "    train_freq = trial.suggest_categorical(\"train_freq\", [512,768,1024])\n",
        "    gradient_steps = train_freq\n",
        "    \n",
        "    noise_type = trial.suggest_categorical(\"noise_type\", [\"ornstein-uhlenbeck\", \"normal\", None])\n",
        "    noise_std = trial.suggest_categorical(\"noise_std\", [.1,.2,.3] )\n",
        "\n",
        "    # NOTE: Add \"verybig\" to net_arch when tuning HER (see TD3)\n",
        "    net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"big\"])\n",
        "    # activation_fn = trial.suggest_categorical('activation_fn', [nn.Tanh, nn.ReLU, nn.ELU, nn.LeakyReLU])\n",
        "\n",
        "    net_arch = {\n",
        "        \"small\": [64, 64],\n",
        "        \"medium\": [256, 256],\n",
        "        \"big\": [512, 512],\n",
        "    }[net_arch]\n",
        "  \n",
        "    hyperparams = {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"buffer_size\": buffer_size,\n",
        "        \"gamma\": gamma,\n",
        "        \"gradient_steps\": gradient_steps,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"tau\": tau,\n",
        "        \"train_freq\": train_freq,\n",
        "        #\"noise_std\": noise_std,\n",
        "        #\"noise_type\": noise_type,\n",
        "        \n",
        "        \"policy_kwargs\": dict(net_arch=net_arch)\n",
        "    }\n",
        "    return hyperparams"
      ],
      "metadata": {
        "id": "htLdZHKTZKPJ"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_ddpg_params_all(trial:optuna.Trial,\n",
        "                           # fixed values from previous study\n",
        "                           learning_rate=0.0103,\n",
        "                           batch_size=128,\n",
        "                           buffer_size=int(1e6)):\n",
        "\n",
        "    gamma = trial.suggest_categorical(\"gamma\", [0.94, 0.96, 0.98])\n",
        "    # Polyak coeff\n",
        "    tau = trial.suggest_categorical(\"tau\", [0.08, 0.1, 0.12])\n",
        "\n",
        "    train_freq = trial.suggest_categorical(\"train_freq\", [512,768,1024])\n",
        "    gradient_steps = train_freq\n",
        "    \n",
        "    noise_type = trial.suggest_categorical(\"noise_type\", [\"ornstein-uhlenbeck\", \"normal\", None])\n",
        "    noise_std = trial.suggest_categorical(\"noise_std\", [.1,.2,.3] )\n",
        "\n",
        "    # NOTE: Add \"verybig\" to net_arch when tuning HER (see TD3)\n",
        "    net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"big\"])\n",
        "    # activation_fn = trial.suggest_categorical('activation_fn', [nn.Tanh, nn.ReLU, nn.ELU, nn.LeakyReLU])\n",
        "\n",
        "    net_arch = {\n",
        "        \"small\": [64, 64],\n",
        "        \"medium\": [256, 256],\n",
        "        \"big\": [512, 512],\n",
        "    }[net_arch]\n",
        "  \n",
        "    hyperparams = {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"buffer_size\": buffer_size,\n",
        "        \"gamma\": gamma,\n",
        "        \"gradient_steps\": gradient_steps,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"tau\": tau,\n",
        "        \"train_freq\": train_freq,\n",
        "        #\"noise_std\": noise_std,\n",
        "        #\"noise_type\": noise_type,\n",
        "        \n",
        "        \"policy_kwargs\": dict(net_arch=net_arch)\n",
        "    }\n",
        "    return hyperparams"
      ],
      "metadata": {
        "id": "dJYdh-E4ZQKP"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Callbacks\n",
        "\n",
        "\n",
        "1. The callback will terminate if the improvement margin is below certain point\n",
        "2. It will terminate after certain number of trial_number are reached, not before that\n",
        "3. It will hold its patience to reach the threshold"
      ],
      "metadata": {
        "id": "mWEoJMPLZY4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoggingCallback:\n",
        "    def __init__(self,threshold,trial_number,patience):\n",
        "      '''\n",
        "      threshold:int tolerance for increase in objective\n",
        "      trial_number: int Prune after minimum number of trials\n",
        "      patience: int patience for the threshold\n",
        "      '''\n",
        "      self.threshold = threshold\n",
        "      self.trial_number  = trial_number\n",
        "      self.patience = patience\n",
        "      print(f'Callback threshold {self.threshold}, \\\n",
        "            trial_number {self.trial_number}, \\\n",
        "            patience {self.patience}')\n",
        "      self.cb_list = [] #Trials list for which threshold is reached\n",
        "    def __call__(self,study:optuna.study, frozen_trial:optuna.Trial):\n",
        "      #Setting the best value in the current trial\n",
        "      study.set_user_attr(\"previous_best_value\", study.best_value)\n",
        "      \n",
        "      #Checking if the minimum number of trials have pass\n",
        "      if frozen_trial.number >self.trial_number:\n",
        "          previous_best_value = study.user_attrs.get(\"previous_best_value\",None)\n",
        "          #Checking if the previous and current objective values have the same sign\n",
        "          if previous_best_value * study.best_value >=0:\n",
        "              #Checking for the threshold condition\n",
        "              if abs(previous_best_value-study.best_value) < self.threshold: \n",
        "                  self.cb_list.append(frozen_trial.number)\n",
        "                  #If threshold is achieved for the patience amount of time\n",
        "                  if len(self.cb_list)>self.patience:\n",
        "                      print('The study stops now...')\n",
        "                      print('With number',frozen_trial.number ,'and value ',frozen_trial.value)\n",
        "                      print('The previous and current best values are {} and {} respectively'\n",
        "                              .format(previous_best_value, study.best_value))\n",
        "                      study.stop()"
      ],
      "metadata": {
        "id": "He7GTZZUZWP8"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import sys   \n",
        "\n",
        "os.makedirs(\"models\",exist_ok=True)\n",
        "\n",
        "def objective(trial:optuna.Trial):\n",
        "  #Trial will suggest a set of hyperparamters from the specified range\n",
        "\n",
        "  # Optional to optimize larger set of parameters\n",
        "  # hyperparameters = sample_ddpg_params_all(trial)\n",
        "  \n",
        "  # Optimize buffer size, batch size, learning rate\n",
        "  hyperparameters = sample_ddpg_params_all(trial)\n",
        "  print(f'Hyperparameters from objective: {hyperparameters.keys()}')\n",
        "  policy_kwargs = None  # default\n",
        "  if 'policy_kwargs' in hyperparameters.keys():\n",
        "    policy_kwargs = hyperparameters['policy_kwargs']\n",
        "    del hyperparameters['policy_kwargs']\n",
        "    print(f'Policy keyword arguments {policy_kwargs}')\n",
        "  model_ddpg = agent.get_model(\"ddpg\",\n",
        "                               policy_kwargs = policy_kwargs,\n",
        "                               model_kwargs = hyperparameters )\n",
        "  \n",
        "  #You can increase it for better comparison\n",
        "  trained_ddpg = agent.train_model(model=model_ddpg,\n",
        "                                   tb_log_name=\"ddpg\",\n",
        "                                   total_timesteps=total_timesteps)\n",
        "  trained_ddpg.save('models/ddpg_{}.pth'.format(trial.number))\n",
        "  clear_output(wait=True)\n",
        "  \n",
        "  #For the given hyperparamters, determine the account value in the trading period\n",
        "  df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
        "    model=trained_ddpg, \n",
        "    environment = e_trade_gym)\n",
        " \n",
        "  # Calculate trade performance metric\n",
        "  # Currently ratio of average win and loss market values\n",
        "  tpm = calc_trade_perf_metric(df_actions,init_trade_data,tp_metric)\n",
        "  return tpm\n",
        "\n",
        "#Create a study object and specify the direction as 'maximize'\n",
        "#As you want to maximize sharpe\n",
        "#Pruner stops not promising iterations\n",
        "#Use a pruner, else you will get error related to divergence of model\n",
        "#You can also use Multivariate samplere\n",
        "#sampler = optuna.samplers.TPESampler(multivarite=True,seed=42)\n",
        "sampler = optuna.samplers.TPESampler()\n",
        "\n",
        "study = optuna.create_study(study_name=\"ddpg_study\",direction='maximize',\n",
        "                            sampler = sampler, pruner=optuna.pruners.HyperbandPruner())\n",
        "\n",
        "logging_callback = LoggingCallback(threshold=lc_threshold,\n",
        "                                   patience=lc_patience,\n",
        "                                   trial_number=lc_trial_number)\n",
        "#You can increase the n_trials for a better search space scanning\n",
        "study.optimize(objective, n_trials=n_trials,catch=(ValueError,),callbacks=[logging_callback])"
      ],
      "metadata": {
        "id": "b6EiwiiIZpRU",
        "outputId": "2fc4d143-998d-4f03-8197-bae4f8f9dfa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-27 17:53:30,707]\u001b[0m A new study created in memory with name: ddpg_study\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Callback threshold 1e-05,             trial_number 5,             patience 15\n",
            "Hyperparameters from objective: dict_keys(['batch_size', 'buffer_size', 'gamma', 'gradient_steps', 'learning_rate', 'tau', 'train_freq', 'policy_kwargs'])\n",
            "Policy keyword arguments {'net_arch': [512, 512]}\n",
            "{'batch_size': 128, 'buffer_size': 1000000, 'gamma': 0.96, 'gradient_steps': 512, 'learning_rate': 0.0103, 'tau': 0.08, 'train_freq': 512}\n",
            "Using cuda device\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "Total Stocks\n",
            "[39  9  9  0  0  0  5  0  8  0  0  0 83 48 62 11  0  0  0  0  0 44 22 39\n",
            "  0 60 61 97 61]\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 2\n",
            "stocks Sold sell_num_shares 2\n",
            "Total Stocks\n",
            "[ 17 101  49  78   0  95  31  39  58   0  61   0 147  79  18  56  45   0\n",
            "  92   0   0 109  88   9  14   0  59 130  54]\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 0\n",
            "Total Stocks\n",
            "[  0 179  50   0   0  43  41  44   0   0  28  74 138   3   0  32   6  78\n",
            " 113  63  13 141 166  91  44  93   0 125 138]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[ 65 178  78  38  51   0  62 110   0   0   0 120 151   2   0  58   0  89\n",
            "  91 118   0 239 119 190 110  86  72 114  56]\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 2\n",
            "stocks Sold sell_num_shares 2\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "Total Stocks\n",
            "[113 239  10   1   0   0 132 189  82   0   0  97 179   0   0   0   0 158\n",
            "  20 205  52 297  74 176  79   0 101  18  16]\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 13\n",
            "Total Stocks\n",
            "[208 273   0   0  37   0 106 166 131  26   0  27 128   0  59  57   0 225\n",
            "  20 209  39 297 114 131  97   0  23 100  16]\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "Total Stocks\n",
            "[200 366  46   0  19  60 196 234  99   4   0  92  31  17  31 110  41 211\n",
            "  24 137   0 372  37  53  75  23  39  52   0]\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 15\n",
            "stocks Sold sell_num_shares 15\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "Total Stocks\n",
            "[144 280  18   0   4   0 243 282  91   0  62   0  72  93 118 191   0 306\n",
            "  85 137  16 351  49  42 123   0   0  23  77]\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "Total Stocks\n",
            "[132 212   0   0   0  76 183 314 106   0   0   6 156  21  76 251   0 335\n",
            "  17 116   0 315  43  67 139  41   0   0  95]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "Total Stocks\n",
            "[214 233   0  68   0 102 240 260  32  59   0  29  72  81  97 165   0 255\n",
            " 100 120  61 323   0  35 157  85  86   0  72]\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "Total Stocks\n",
            "[128 184  52  89  41 137 253 318   0  86  91   0  53  62 157 143   3 246\n",
            " 185  57  86 313  29  15  77  64  41  28  51]\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "Total Stocks\n",
            "[ 66  91 135 105   0  56 231 318  68   3 112   0   0   0 149  53   0 321\n",
            " 127  33 142 411   0  42  33  83 124  15  63]\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 2\n",
            "stocks Sold sell_num_shares 2\n",
            "Total Stocks\n",
            "[127 188 150 101  55  82 267 325   6   0 185  88   0  93 177  23   0 325\n",
            " 168 125 240 409   0   0   0  34 159  95  66]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "Total Stocks\n",
            "[186 272 196  36 114 159 253 345  56  36 262 135  54 136 230 108   0 328\n",
            " 148  71 229 365  26   0   0 111 159  78  78]\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 46\n",
            "stocks Sold sell_num_shares 46\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[153 272 123   0  32  78 278 377 103   0 275 217   0  70 252 153   0 327\n",
            "  50  87 181 453  38   0   0 157 113  48 132]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[207 295 173   0  84   3 329 416  14   0 284 212  10 145 259 125   0 324\n",
            "  46 176 197 453   6  18   0 194  43  59 118]\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 46\n",
            "stocks Sold sell_num_shares 46\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[236 351 191  49 120   0 358 457   0   0 202 159   0 237 163 220   0 283\n",
            " 134 238 260 383   0  84  41 206   0  42  72]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "Total Stocks\n",
            "[311 309 129 118  35  68 274 393   0   0 123 117   0 280 128 294   0 278\n",
            " 221 273 254 438  23 164  98 249   0 129 124]\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 67\n",
            "stocks Sold sell_num_shares 67\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 7\n",
            "Total Stocks\n",
            "[292 255 207  20 110   0 295 326  65   0 206 147  67 273 165 260  85 320\n",
            " 179 294 265 447   0 254 181 339   0  86  51]\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 67\n",
            "stocks Sold sell_num_shares 67\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 15\n",
            "stocks Sold sell_num_shares 15\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 2\n",
            "stocks Sold sell_num_shares 2\n",
            "Total Stocks\n",
            "[357 167 186  65 127   0 279 331   0   0 266 184   0 263 173 256 129 236\n",
            " 177 333 250 457   2 310 150 377   0  72  41]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 2\n",
            "stocks Sold sell_num_shares 2\n",
            "Total Stocks\n",
            "[292 135 184  92  66  89 193 398   0   9 311 202   0 347 193 320 110 203\n",
            " 219 330 258 556  16 397 103 452   0  47  97]\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 91\n",
            "stocks Sold sell_num_shares 91\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "Total Stocks\n",
            "[278 143  89  68   0  90 137 321  60  85 261 194  22 326 220 337 102 234\n",
            " 286 307 246 602  21 303  14 499  24  35   6]\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "Total Stocks\n",
            "[359 148 140  39   0  45 198 245  54  40 270 234  16 362 155 238  82 255\n",
            " 236 226 158 611  56 399  55 576   0  74  82]\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "Total Stocks\n",
            "[275 100 100   0  97   0 189 293 137  26 340 172   0 320 201 271 148 286\n",
            " 181 307 209 691  26 354 108 665   0 146  64]\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 12\n",
            "Total Stocks\n",
            "[227 181  42  78 108   0 288 233 203 120 424 160   0 407 297 181 112 235\n",
            " 186 234 178 612 115 421  49 672  49 130  94]\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 91\n",
            "stocks Sold sell_num_shares 91\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 7\n",
            "Total Stocks\n",
            "[292 278   0  23  88   0 323 308 140 113 504 111   0 472 300 201  17 250\n",
            " 122 243 130 529  75 330   9 588  70 154 159]\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[312 273  56 118   0   0 323 213 169 101 475  60  13 521 263 247   0 261\n",
            "  86 266 189 526 135 388   0 654   0  86 188]\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 0\n",
            "Total Stocks\n",
            "[227 301   0  36  62  26 360 164 113  77 382   9   0 566 244 256   0 162\n",
            "  28 238 279 587 223 354  62 598   0  97 259]\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 46\n",
            "stocks Sold sell_num_shares 46\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "Total Stocks\n",
            "[277 346  57   0  53  54 402  89 113  31 316   0   9 560 273 183  30 228\n",
            "  32 252 211 657 147 357 145 608   0   9 184]\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "Total Stocks\n",
            "[277 270 131  66 134  37 440   0  74  56 224  25   0 520 307 265  80 148\n",
            " 125 303 132 711 169 374 123 681   0   0  92]\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[305 328 159   0  45   0 480  65  73   3 145  30  31 497 287 321  80 119\n",
            "  48 373 129 717 182 470 203 727   0  37 160]\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "Total Stocks\n",
            "[369 233 128  86   0   0 442   6  18   5 232  87   0 460 358 301  46 178\n",
            "  28 315  65 618 104 448 239 674   0   0 138]\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 46\n",
            "stocks Sold sell_num_shares 46\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[442 302  54   0  88  84 448  25  87  86 249 124  82 503 456 215   0 245\n",
            "  27 375  83 713  83 358 260 744   0  62 184]\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "Total Stocks\n",
            "[524 282  24  60  48 118 395  47 156  16 169 208   0 443 467 291  21 290\n",
            "  22 430   0 629  20 269 178 674   0   0 265]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 27\n",
            "stocks Sold sell_num_shares 27\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 2\n",
            "stocks Sold sell_num_shares 2\n",
            "Total Stocks\n",
            "[570 315  85 159   0 145 421   2  87   0 263 293  10 416 566 310 107 303\n",
            "  92 469   0 584  18 206 129 636  66   0 279]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 27\n",
            "stocks Sold sell_num_shares 27\n",
            "Total Stocks\n",
            "[642 223 109 184   7 204 394  99  96   0 227 245   0 351 596 357 194 353\n",
            " 129 567   0 539   0 121  60 677 109   8 186]\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 0\n",
            "Total Stocks\n",
            "[651 244 165 113  25 203 352  49 145   0 229 192   0 308 605 430 116 364\n",
            " 107 505  28 473   0 220  41 661  98  41 136]\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "Total Stocks\n",
            "[588 258 156  21  39 162 402  41 174   0 303 193   0 407 507 495 118 303\n",
            " 117 544  42 442   0 302  33 568 138 137 198]\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[645 310  62   0  79 195 309  43 170   0 370 185  53 341 578 565  87 369\n",
            " 140 471   0 540  63 299  79 614 214 209  99]\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[576 355  61   0  96 120 374 121 123  63 460 205 150 402 492 580 109 328\n",
            "  95 506   0 544   0 346 163 527 291 168 181]\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 27\n",
            "stocks Sold sell_num_shares 27\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[491 328 123  16 110 210 451 146  53   0 540 192 156 321 476 488 109 280\n",
            " 193 537   0 635  89 343 171 551 337  89 113]\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[555 283 127   0  14 209 430 111  30   0 492 185 234 223 464 469  80 355\n",
            " 205 462  84 701  97 419 216 483 421 151 183]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "Total Stocks\n",
            "[514 250 212   0   0 134 395  95 115   0 403 165 260 145 507 395 113 306\n",
            " 147 424 118 774  47 365 249 518 378 188 278]\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[554 185 245   0  21 140 374 101 142   0 498  83 257 237 521 331 164 270\n",
            " 200 361  37 682 131 437 163 515 407 139 194]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "Total Stocks\n",
            "[579 116 227   0   0 129 363 162 116   0 468  55 202 163 507 369  83 237\n",
            " 178 391   3 781  98 455 195 543 454 109 275]\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "Total Stocks\n",
            "[497 176 259  48   0  97 328  77  96  71 532   0 260 166 409 411  85 228\n",
            " 266 306   0 834 170 392 195 583 462  95 246]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[531  87 222  10   0  63 291  65 135 168 599  51 274 227 372 395 157 308\n",
            " 261 305   0 791 192 339 265 551 398  96 278]\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "Total Stocks\n",
            "[567   0 284   0   0  31 226   0  69 209 516   2 325 259 295 405 225 326\n",
            " 168 235  52 696 262 251 228 636 462  61 210]\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "Total Stocks\n",
            "[506   0 212   0   0 120 265  57 161 192 505  74 396 272 297 310 253 326\n",
            " 119 161  47 609 186 274 176 631 436  95 297]\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[582  51 165  33  57  89 319 137 205 117 500 166 358 216 306 249 250 330\n",
            "  38  62   0 601 149 254 156 549 392 187 254]\n",
            "stocks Sold sell_num_shares 91\n",
            "stocks Sold sell_num_shares 91\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 12\n",
            "Total Stocks\n",
            "[649  39 120  47   0  63 347 221 206  60 521  75 380 301 341 345 226 427\n",
            " 105 143   0 561 101 314 191 509 453 257 194]\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "Total Stocks\n",
            "[728  98 167   0   9  15 446 213 156   0 470   0 423 231 323 354 177 464\n",
            "  65 229  87 520 157 240 213 451 387 308 281]\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 15\n",
            "stocks Sold sell_num_shares 15\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "Total Stocks\n",
            "[659  61 109   0   0   0 395 168 251   7 526   0 326 313 225 276 209 438\n",
            " 139 217  18 440 176 241 205 483 427 338 291]\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 0\n",
            "Total Stocks\n",
            "[738  40 193  85   0   0 317 209 324   0 507   0 378 296 188 267 228 438\n",
            "  40 254   0 487  83 272 294 398 522 260 246]\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[724  16 285  10  94  48 232 303 323   0 485  45 461 384 270 320 254 470\n",
            "   0 165   0 399  76 288 359 479 552 244 322]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 8\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 7\n",
            "Total Stocks\n",
            "[784  42 210  78 139  81 309 356 323  10 436   0 517 377 242 292 267 494\n",
            "  22 141   0 439  68 288 296 496 593 274 379]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 7\n",
            "Total Stocks\n",
            "[848 107 221 161 101   0 317 347 253  97 395   0 518 379 186 285 194 536\n",
            "  29 120  60 483 147 362 223 454 511 249 412]\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "Total Stocks\n",
            "[791  97 308 223  57  51 265 377 304 137 353   0 607 351 259 333 194 467\n",
            "  29 202  72 483  99 392 283 454 596 238 412]\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "Total Stocks\n",
            "[754   3 214 288   3 137 200 294 299  41 290  93 510 382 274 387 235 510\n",
            "   4 236 142 426 124 453 344 430 506 143 445]\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "Total Stocks\n",
            "[732   0 179 288  90 137 158 375 294 138 211 185 510 372 219 477 200 557\n",
            "   4 137 214 348  92 440 344 372 449 123 423]\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 4.0\n",
            "stocks Sold sell_num_shares 4.0\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "Total Stocks\n",
            "[683   0 163 316  32  93 200 328 364 150 201 134 426 285 310 435 158 642\n",
            "   0  76 175 264 185 533 262 320 488  86 520]\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "Total Stocks\n",
            "[749   0 230 266   0  14 261 331 457 221 185 110 487 286 310 435 138 566\n",
            "  95 146  85 353 185 533 312 367 488 184 457]\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 14.0\n",
            "stocks Sold sell_num_shares 14.0\n",
            "stocks Sold sell_num_shares 15\n",
            "stocks Sold sell_num_shares 15\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[845  90 178 266   0   0 334 266 396 221 133  95 487 362 386 429 129 566\n",
            " 120 147  82 353 275 454 312 285 425 184 457]\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[940  90 178 193   0   0 427 265 459 159 199 133 412 321 462 359 217 487\n",
            "  90 226  82 434 272 500 270 366 337 184 364]\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 15\n",
            "stocks Sold sell_num_shares 15\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "Total Stocks\n",
            "[940  90 178 193   0   0 428 265 551 159 199 113 412 283 552 359 307 482\n",
            "  75 209  82 434 272 500 270 314 337 277 266]\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 27\n",
            "stocks Sold sell_num_shares 27\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "Total Stocks\n",
            "[863 187 139 130   0   0 524 193 552 222 199  74 358 353 603 425 287 453\n",
            "  48 183  82 389 272 468 249 356 337 206 292]\n",
            "stocks Sold sell_num_shares 82.0\n",
            "stocks Sold sell_num_shares 82.0\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 10\n",
            "stocks Sold sell_num_shares 10\n",
            "Total Stocks\n",
            "[863 177 227 130   0   0 525 261 480 222 199  99 444 354 603 374 287 526\n",
            "  48 279   0 389 272 418 249 356 319 159 220]\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 15\n",
            "stocks Sold sell_num_shares 15\n",
            "Total Stocks\n",
            "[880 238 128  53   0   0 548 246 447 302 213 113 364 274 614 306 377 434\n",
            "  71 334   0 317 355 496 263 279 281 226 127]\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "Total Stocks\n",
            "[880 164 218  53   0  78 548 246 543 302 193  68 353 274 614 238 442 340\n",
            "  40 334   0 317 448 496 358 259 353 217 196]\n",
            "stocks Sold sell_num_shares 67\n",
            "stocks Sold sell_num_shares 67\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 23\n",
            "stocks Sold sell_num_shares 23\n",
            "Total Stocks\n",
            "[880 138 218  53   0 162 630 246 627 277 193 150 353 352 557 238 442 340\n",
            "  72 311   0 288 448 496 305 259 354 175 129]\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 53.0\n",
            "stocks Sold sell_num_shares 53.0\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "Total Stocks\n",
            "[944 154 224   0  85 208 572 199 539 255 133 114 290 255 644 198 451 435\n",
            " 156 294   0 295 481 547 273 162 354 266 169]\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "Total Stocks\n",
            "[1014  248  272    0  181  116  621  193  505  195   57   22  350  265\n",
            "  724  231  426  348  221  217    0  326  483  534  228   99  261  194\n",
            "   77]\n",
            "stocks Sold sell_num_shares 77.0\n",
            "stocks Sold sell_num_shares 77.0\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 22.0\n",
            "stocks Sold sell_num_shares 22.0\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 35\n",
            "Total Stocks\n",
            "[1014  347  208    0  185   42  683  201  415  253   82    0  290  185\n",
            "  689  292  462  370  143  261    0  390  542  597  302  159  336  137\n",
            "    0]\n",
            "stocks Sold sell_num_shares 42.0\n",
            "stocks Sold sell_num_shares 42.0\n",
            "stocks Sold sell_num_shares 82.0\n",
            "stocks Sold sell_num_shares 82.0\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 61\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 0\n",
            "Total Stocks\n",
            "[973 270 301   0 218   0 729 201 323 259   0   0 202 256 656 278 527 311\n",
            "  73 192   0 302 600 545 241 133 251 138   0]\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 93\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 34\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "Total Stocks\n",
            "[919 191 333   0 304   0 767 118 291 185  88   0 234 204 614 216 493 217\n",
            " 165 267   0 285 507 469 287  93 265  39   0]\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 95\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 39.0\n",
            "stocks Sold sell_num_shares 39.0\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[960 203 274   0 387  26 710 175 352 154 184   0 293 151 536 187 406 184\n",
            " 195 335   0 324 520 374 346  92 195   0   0]\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[907 224 245   0 382  49 651 270 351 135 234   0 385 209 488 151 399 129\n",
            " 146 368  42 319 424 354 281 123 163   0  67]\n",
            "stocks Sold sell_num_shares 49.0\n",
            "stocks Sold sell_num_shares 49.0\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 38\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "Total Stocks\n",
            "[829 210 166  30 457   0 565 272 273 225 164  77 483 233 415 225 406 166\n",
            " 152 408  21 327 386 304 228  79 243  92 112]\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 99\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 21.0\n",
            "stocks Sold sell_num_shares 21.0\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 51\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 32\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 27\n",
            "stocks Sold sell_num_shares 27\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[731 255 160  57 508  52 603 324 189 174 133 100 548 257 347 207 453 165\n",
            "  53 439   0 343 314 354 196  42 289 134  85]\n",
            "stocks Sold sell_num_shares 91\n",
            "stocks Sold sell_num_shares 91\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 53.0\n",
            "stocks Sold sell_num_shares 53.0\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 24\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "Total Stocks\n",
            "[640 310 215 133 596  35 646 310 112 125 139 171 604 297 326 284 484 109\n",
            "   0 513   4 338 244 444 120  50 265 232 164]\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 89\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 82\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 4.0\n",
            "stocks Sold sell_num_shares 4.0\n",
            "stocks Sold sell_num_shares 27\n",
            "stocks Sold sell_num_shares 27\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 21\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 13\n",
            "Total Stocks\n",
            "[620 370 304  44 580  64 565 375  91 161 208 203 625 369 244 188 572  64\n",
            "  17 486   0 381 327 431  65 137 328 180  96]\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 58\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 28\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 16\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 12\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "Total Stocks\n",
            "[577 339 241 123 523  65 601 398  29 128 192 124 694 441 238 130 669 109\n",
            "  30 562   0 353 376 495  43 174 316 131 167]\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 29.0\n",
            "stocks Sold sell_num_shares 29.0\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 88\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 30\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[591 378 285 210 608  92 649 395   0  41 230 187 664 412 273  45 713 179\n",
            "  80 561  28 276 341 486  74  86 226 225 171]\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 74.0\n",
            "stocks Sold sell_num_shares 74.0\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 65\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[607 401 315 163 662  93 686 301  34  93 239 216 599 369 218 119 693 176\n",
            "  25 483 104 289 273 457   0 164 248 274 225]\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 72\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 25.0\n",
            "stocks Sold sell_num_shares 25.0\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 35\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 13\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[691 463 312 240 662  15 752 385 133 171 167 227 697 307 263 147 622 244\n",
            "   0 518 188 220 238 444  81 133 152 315 310]\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 15.0\n",
            "stocks Sold sell_num_shares 15.0\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 53\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 40\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 36\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 7\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "Total Stocks\n",
            "[631 549 249 286 622   0 700 359 126 101 167 178 759 285 263 111 644 342\n",
            "   0 492 134 308 238 439  81  80 250 232 367]\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 86\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 54\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 5\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[631 504 192 367 715  85 646 359  29 193  87 107 759 286 252 111 644 342\n",
            "   0 492 134 303 165 439 139  80 247 146 367]\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 77\n",
            "stocks Sold sell_num_shares 29.0\n",
            "stocks Sold sell_num_shares 29.0\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 56\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 46\n",
            "stocks Sold sell_num_shares 46\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 39\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 31\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[550 518 237 350 712  39 648 388   0 151 101 174 777 369 168  78 741 352\n",
            "   0 442 203 241  71 383  62  41 216 159 429]\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 96\n",
            "stocks Sold sell_num_shares 91\n",
            "stocks Sold sell_num_shares 91\n",
            "stocks Sold sell_num_shares 62.0\n",
            "stocks Sold sell_num_shares 62.0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 75\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 70\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 68\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 66\n",
            "stocks Sold sell_num_shares 39.0\n",
            "stocks Sold sell_num_shares 39.0\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 9\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 4\n",
            "Total Stocks\n",
            "[541 549 240 388 703   0 709 397   0 226  26 170 842 273 102  60 660 375\n",
            "   0 453 253 150 158 313   0 101 148 126 513]\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 97\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 76\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 41\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 29\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 25\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 14\n",
            "stocks Sold sell_num_shares 11\n",
            "stocks Sold sell_num_shares 11\n",
            "Total Stocks\n",
            "[624 625 240 374 763  56 684 397  51 129 107  94 903 326 102 125 746 442\n",
            "   0 406 231 191 147 233   7  60 148 132 484]\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 73\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 71\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 50\n",
            "stocks Sold sell_num_shares 7.0\n",
            "stocks Sold sell_num_shares 7.0\n",
            "stocks Sold sell_num_shares 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m[W 2023-04-27 17:53:32,472]\u001b[0m Trial 0 failed with parameters: {'gamma': 0.96, 'tau': 0.08, 'train_freq': 512, 'noise_type': 'normal', 'noise_std': 0.1, 'net_arch': 'big'} because of the following error: KeyboardInterrupt().\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-115-66f3543408ef>\", line 25, in objective\n",
            "    trained_ddpg = agent.train_model(model=model_ddpg,\n",
            "  File \"/usr/local/lib/python3.9/site-packages/finrl/agents/stablebaselines3/models.py\", line 103, in train_model\n",
            "    model = model.learn(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py\", line 123, in learn\n",
            "    return super().learn(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/stable_baselines3/td3/td3.py\", line 216, in learn\n",
            "    return super().learn(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\", line 311, in learn\n",
            "    rollout = self.collect_rollouts(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\", line 543, in collect_rollouts\n",
            "    new_obs, rewards, dones, infos = env.step(actions)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\", line 163, in step\n",
            "    return self.step_wait()\n",
            "  File \"/usr/local/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\", line 54, in step_wait\n",
            "    obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n",
            "  File \"<ipython-input-104-0911b98c4317>\", line 293, in step\n",
            "    actions[index] = self._sell_stock(index, actions[index]) * (-1)\n",
            "  File \"<ipython-input-104-0911b98c4317>\", line 171, in _sell_stock\n",
            "    sell_num_shares = _do_sell_normal()\n",
            "  File \"<ipython-input-104-0911b98c4317>\", line 134, in _do_sell_normal\n",
            "    print(\"stocks Sold sell_num_shares\", sell_num_shares)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\", line 402, in write\n",
            "    self.pub_thread.schedule(lambda : self._buffer.write(string))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\", line 203, in schedule\n",
            "    self._event_pipe.send(b'')\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/zmq/sugar/socket.py\", line 618, in send\n",
            "    return super().send(data, flags=flags, copy=copy, track=track)\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 740, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 787, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 244, in zmq.backend.cython.socket._send_copy\n",
            "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
            "KeyboardInterrupt\n",
            "\u001b[33m[W 2023-04-27 17:53:32,474]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stocks Sold sell_num_shares 47\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[591 628 321 327 680  83 586 439   1  84  34  95 811 255 122  92 740 496\n",
            "  58 342 228 239 183 327   0  60 242 219 451]\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 81\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 78\n",
            "stocks Sold sell_num_shares 58.0\n",
            "stocks Sold sell_num_shares 58.0\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 69\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 63\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 42\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "Total Stocks\n",
            "[543 568 384 264 759 172 617 402  94  64  94   5 719 326  53  33 722 417\n",
            "   0 351 145 206 105 333   0 144 161 170 409]\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 92\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 26\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 1\n",
            "stocks Sold sell_num_shares 1\n",
            "Total Stocks\n",
            "[585 488 388 314 810 129 562 402 180  42   2  95 693 334  88  81 748 472\n",
            "  51 363 148 225 119 249   0 215 160 257 420]\n",
            "stocks Sold sell_num_shares 42.0\n",
            "stocks Sold sell_num_shares 42.0\n",
            "stocks Sold sell_num_shares 51.0\n",
            "stocks Sold sell_num_shares 51.0\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 62\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 52\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 43\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "Total Stocks\n",
            "[523 537 298 407 810 129 500 402 137   0  75 172 693 334 178  81 829 472\n",
            "   0 311 148 225 206 230   0 195 237 257 502]\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 98\n",
            "stocks Sold sell_num_shares 75.0\n",
            "stocks Sold sell_num_shares 75.0\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 80\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 79\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 74\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 60\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 59\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 55\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 6\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 4\n",
            "stocks Sold sell_num_shares 0\n",
            "Total Stocks\n",
            "[505 537 339 327 804 204 445 486 137   0   0 265 693 236  99 136 825 533\n",
            "  53 312 227 166 158 243   0 135 311 349 428]\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 94\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 85\n",
            "stocks Sold sell_num_shares 67\n",
            "stocks Sold sell_num_shares 67\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 64\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 49\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 48\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 45\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 19\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 17\n",
            "stocks Sold sell_num_shares 17\n",
            "Total Stocks\n",
            "[505 623 437 260 719 204 396 392  89   0   0 265 756 236 192  91 911 515\n",
            "  53 295 227 166 243 224   0  91 312 349 364]\n",
            "stocks Sold sell_num_shares 91.0\n",
            "stocks Sold sell_num_shares 91.0\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 90\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 87\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 84\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 83\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 57\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 44\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 37\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 33\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 22\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 20\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 18\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 0\n",
            "stocks Sold sell_num_shares 3\n",
            "stocks Sold sell_num_shares 3\n",
            "Total Stocks\n",
            "[585 539 460 173 699 201 363 302 105   0   0 309 819 214 148 180 893 581\n",
            "  35 319 144 188 206 140   0   0 387 378 307]\n",
            "stocks Sold sell_num_shares"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-66f3543408ef>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m                                    trial_number=lc_trial_number)\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#You can increase the n_trials for a better search space scanning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogging_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-115-66f3543408ef>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m#You can increase it for better comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   trained_ddpg = agent.train_model(model=model_ddpg,\n\u001b[0m\u001b[1;32m     26\u001b[0m                                    \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ddpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                    total_timesteps=total_timesteps)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         model = model.learn(\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     ) -> SelfDDPG:\n\u001b[0;32m--> 123\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/td3/td3.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     ) -> SelfTD3:\n\u001b[0;32m--> 216\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             rollout = self.collect_rollouts(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mtrain_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;31m# Rescale and perform action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \"\"\"\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVecEnvStepReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-104-0911b98c4317>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msell_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m               \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sell_stock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuy_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-0911b98c4317>\u001b[0m in \u001b[0;36m_sell_stock\u001b[0;34m(self, index, action)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0msell_num_shares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_do_sell_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0msell_num_shares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_do_sell_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stocks Sold sell_num_shares\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msell_num_shares\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msell_num_shares\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-0911b98c4317>\u001b[0m in \u001b[0;36m_do_sell_normal\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrades\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msell_num_shares\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stocks Sold sell_num_shares\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msell_num_shares\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0msell_num_shares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(study, \"final_ddpg_study__.pkl\")"
      ],
      "metadata": {
        "id": "1yIXC6W2ZqPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the best hyperparamters\n",
        "print('Hyperparameters after tuning',study.best_params)\n",
        "print('Hyperparameters before tuning',config.DDPG_PARAMS)"
      ],
      "metadata": {
        "id": "gXzfenQTdqq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_trial"
      ],
      "metadata": {
        "id": "VQcuj-yidu0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DDPG\n",
        "tuned_model_ddpg = DDPG.load('models/ddpg_{}.pth'.format(study.best_trial.number),env=env_train)"
      ],
      "metadata": {
        "id": "ZjYe9lOIdw3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Trading period account value with tuned model\n",
        "df_account_value_tuned, df_actions_tuned = DRLAgent.DRL_prediction(\n",
        "    model=tuned_model_ddpg, \n",
        "    environment = e_trade_gym)"
      ],
      "metadata": {
        "id": "3bnbx87vdzHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Backtesting with our pruned model\n",
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all_tuned = backtest_stats(account_value=df_account_value_tuned)\n",
        "perf_stats_all_tuned = pd.DataFrame(perf_stats_all_tuned)\n",
        "perf_stats_all_tuned.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_tuned_\"+now+'.csv')"
      ],
      "metadata": {
        "id": "FJrv144od3G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now train with not tuned hyperaparameters\n",
        "#Default config.ddpg_PARAMS\n",
        "non_tuned_model_ddpg = agent.get_model(\"ddpg\",model_kwargs = config.DDPG_PARAMS )\n",
        "trained_ddpg = agent.train_model(model=non_tuned_model_ddpg, \n",
        "                             tb_log_name='ddpg',\n",
        "                             total_timesteps=50000)"
      ],
      "metadata": {
        "id": "asWsWzemd5dk",
        "outputId": "e96edc18-f8cc-4ac1-e566-c5292cf1ea8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cuda device\n",
            "day: 2892, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3738292.05\n",
            "total_reward: 2738292.05\n",
            "total_cost: 999.00\n",
            "total_trades: 52056\n",
            "Sharpe: 0.719\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 77        |\n",
            "|    time_elapsed    | 148       |\n",
            "|    total_timesteps | 11572     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 60.3      |\n",
            "|    critic_loss     | 2.21e+03  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 8679      |\n",
            "|    reward          | 2.2091973 |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 73        |\n",
            "|    time_elapsed    | 313       |\n",
            "|    total_timesteps | 23144     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 28.3      |\n",
            "|    critic_loss     | 11        |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 20251     |\n",
            "|    reward          | 2.2091973 |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 72        |\n",
            "|    time_elapsed    | 478       |\n",
            "|    total_timesteps | 34716     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 13.8      |\n",
            "|    critic_loss     | 2.74      |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 31823     |\n",
            "|    reward          | 2.2091973 |\n",
            "----------------------------------\n",
            "day: 2892, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3738292.05\n",
            "total_reward: 2738292.05\n",
            "total_cost: 999.00\n",
            "total_trades: 52056\n",
            "Sharpe: 0.719\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 71        |\n",
            "|    time_elapsed    | 644       |\n",
            "|    total_timesteps | 46288     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.79      |\n",
            "|    critic_loss     | 1.57      |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 43395     |\n",
            "|    reward          | 2.2091973 |\n",
            "----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
        "    model=trained_ddpg, \n",
        "    environment = e_trade_gym)"
      ],
      "metadata": {
        "id": "mv1zgwOgd9FY",
        "outputId": "b61c2daa-e7e6-41af-8a20-3132f5d50657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day: 356, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1368415.68\n",
            "total_reward: 368415.68\n",
            "total_cost: 999.00\n",
            "total_trades: 6408\n",
            "Sharpe: 1.412\n",
            "=================================\n",
            "hit end!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Backtesting for not tuned hyperparamters\n",
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "# perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
      ],
      "metadata": {
        "id": "DuZL52qDeEz6",
        "outputId": "f4e9cd19-27cd-4dba-956e-353df0dabffa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Get Backtest Results===========\n",
            "Annual return          0.247826\n",
            "Cumulative returns     0.368416\n",
            "Annual volatility      0.167226\n",
            "Sharpe ratio           1.412093\n",
            "Calmar ratio           2.531845\n",
            "Stability              0.897149\n",
            "Max drawdown          -0.097883\n",
            "Omega ratio            1.280406\n",
            "Sortino ratio          2.010344\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.033938\n",
            "Daily value at risk   -0.020131\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#You can see with trial, our sharpe ratio is increasing\n",
        "#Certainly you can afford more number of trials for further optimization\n",
        "from optuna.visualization import plot_optimization_history\n",
        "plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "5aSsEmpZeI5C",
        "outputId": "4e4acb29-dc3a-4b5b-fabe-736db19aea9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.20.0.min.js\"></script>                <div id=\"6afac010-8c60-495c-b9f7-1749179d9521\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6afac010-8c60-495c-b9f7-1749179d9521\")) {                    Plotly.newPlot(                        \"6afac010-8c60-495c-b9f7-1749179d9521\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4],\"y\":[25.0,5.458908059384231,9.181461931558035,26.496666465769017,7.580685200661261],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4],\"y\":[25.0,25.0,25.0,26.496666465769017,26.496666465769017],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6afac010-8c60-495c-b9f7-1749179d9521');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from optuna.visualization import plot_contour\n",
        "from optuna.visualization import plot_edf\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_parallel_coordinate\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_slice"
      ],
      "metadata": {
        "id": "K9zcey_BeJMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparamters importance\n",
        "#Ent_coef is the most important\n",
        "plot_param_importances(study)"
      ],
      "metadata": {
        "id": "J6WmB5DneOgh",
        "outputId": "9510c118-7601-45ac-adba-0226c3c76277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.20.0.min.js\"></script>                <div id=\"79c56b7b-1dac-42d7-a7e1-58bd16ed9c0e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"79c56b7b-1dac-42d7-a7e1-58bd16ed9c0e\")) {                    Plotly.newPlot(                        \"79c56b7b-1dac-42d7-a7e1-58bd16ed9c0e\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"gamma (CategoricalDistribution): 0.051402280785507216<extra></extra>\",\"noise_std (CategoricalDistribution): 0.10120568535574027<extra></extra>\",\"noise_type (CategoricalDistribution): 0.16624172227685763<extra></extra>\",\"net_arch (CategoricalDistribution): 0.20489031403705613<extra></extra>\",\"train_freq (CategoricalDistribution): 0.22282841915371404<extra></extra>\",\"tau (CategoricalDistribution): 0.25343157839112473<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.05\",\"0.10\",\"0.17\",\"0.20\",\"0.22\",\"0.25\"],\"textposition\":\"outside\",\"x\":[0.051402280785507216,0.10120568535574027,0.16624172227685763,0.20489031403705613,0.22282841915371404,0.25343157839112473],\"y\":[\"gamma\",\"noise_std\",\"noise_type\",\"net_arch\",\"train_freq\",\"tau\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('79c56b7b-1dac-42d7-a7e1-58bd16ed9c0e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib\n",
        "    import matplotlib.pyplot as plt\n",
        "    # matplotlib.use('Agg')\n",
        "    import datetime\n",
        "\n",
        "\n",
        "    from finrl.config_tickers import DOW_30_TICKER\n",
        "    from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "    from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "    from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "    from finrl.agents.stablebaselines3.models import DRLAgent, DRLEnsembleAgent\n",
        "    from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "    from pprint import pprint\n",
        "\n",
        "    import sys\n",
        "    sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "    import itertools\n",
        "\n",
        "    import os\n",
        "    from finrl.main import check_and_make_directories\n",
        "    from finrl.config import (\n",
        "        DATA_SAVE_DIR,\n",
        "        TRAINED_MODEL_DIR,\n",
        "        TENSORBOARD_LOG_DIR,\n",
        "        RESULTS_DIR,\n",
        "        INDICATORS,\n",
        "        TRAIN_START_DATE,\n",
        "        TRAIN_END_DATE,\n",
        "        TEST_START_DATE,\n",
        "        TEST_END_DATE,\n",
        "        TRADE_START_DATE,\n",
        "        TRADE_END_DATE,\n",
        "    )\n",
        "\n",
        "    check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
        "    print(DOW_30_TICKER)\n",
        "    TRAIN_START_DATE = '2009-04-01'\n",
        "    TRAIN_END_DATE = '2021-01-01'\n",
        "    TEST_START_DATE = '2021-01-01'\n",
        "    TEST_END_DATE = '2022-06-01'\n",
        "\n",
        "    df = YahooDownloader(start_date=TRAIN_START_DATE,\n",
        "                         end_date=TEST_END_DATE,\n",
        "                         ticker_list=DOW_30_TICKER).fetch_data()\n",
        "\n",
        "    df.sort_values(['date', 'tic']).head()\n",
        "\n",
        "    fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                         tech_indicator_list=INDICATORS,\n",
        "                         use_turbulence=True,\n",
        "                         user_defined_feature=False)\n",
        "\n",
        "    processed = fe.preprocess_data(df)\n",
        "    processed = processed.copy()\n",
        "    processed = processed.fillna(0)\n",
        "    processed = processed.replace(np.inf, 0)\n",
        "\n",
        "    stock_dimension = len(processed.tic.unique())\n",
        "    state_space = 1 + 2 * stock_dimension + len(INDICATORS) * stock_dimension\n",
        "    print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
        "\n",
        "    env_kwargs = {\n",
        "        \"hmax\": 100,\n",
        "        \"initial_amount\": 1000000,\n",
        "        \"buy_cost_pct\": 0.001,\n",
        "        \"sell_cost_pct\": 0.001,\n",
        "        \"state_space\": state_space,\n",
        "        \"stock_dim\": stock_dimension,\n",
        "        \"tech_indicator_list\": INDICATORS,\n",
        "        \"action_space\": stock_dimension,\n",
        "        \"reward_scaling\": 1e-4,\n",
        "        \"print_verbosity\": 5\n",
        "\n",
        "    }\n",
        "\n",
        "    rebalance_window = 63  # rebalance_window is the number of days to retrain the model\n",
        "    validation_window = 63  # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n",
        "    ensemble_agent = DRLEnsembleAgent(df=processed,\n",
        "                                      train_period=(TRAIN_START_DATE, TRAIN_END_DATE),\n",
        "                                      val_test_period=(TEST_START_DATE, TEST_END_DATE),\n",
        "                                      rebalance_window=rebalance_window,\n",
        "                                      validation_window=validation_window,\n",
        "                                      **env_kwargs)\n",
        "\n",
        "    A2C_model_kwargs = {\n",
        "        'n_steps': 5,\n",
        "        'ent_coef': 0.005,\n",
        "        'learning_rate': 0.0007\n",
        "    }\n",
        "\n",
        "    PPO_model_kwargs = {\n",
        "        \"ent_coef\": 0.01,\n",
        "        \"n_steps\": 2048,\n",
        "        \"learning_rate\": 0.00025,\n",
        "        \"batch_size\": 128\n",
        "    }\n",
        "\n",
        "    DDPG_model_kwargs = {\n",
        "        # \"action_noise\":\"ornstein_uhlenbeck\",\n",
        "        \"buffer_size\": 10_000,\n",
        "        \"learning_rate\": 0.0005,\n",
        "        \"batch_size\": 64\n",
        "    }\n",
        "\n",
        "    timesteps_dict = {'a2c': 10_000,\n",
        "                      'ppo': 10_000,\n",
        "                      'ddpg': 10_000\n",
        "                      }\n",
        "    df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
        "                                                      PPO_model_kwargs,\n",
        "                                                      DDPG_model_kwargs,\n",
        "                                                      timesteps_dict)\n",
        "\n",
        "    unique_trade_date = processed[(processed.date > TEST_START_DATE) & (processed.date <= TEST_END_DATE)].date.unique()\n",
        "\n",
        "    df_trade_date = pd.DataFrame({'datadate': unique_trade_date})\n",
        "\n",
        "    df_account_value = pd.DataFrame()\n",
        "    for i in range(rebalance_window + validation_window, len(unique_trade_date) + 1, rebalance_window):\n",
        "        temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble', i))\n",
        "        df_account_value = df_account_value.append(temp, ignore_index=True)\n",
        "    sharpe = (252 ** 0.5) * df_account_value.account_value.pct_change(\n",
        "        1).mean() / df_account_value.account_value.pct_change(1).std()\n",
        "    print('Sharpe Ratio: ', sharpe)\n",
        "    df_account_value = df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))\n",
        "\n",
        "    df_account_value.account_value.plot()\n",
        "\n",
        "    print(\"==============Get Backtest Results===========\")\n",
        "    now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "    perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "    perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "\n",
        "    # baseline stats\n",
        "    print(\"==============Get Baseline Stats===========\")\n",
        "    baseline_df = get_baseline(\n",
        "        ticker=\"^DJI\",\n",
        "        start=df_account_value.loc[0, 'date'],\n",
        "        end=df_account_value.loc[len(df_account_value) - 1, 'date'])\n",
        "\n",
        "    stats = backtest_stats(baseline_df, value_col_name='close')\n",
        "\n",
        "    print(\"==============Compare to DJIA===========\")\n",
        "\n",
        "    # S&P 500: ^GSPC\n",
        "    # Dow Jones Index: ^DJI\n",
        "    # NASDAQ 100: ^NDX\n",
        "    backtest_plot(df_account_value,\n",
        "                  baseline_ticker='^DJI',\n",
        "                  baseline_start=df_account_value.loc[0, 'date'],\n",
        "                  baseline_end=df_account_value.loc[len(df_account_value) - 1, 'date'])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "s_xcVpBSeOyE",
        "outputId": "52b3d82a-1f8d-4af4-a405-6b5b9778781d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (96942, 8)\n",
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n",
            "Stock Dimension: 29, State Space: 291\n",
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  203.40117769841157\n",
            "======Model training from:  2009-04-01 to  2021-01-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_126_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0.00295    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -71.2      |\n",
            "|    reward             | 0.78650117 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 12.2       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0.00111    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 6.59       |\n",
            "|    reward             | 0.66569686 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 1.03       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 102       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -123      |\n",
            "|    reward             | 2.9206326 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 15.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 102        |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -6.35      |\n",
            "|    reward             | -1.8242201 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 3.27       |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 102           |\n",
            "|    iterations         | 500           |\n",
            "|    time_elapsed       | 24            |\n",
            "|    total_timesteps    | 2500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -41.2         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 499           |\n",
            "|    policy_loss        | 16            |\n",
            "|    reward             | -0.0061751665 |\n",
            "|    std                | 1             |\n",
            "|    value_loss         | 0.657         |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 102       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -33.6     |\n",
            "|    reward             | 0.5337091 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.837     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 102        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 34         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -1.97      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -76.4      |\n",
            "|    reward             | -1.3246601 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 3.85       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 39         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.0632     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 44.6       |\n",
            "|    reward             | -1.6959082 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.53       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 44       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0.0211   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -33.2    |\n",
            "|    reward             | 3.994608 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 3.53     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 101         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 49          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | 36.3        |\n",
            "|    reward             | -0.20298508 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.68        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 101         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 54          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 0.0114      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 393         |\n",
            "|    reward             | -0.92543656 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 120         |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 101          |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 59           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.2        |\n",
            "|    explained_variance | 0.0236       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | 151          |\n",
            "|    reward             | -0.099366836 |\n",
            "|    std                | 1            |\n",
            "|    value_loss         | 19.4         |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 101         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 64          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | -0.000106   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | -47.6       |\n",
            "|    reward             | -0.39146426 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 3.15        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 101         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 69          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | 31.8        |\n",
            "|    reward             | -0.25985184 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.84        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 101       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 74        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -30.8     |\n",
            "|    reward             | 3.1766434 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.93      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 78         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.00673    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 133        |\n",
            "|    reward             | -2.0720153 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 10.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 101       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 83        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -84.2     |\n",
            "|    reward             | 3.8356218 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 7         |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 88         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.063      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 42         |\n",
            "|    reward             | 0.97460705 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.23       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 101       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 93        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0.0122    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -84.7     |\n",
            "|    reward             | 2.2624621 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 8.34      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 45.9       |\n",
            "|    reward             | -1.0189797 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.77       |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2021-01-04 to  2021-04-06\n",
            "A2C Sharpe Ratio:  0.26168708794170054\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_126_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 111       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 18        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.8877938 |\n",
            "----------------------------------\n",
            "day: 2959, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3881161.61\n",
            "total_reward: 2881161.61\n",
            "total_cost: 376867.37\n",
            "total_trades: 82873\n",
            "Sharpe: 0.776\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 109         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016203282 |\n",
            "|    clip_fraction        | 0.192       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0104     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4           |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0191     |\n",
            "|    reward               | 1.0358981   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 11.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 109         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 56          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012528071 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00217    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 57          |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0176     |\n",
            "|    reward               | 0.07821791  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 55.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 107         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 76          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012139827 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00454    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 13.7        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.018      |\n",
            "|    reward               | -1.5925834  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 43.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 107         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 94          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019309906 |\n",
            "|    clip_fraction        | 0.17        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0161     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.07        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0225     |\n",
            "|    reward               | 0.0615912   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 11.3        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2021-01-04 to  2021-04-06\n",
            "PPO Sharpe Ratio:  0.3016310407987196\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_126_1\n",
            "day: 2959, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4424085.63\n",
            "total_reward: 3424085.63\n",
            "total_cost: 1037.34\n",
            "total_trades: 50241\n",
            "Sharpe: 0.797\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 78        |\n",
            "|    time_elapsed    | 151       |\n",
            "|    total_timesteps | 11840     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -60.3     |\n",
            "|    critic_loss     | 441       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 8880      |\n",
            "|    reward          | 3.0541244 |\n",
            "----------------------------------\n",
            "======DDPG Validation from:  2021-01-04 to  2021-04-06\n",
            "======Best Model Retraining from:  2009-04-01 to  2021-04-06\n",
            "======Trading from:  2021-04-06 to  2021-07-06\n",
            "============================================\n",
            "turbulence_threshold:  203.40117769841157\n",
            "======Model training from:  2009-04-01 to  2021-04-06\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_189_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 99         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | -0.446     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -85.9      |\n",
            "|    reward             | -0.6058027 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 9.16       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -19.4     |\n",
            "|    reward             | 1.8647146 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 0.253     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41      |\n",
            "|    explained_variance | 0.0122   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -179     |\n",
            "|    reward             | 3.291392 |\n",
            "|    std                | 0.996    |\n",
            "|    value_loss         | 22.1     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0.0507    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -11.1     |\n",
            "|    reward             | 0.3743614 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 1.09      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 24         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 169        |\n",
            "|    reward             | -0.3291204 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 16         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0.054      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 905        |\n",
            "|    reward             | -1.0711567 |\n",
            "|    std                | 0.994      |\n",
            "|    value_loss         | 521        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 34         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | -0.0433    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -32.9      |\n",
            "|    reward             | -2.9666545 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 0.946      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 39         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -3.25      |\n",
            "|    reward             | -0.5585839 |\n",
            "|    std                | 0.994      |\n",
            "|    value_loss         | 1.05       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | -0.66     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 306       |\n",
            "|    reward             | 2.3080251 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 70.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 49        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -108      |\n",
            "|    reward             | 1.1761196 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 10.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -117      |\n",
            "|    reward             | 3.2501192 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 10.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 59        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 362       |\n",
            "|    reward             | 6.932239  |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 84.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 64         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 44.8       |\n",
            "|    reward             | -1.5383602 |\n",
            "|    std                | 0.994      |\n",
            "|    value_loss         | 2.08       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 69        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -143      |\n",
            "|    reward             | 0.7461217 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 17        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 74         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -145       |\n",
            "|    reward             | -1.6722031 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 14.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 79        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 4.35      |\n",
            "|    reward             | 3.1992574 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 0.916     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 84        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | -0.00566  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -1.16e+03 |\n",
            "|    reward             | 11.774156 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 936       |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 89       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -40.9    |\n",
            "|    explained_variance | -0.00464 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -185     |\n",
            "|    reward             | 4.000574 |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 41.6     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 94         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 12.7       |\n",
            "|    reward             | -1.3208354 |\n",
            "|    std                | 0.991      |\n",
            "|    value_loss         | 0.306      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 99        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -10.6     |\n",
            "|    reward             | 0.7043803 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 0.431     |\n",
            "-------------------------------------\n",
            "======A2C Validation from:  2021-04-06 to  2021-07-06\n",
            "A2C Sharpe Ratio:  0.23121777505990648\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_189_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 104       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 19        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.1126131 |\n",
            "----------------------------------\n",
            "day: 3022, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3636477.12\n",
            "total_reward: 2636477.12\n",
            "total_cost: 386575.15\n",
            "total_trades: 84625\n",
            "Sharpe: 0.731\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 105         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015871149 |\n",
            "|    clip_fraction        | 0.234       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0129     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.2         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0282     |\n",
            "|    reward               | 0.88015693  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 10.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 105         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 58          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019049045 |\n",
            "|    clip_fraction        | 0.166       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.00262     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 32.1        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.023      |\n",
            "|    reward               | 0.49640504  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 53.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 105         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015561214 |\n",
            "|    clip_fraction        | 0.161       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0133     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 31.9        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0201     |\n",
            "|    reward               | -0.7624933  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 45.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 105         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 96          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014756277 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00517    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.56        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0204     |\n",
            "|    reward               | 1.2296445   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 14.8        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2021-04-06 to  2021-07-06\n",
            "PPO Sharpe Ratio:  0.010011405217654536\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_189_1\n",
            "day: 3022, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5009064.34\n",
            "total_reward: 4009064.34\n",
            "total_cost: 1282.47\n",
            "total_trades: 51375\n",
            "Sharpe: 0.880\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 76       |\n",
            "|    time_elapsed    | 157      |\n",
            "|    total_timesteps | 12092    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65.5    |\n",
            "|    critic_loss     | 3.14e+03 |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 9069     |\n",
            "|    reward          | 8.301459 |\n",
            "---------------------------------\n",
            "======DDPG Validation from:  2021-04-06 to  2021-07-06\n",
            "======Best Model Retraining from:  2009-04-01 to  2021-07-06\n",
            "======Trading from:  2021-07-06 to  2021-10-04\n",
            "============================================\n",
            "turbulence_threshold:  203.40117769841157\n",
            "======Model training from:  2009-04-01 to  2021-07-06\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_252_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 98          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | -0.0351     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -28.6       |\n",
            "|    reward             | -0.15436654 |\n",
            "|    std                | 0.998       |\n",
            "|    value_loss         | 5.15        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 97        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 50.5      |\n",
            "|    reward             | 1.3676119 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 2.12      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -179      |\n",
            "|    reward             | 5.1952586 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 22.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 20         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | 79.1       |\n",
            "|    reward             | -0.3978011 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 7.82       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.9      |\n",
            "|    explained_variance | 0.19       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -8.81      |\n",
            "|    reward             | 0.19138733 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 6.38       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | -0.00925   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -498       |\n",
            "|    reward             | -11.956305 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 222        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 35         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | -0.169     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -68.7      |\n",
            "|    reward             | 0.39965674 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 3.86       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 98          |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | -0.0865     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | -164        |\n",
            "|    reward             | -0.33571205 |\n",
            "|    std                | 0.996       |\n",
            "|    value_loss         | 16.1        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 98          |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | 0.159       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 46.5        |\n",
            "|    reward             | -0.19355251 |\n",
            "|    std                | 0.996       |\n",
            "|    value_loss         | 1.99        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 98          |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 0.0618      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -15.1       |\n",
            "|    reward             | -0.48996487 |\n",
            "|    std                | 0.997       |\n",
            "|    value_loss         | 0.677       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 55        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | -0.192    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -233      |\n",
            "|    reward             | 1.1524396 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 35.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 60        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -0.214    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 14.9      |\n",
            "|    reward             | -2.838138 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 3.95      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 65         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.167      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 43.7       |\n",
            "|    reward             | -1.0078373 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.86       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 70        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.0727   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -17.9     |\n",
            "|    reward             | 2.1590974 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.71      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 75         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 42.5       |\n",
            "|    reward             | 0.47163484 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.17       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 80        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0.000262  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -73.2     |\n",
            "|    reward             | 0.8027305 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 19.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 85        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -184      |\n",
            "|    reward             | 0.3686392 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 29.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 90        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 116       |\n",
            "|    reward             | 1.6162095 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 21.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.00951  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -1.74     |\n",
            "|    reward             | 1.1433389 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.195     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 101        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0113    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -38.9      |\n",
            "|    reward             | 0.97623837 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.806      |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2021-07-06 to  2021-10-04\n",
            "A2C Sharpe Ratio:  -0.0528373614471615\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_252_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 101       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 20        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.2801732 |\n",
            "----------------------------------\n",
            "day: 3085, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4550937.53\n",
            "total_reward: 3550937.53\n",
            "total_cost: 408098.28\n",
            "total_trades: 86397\n",
            "Sharpe: 0.873\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 102         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018978704 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00994    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.48        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0284     |\n",
            "|    reward               | 0.49718028  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 10.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 103         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 59          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012346724 |\n",
            "|    clip_fraction        | 0.155       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00278    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 19.6        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0154     |\n",
            "|    reward               | -0.8982904  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 50.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 103         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 78          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014507987 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.012      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 43.8        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.016      |\n",
            "|    reward               | -0.0212465  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 74.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 104         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 98          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016703494 |\n",
            "|    clip_fraction        | 0.186       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0496     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.09        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0285     |\n",
            "|    reward               | 1.0109037   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 14.2        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2021-07-06 to  2021-10-04\n",
            "PPO Sharpe Ratio:  -0.05262682094979255\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_252_1\n",
            "day: 3085, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4501430.61\n",
            "total_reward: 3501430.61\n",
            "total_cost: 1082.97\n",
            "total_trades: 61741\n",
            "Sharpe: 0.737\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 76        |\n",
            "|    time_elapsed    | 161       |\n",
            "|    total_timesteps | 12344     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -3.66     |\n",
            "|    critic_loss     | 176       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 9258      |\n",
            "|    reward          | 2.1645079 |\n",
            "----------------------------------\n",
            "======DDPG Validation from:  2021-07-06 to  2021-10-04\n",
            "======Best Model Retraining from:  2009-04-01 to  2021-10-04\n",
            "======Trading from:  2021-10-04 to  2022-01-03\n",
            "============================================\n",
            "turbulence_threshold:  203.40117769841157\n",
            "======Model training from:  2009-04-01 to  2021-10-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_315_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 98           |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 5            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.3        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -51.2        |\n",
            "|    reward             | -0.096114956 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 4.56         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -36.9     |\n",
            "|    reward             | 2.9646184 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.756     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 97        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -236      |\n",
            "|    reward             | 1.1201329 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 36.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 20         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -53.9      |\n",
            "|    reward             | 0.03644575 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.41       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 34.1      |\n",
            "|    reward             | 0.3948357 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.08      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -618       |\n",
            "|    reward             | -12.502208 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 338        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 35         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0164    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -105       |\n",
            "|    reward             | 0.30092302 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 10.8       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 98          |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | 74.6        |\n",
            "|    reward             | 0.009111182 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 4.73        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 45        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -0.0124   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -131      |\n",
            "|    reward             | 2.0478728 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 16.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 50         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -34.9      |\n",
            "|    reward             | 0.04952446 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.24       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 98          |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 55          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | -0.0188     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 344         |\n",
            "|    reward             | -0.11844914 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 64.7        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 98          |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 60          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | 58.9        |\n",
            "|    reward             | -0.28185675 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 6.99        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 66         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0.549      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -11.7      |\n",
            "|    reward             | -0.7957832 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.135      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 71         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -29.7      |\n",
            "|    reward             | 0.16117185 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.859      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 76         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 15.7       |\n",
            "|    reward             | 0.17504984 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.528      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 81        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 48.7      |\n",
            "|    reward             | 3.1540215 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 6.42      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 98          |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 86          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | 22.9        |\n",
            "|    reward             | -0.09754947 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.677       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 91        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -0.171    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 99        |\n",
            "|    reward             | -1.175583 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 9.98      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 98       |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 96       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.4    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -24.6    |\n",
            "|    reward             | 0.362812 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.367    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 101        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -146       |\n",
            "|    reward             | -1.7740997 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 13.5       |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2021-10-04 to  2022-01-03\n",
            "A2C Sharpe Ratio:  0.3744625013790845\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_315_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 106       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 19        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 0.7561091 |\n",
            "----------------------------------\n",
            "day: 3148, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4259003.47\n",
            "total_reward: 3259003.47\n",
            "total_cost: 426068.70\n",
            "total_trades: 87901\n",
            "Sharpe: 0.790\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 101         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016951367 |\n",
            "|    clip_fraction        | 0.229       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.000697   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.25        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0307     |\n",
            "|    reward               | 0.9373541   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 9.91        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 102         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 60          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017283382 |\n",
            "|    clip_fraction        | 0.176       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.00633     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 33.4        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0207     |\n",
            "|    reward               | 7.712371    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 56.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 102         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 79          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010827523 |\n",
            "|    clip_fraction        | 0.0962      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.00682     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 73.4        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.018      |\n",
            "|    reward               | -0.83698237 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 134         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 102         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 99          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013603406 |\n",
            "|    clip_fraction        | 0.172       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | 0.0243      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.64        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0243     |\n",
            "|    reward               | 0.5904208   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 12.7        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2021-10-04 to  2022-01-03\n",
            "PPO Sharpe Ratio:  0.0593551480877188\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_315_1\n",
            "day: 3148, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4617783.42\n",
            "total_reward: 3617783.42\n",
            "total_cost: 1110.92\n",
            "total_trades: 49019\n",
            "Sharpe: 0.745\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 75        |\n",
            "|    time_elapsed    | 167       |\n",
            "|    total_timesteps | 12596     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 36.1      |\n",
            "|    critic_loss     | 656       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 9447      |\n",
            "|    reward          | 5.4972343 |\n",
            "----------------------------------\n",
            "======DDPG Validation from:  2021-10-04 to  2022-01-03\n",
            "======Best Model Retraining from:  2009-04-01 to  2022-01-03\n",
            "======Trading from:  2022-01-03 to  2022-04-04\n",
            "Ensemble Strategy took:  25.210217595100403  minutes\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-4153cda81a48>\u001b[0m in \u001b[0;36m<cell line: 163>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-4153cda81a48>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrebalance_window\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalidation_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_trade_date\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrebalance_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/account_value_trade_{}_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensemble'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mdf_account_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     sharpe = (252 ** 0.5) * df_account_value.account_value.pct_change(\n\u001b[1;32m    131\u001b[0m         1).mean() / df_account_value.account_value.pct_change(1).std()\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6wjk6Qwg-ar"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Making the most of your colab subscription",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}